import type { Question } from '../types';

export const mlFundamentalsQuestions: Question[] = [
  {
    id: 'ai-ml-fundamentals-001',
    block: 'ai',
    topic: 'ml-fundamentals',
    topicLabel: 'Основы ML',
    difficulty: 'junior',
    type: 'quiz',
    question: 'Какой тип машинного обучения использует размеченные данные (пары вход-выход) для обучения модели?',
    options: [
      'Обучение с подкреплением (Reinforcement Learning)',
      'Обучение с учителем (Supervised Learning)',
      'Обучение без учителя (Unsupervised Learning)',
      'Самообучение (Self-supervised Learning)',
    ],
    correctIndex: 1,
    explanation:
      'Supervised Learning (обучение с учителем) — подход, при котором модель обучается на размеченных данных, где каждому входу соответствует правильный ответ (label). Модель учится находить зависимость между входными признаками и целевой переменной. Примеры задач: классификация (спам/не спам), регрессия (предсказание цены). В отличие от unsupervised learning, где разметки нет, и reinforcement learning, где агент учится через взаимодействие со средой.',
  },
  {
    id: 'ai-ml-fundamentals-002',
    block: 'ai',
    topic: 'ml-fundamentals',
    topicLabel: 'Основы ML',
    difficulty: 'junior',
    type: 'quiz',
    question: 'Что такое переобучение (overfitting)?',
    options: [
      'Модель показывает низкое качество и на обучающей, и на тестовой выборке',
      'Модель хорошо работает на обучающих данных, но плохо обобщает на новые данные',
      'Модель обучена на слишком малом количестве эпох',
      'Модель использует слишком мало признаков для обучения',
    ],
    correctIndex: 1,
    explanation:
      'Переобучение (overfitting) — ситуация, когда модель «запоминает» обучающую выборку вместо того, чтобы выучить общие закономерности. Признак: высокая точность на train, низкая на test/validation. Причины: слишком сложная модель, мало данных, слишком долгое обучение. Методы борьбы: регуляризация (L1/L2), dropout, early stopping, увеличение данных (data augmentation), кросс-валидация.',
  },
  {
    id: 'ai-ml-fundamentals-003',
    block: 'ai',
    topic: 'ml-fundamentals',
    topicLabel: 'Основы ML',
    difficulty: 'junior',
    type: 'quiz',
    question: 'Какая метрика лучше подходит для оценки модели классификации на несбалансированных данных (например, 95% класс A, 5% класс B)?',
    options: [
      'Accuracy (точность)',
      'F1-score',
      'Средняя абсолютная ошибка (MAE)',
      'R² (коэффициент детерминации)',
    ],
    correctIndex: 1,
    explanation:
      'На несбалансированных данных accuracy обманчива: модель, предсказывающая всегда класс A, получит 95% accuracy. F1-score — гармоническое среднее precision и recall — учитывает обе ошибки (false positives и false negatives) и не зависит от дисбаланса классов. Также полезны: precision-recall кривая, ROC-AUC, и confusion matrix для детального анализа. MAE и R² — метрики для задач регрессии, не классификации.',
  },
  {
    id: 'ai-ml-fundamentals-004',
    block: 'ai',
    topic: 'ml-fundamentals',
    topicLabel: 'Основы ML',
    difficulty: 'middle',
    type: 'quiz',
    question: 'Что описывает компромисс bias-variance (дилемма смещения-дисперсии)?',
    options: [
      'Компромисс между скоростью обучения и качеством модели',
      'Компромисс между ошибкой из-за упрощённых предположений модели (bias) и ошибкой из-за чувствительности к конкретным данным (variance)',
      'Компромисс между объёмом обучающей и тестовой выборки',
      'Компромисс между количеством признаков и количеством примеров',
    ],
    correctIndex: 1,
    explanation:
      'Bias-variance tradeoff — фундаментальная концепция ML. High bias (недообучение): модель слишком простая, не улавливает закономерности (пример: линейная регрессия для нелинейных данных). High variance (переобучение): модель слишком сложная, подстраивается под шум в данных. Общая ошибка = bias² + variance + irreducible error. Цель — найти баланс: достаточно сложная модель для capture паттернов, но не настолько сложная, чтобы запоминать шум.',
  },
  {
    id: 'ai-ml-fundamentals-005',
    block: 'ai',
    topic: 'ml-fundamentals',
    topicLabel: 'Основы ML',
    difficulty: 'middle',
    type: 'quiz',
    question: 'Для чего используется k-fold кросс-валидация?',
    options: [
      'Для увеличения объёма обучающих данных',
      'Для более надёжной оценки качества модели путём многократного разбиения данных на обучающую и валидационную выборки',
      'Для автоматического подбора гиперпараметров модели',
      'Для уменьшения времени обучения за счёт параллелизации',
    ],
    correctIndex: 1,
    explanation:
      'K-fold cross-validation: данные делятся на k частей (folds). Модель обучается k раз, каждый раз используя k-1 частей для обучения и 1 для валидации. Итоговая метрика — среднее по k запускам. Преимущества: каждый пример используется для валидации ровно 1 раз, оценка более устойчива чем single train/test split. Типичные значения k: 5 или 10. Вариации: stratified k-fold (сохраняет пропорции классов), leave-one-out (k = N).',
  },
  {
    id: 'ai-ml-fundamentals-006',
    block: 'ai',
    topic: 'ml-fundamentals',
    topicLabel: 'Основы ML',
    difficulty: 'middle',
    type: 'open',
    question: 'Сравните L1 (Lasso) и L2 (Ridge) регуляризацию. В каких случаях предпочтительна каждая?',
    sampleAnswer:
      'L1 (Lasso) добавляет к функции потерь сумму модулей весов (|w|). Приводит к разреженным моделям — часть весов обнуляется, что работает как автоматический отбор признаков. Подходит когда много нерелевантных признаков. L2 (Ridge) добавляет сумму квадратов весов (w²). Уменьшает все веса, но не обнуляет их. Подходит когда все признаки потенциально важны, но нужно предотвратить переобучение. Elastic Net — комбинация L1 и L2, используется когда есть группы коррелированных признаков.',
    explanation:
      'Регуляризация — метод борьбы с переобучением через добавление штрафа за сложность модели в функцию потерь. L1 создаёт разреженные решения (feature selection), L2 — сжимает веса к нулю, но не обнуляет. На практике L2 чаще используется в нейронных сетях (weight decay), а L1 — в линейных моделях для интерпретируемости.',
  },
  {
    id: 'ai-ml-fundamentals-007',
    block: 'ai',
    topic: 'ml-fundamentals',
    topicLabel: 'Основы ML',
    difficulty: 'senior',
    type: 'open',
    question: 'Объясните, как работает градиентный бустинг (Gradient Boosting). Почему XGBoost/LightGBM до сих пор часто побеждают нейросети на табличных данных?',
    sampleAnswer:
      'Градиентный бустинг строит ансамбль слабых моделей (обычно деревьев решений) последовательно. Каждое новое дерево обучается предсказывать остатки (ошибки) предыдущего ансамбля, фактически выполняя градиентный спуск в пространстве функций. Итоговое предсказание — сумма предсказаний всех деревьев. XGBoost/LightGBM побеждают нейросети на табличных данных потому что: (1) деревья естественно обрабатывают смешанные типы данных (числовые + категориальные), (2) не требуют нормализации, (3) устойчивы к нерелевантным признакам, (4) работают хорошо при малом объёме данных, (5) нейросети оптимизированы для данных с пространственной/временной структурой (изображения, текст), которой в табличных данных нет.',
    explanation:
      'Gradient Boosting — один из самых мощных алгоритмов для табличных данных. XGBoost (2014), LightGBM (2017) и CatBoost (2017) — оптимизированные реализации с различными улучшениями: histogram-based splitting, leaf-wise growth, ordered boosting. Исследования (например, табличные бенчмарки 2022-2024) регулярно подтверждают их превосходство над deep learning на структурированных данных.',
  },
  {
    id: 'ai-ml-fundamentals-008',
    block: 'ai',
    topic: 'ml-fundamentals',
    topicLabel: 'Основы ML',
    difficulty: 'senior',
    type: 'open',
    question: 'Что такое data leakage (утечка данных) в ML? Приведите примеры и объясните, как её обнаружить и предотвратить.',
    sampleAnswer:
      'Data leakage — ситуация, когда информация из тестовой выборки или будущих данных «утекает» в обучение, приводя к нереалистично высоким метрикам. Примеры: (1) нормализация до разделения на train/test (статистики test попадают в обучение), (2) признак, напрямую связанный с целевой переменной (ID пациента, коррелирующий с диагнозом), (3) использование данных из будущего в задачах прогнозирования временных рядов. Обнаружение: подозрительно высокие метрики, резкое падение качества на реальных данных, анализ feature importance. Предотвращение: строгое разделение данных до любой предобработки, использование pipeline (sklearn Pipeline), temporal split для временных данных, ревью feature engineering.',
    explanation:
      'Data leakage — одна из самых коварных ошибок в ML, потому что модель кажется отличной на валидации, но проваливается в продакшене. Особенно опасна в медицине, финансах и других high-stakes областях. Правило: всё, что знает модель при обучении, должно быть доступно ей и при инференсе.',
  },
  {
    id: 'ai-ml-fundamentals-009',
    block: 'ai',
    topic: 'ml-fundamentals',
    topicLabel: 'Основы ML',
    difficulty: 'senior',
    type: 'quiz',
    question: 'Какое утверждение о теореме «No Free Lunch» в машинном обучении верно?',
    options: [
      'Существует универсальный алгоритм, превосходящий все остальные на любых задачах',
      'Ни один алгоритм не может быть лучше всех остальных на всех возможных задачах — выбор алгоритма зависит от данных и задачи',
      'Глубокое обучение всегда превосходит классические методы при достаточном объёме данных',
      'Ансамблевые методы всегда лучше одиночных моделей',
    ],
    correctIndex: 1,
    explanation:
      'Теорема No Free Lunch (Wolpert, 1996) утверждает, что при усреднении по всем возможным задачам все алгоритмы оптимизации эквивалентны. Практический вывод: не существует «лучшего» алгоритма — выбор зависит от конкретной задачи, данных и ограничений. Поэтому важно: понимать предположения (inductive bias) каждого алгоритма, пробовать разные подходы, использовать domain knowledge для выбора.',
  },
];
