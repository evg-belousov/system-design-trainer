import type { Question } from '../types';

export const loadBalancingQuestions: Question[] = [
  {
    id: 'sd-lb-001',
    block: 'sd',
    topic: 'load-balancing',
    topicLabel: 'Балансировка нагрузки',
    difficulty: 'junior',
    type: 'quiz',
    question: 'Какова основная задача балансировщика нагрузки (Load Balancer)?',
    options: [
      'Шифрование трафика между клиентом и сервером',
      'Распределение входящих запросов между несколькими серверами',
      'Кэширование ответов для ускорения отклика',
      'Мониторинг состояния здоровья серверов',
    ],
    correctIndex: 1,
    explanation:
      'Основная задача балансировщика нагрузки -- распределение входящего сетевого трафика между несколькими серверами (бэкендами). Это позволяет увеличить пропускную способность системы, обеспечить высокую доступность и отказоустойчивость. Хотя балансировщики часто выполняют и дополнительные функции (SSL-терминация, health-checks, кэширование), распределение нагрузки -- их первичная задача.',
  },
  {
    id: 'sd-lb-002',
    block: 'sd',
    topic: 'load-balancing',
    topicLabel: 'Балансировка нагрузки',
    difficulty: 'middle',
    type: 'quiz',
    question: 'Какой алгоритм балансировки нагрузки лучше всего подходит для серверов с разной производительностью?',
    options: [
      'Round Robin -- запросы распределяются по кругу',
      'Weighted Round Robin -- запросы распределяются с учётом весов серверов',
      'Random -- запросы направляются на случайный сервер',
      'IP Hash -- сервер выбирается на основе хэша IP-адреса клиента',
    ],
    correctIndex: 1,
    explanation:
      'Weighted Round Robin назначает каждому серверу вес, пропорциональный его производительности. Сервер с весом 3 получит в три раза больше запросов, чем сервер с весом 1. Это позволяет эффективно использовать гетерогенную инфраструктуру, где серверы имеют разные характеристики CPU, RAM и производительности. Обычный Round Robin распределяет нагрузку равномерно и не учитывает различия в мощности серверов.',
  },
  {
    id: 'sd-lb-003',
    block: 'sd',
    topic: 'load-balancing',
    topicLabel: 'Балансировка нагрузки',
    difficulty: 'middle',
    type: 'open',
    question: 'Объясните разницу между балансировкой нагрузки на уровне L4 и L7 модели OSI. В каких сценариях предпочтительнее каждый из вариантов?',
    sampleAnswer:
      'L4 (транспортный уровень) балансировка работает на уровне TCP/UDP: решение о маршрутизации принимается на основе IP-адреса и порта без анализа содержимого запроса. Она быстрее, потребляет меньше ресурсов и подходит для высоконагруженных сценариев, где не нужна маршрутизация на основе содержимого. L7 (уровень приложения) балансировка анализирует содержимое HTTP-запроса: URL, заголовки, куки. Она позволяет маршрутизировать запросы на основе пути (/api на один бэкенд, /static на другой), делать content-based routing, SSL-терминацию, модификацию заголовков. L4 предпочтителен для протоколов, отличных от HTTP, и для максимальной производительности. L7 -- для веб-приложений, где нужна гибкая маршрутизация, A/B-тестирование, канареечные деплои.',
    explanation:
      'Выбор между L4 и L7 балансировкой -- это компромисс между производительностью и функциональностью. На практике часто используют оба уровня: L4 на внешнем периметре для распределения трафика между кластерами, L7 внутри кластера для интеллектуальной маршрутизации. Примеры L4: AWS NLB, HAProxy в режиме TCP. Примеры L7: Nginx, HAProxy в режиме HTTP, AWS ALB, Envoy.',
  },
  {
    id: 'sd-lb-004',
    block: 'sd',
    topic: 'load-balancing',
    topicLabel: 'Балансировка нагрузки',
    difficulty: 'senior',
    type: 'open',
    question: 'Как обеспечить высокую доступность самого балансировщика нагрузки? Что произойдёт, если балансировщик выйдет из строя?',
    sampleAnswer:
      'Балансировщик нагрузки сам может стать единой точкой отказа (SPOF), поэтому необходимо обеспечить его отказоустойчивость. Основные подходы: 1) Active-Passive (горячий резерв): два балансировщика, один активный, второй в режиме ожидания. Используется протокол VRRP (Virtual Router Redundancy Protocol) для автоматического переключения виртуального IP (VIP) при отказе активного узла. Время переключения -- несколько секунд. 2) Active-Active: несколько балансировщиков работают одновременно, трафик распределяется между ними через DNS Round Robin или Anycast. Обеспечивает лучшее использование ресурсов. 3) DNS-based failover: несколько A-записей указывают на разные балансировщики, при отказе одного DNS обновляется (но TTL может замедлить переключение). 4) Облачные решения (AWS ELB, GCP LB): провайдер автоматически обеспечивает отказоустойчивость.',
    explanation:
      'На практике для критически важных систем используется комбинация подходов. Например, Anycast DNS направляет трафик на ближайший кластер, внутри кластера Active-Passive пара балансировщиков обрабатывает трафик. Важно проводить регулярные учения (chaos engineering) по отказу балансировщиков, чтобы убедиться в корректности переключения.',
  },
  {
    id: 'sd-lb-005',
    block: 'sd',
    topic: 'load-balancing',
    topicLabel: 'Балансировка нагрузки',
    difficulty: 'junior',
    type: 'quiz',
    question: 'Что такое health check в контексте балансировки нагрузки?',
    options: [
      'Проверка SSL-сертификата сервера',
      'Периодическая проверка доступности и работоспособности серверов за балансировщиком',
      'Анализ нагрузки на CPU и память серверов',
      'Проверка корректности HTTP-ответов на стороне клиента',
    ],
    correctIndex: 1,
    explanation:
      'Health check -- это механизм, с помощью которого балансировщик нагрузки периодически проверяет доступность и работоспособность бэкенд-серверов. Обычно это HTTP-запрос на специальный endpoint (например, /health), TCP-проверка соединения или выполнение скрипта. Если сервер не отвечает или отвечает с ошибкой, балансировщик перестаёт направлять на него трафик до восстановления. Это ключевой механизм обеспечения высокой доступности.',
  },
  {
    id: 'sd-lb-006',
    block: 'sd',
    topic: 'load-balancing',
    topicLabel: 'Балансировка нагрузки',
    difficulty: 'junior',
    type: 'quiz',
    question: 'Что такое sticky sessions (привязка сессий) в контексте балансировки нагрузки?',
    options: [
      'Механизм шифрования сессионных данных',
      'Привязка клиента к одному и тому же серверу на протяжении всей сессии',
      'Автоматическое продление времени жизни сессии',
      'Копирование сессии на все серверы кластера',
    ],
    correctIndex: 1,
    explanation:
      'Sticky sessions (session affinity) — это механизм, при котором балансировщик нагрузки направляет все запросы одного клиента на один и тот же бэкенд-сервер. Реализуется через cookie (балансировщик добавляет cookie с идентификатором сервера) или по IP-адресу клиента. Sticky sessions необходимы, когда приложение хранит состояние сессии в памяти сервера. Однако они создают неравномерную нагрузку и затрудняют масштабирование. Лучшая альтернатива — вынести состояние сессии в внешнее хранилище (Redis) и использовать stateless-серверы.',
  },
  {
    id: 'sd-lb-007',
    block: 'sd',
    topic: 'load-balancing',
    topicLabel: 'Балансировка нагрузки',
    difficulty: 'junior',
    type: 'quiz',
    question: 'Какой алгоритм балансировки направляет каждый новый запрос на сервер с наименьшим количеством активных соединений?',
    options: [
      'Round Robin',
      'Weighted Round Robin',
      'Least Connections',
      'IP Hash',
    ],
    correctIndex: 2,
    explanation:
      'Least Connections — алгоритм балансировки, который направляет новый запрос на сервер с наименьшим количеством текущих активных соединений. Он лучше, чем Round Robin, когда запросы имеют разную длительность обработки: сервер с долгими запросами будет получать меньше новых. Это особенно полезно для WebSocket-соединений и длительных операций. Существует также вариант Weighted Least Connections, учитывающий производительность серверов.',
  },
  {
    id: 'sd-lb-008',
    block: 'sd',
    topic: 'load-balancing',
    topicLabel: 'Балансировка нагрузки',
    difficulty: 'junior',
    type: 'quiz',
    question: 'Что такое DNS-based балансировка нагрузки?',
    options: [
      'Шифрование DNS-запросов для защиты от атак',
      'Распределение трафика между серверами путём возврата разных IP-адресов в DNS-ответах',
      'Кэширование DNS-записей на стороне балансировщика',
      'Использование DNS для мониторинга здоровья серверов',
    ],
    correctIndex: 1,
    explanation:
      'DNS-based балансировка работает на уровне DNS-резолвинга: DNS-сервер возвращает разные IP-адреса (A-записи) для одного доменного имени, распределяя клиентов между серверами. Простейшая реализация — DNS Round Robin (несколько A-записей ротируются). Более продвинутые решения (Route53, Cloudflare) учитывают географию клиента, здоровье серверов и нагрузку. Недостаток — DNS-кэширование (TTL) замедляет реакцию на отказы.',
  },
  {
    id: 'sd-lb-009',
    block: 'sd',
    topic: 'load-balancing',
    topicLabel: 'Балансировка нагрузки',
    difficulty: 'middle',
    type: 'quiz',
    question: 'Что такое connection draining (deregistration delay) в балансировке нагрузки?',
    options: [
      'Удаление всех соединений при перезагрузке балансировщика',
      'Завершение существующих соединений перед выводом сервера из обслуживания, без приёма новых запросов',
      'Ограничение максимального количества соединений на один сервер',
      'Перенаправление соединений с медленного сервера на быстрый',
    ],
    correctIndex: 1,
    explanation:
      'Connection draining — механизм плавного вывода сервера из обслуживания. Когда сервер помечается для вывода (при деплое, масштабировании вниз или по результатам health check), балансировщик перестаёт направлять на него новые запросы, но даёт время завершить обработку текущих. Обычно настраивается таймаут (например, 30 секунд), после которого оставшиеся соединения принудительно закрываются. Это предотвращает ошибки у клиентов при обновлении или обслуживании серверов.',
  },
  {
    id: 'sd-lb-010',
    block: 'sd',
    topic: 'load-balancing',
    topicLabel: 'Балансировка нагрузки',
    difficulty: 'middle',
    type: 'quiz',
    question: 'Какое основное преимущество L7-балансировщика нагрузки перед L4 при развёртывании микросервисов?',
    options: [
      'Более высокая пропускная способность',
      'Меньшее потребление ресурсов',
      'Возможность маршрутизации запросов на основе URL-пути, заголовков и содержимого запроса',
      'Отсутствие необходимости в SSL-сертификатах',
    ],
    correctIndex: 2,
    explanation:
      'L7-балансировщик анализирует содержимое HTTP-запроса и может маршрутизировать на основе URL-пути (/api/users → user-service, /api/orders → order-service), заголовков (A/B-тестирование по cookie), метода запроса, и даже тела запроса. Это критически важно для микросервисной архитектуры, где один входной URL должен быть направлен на разные сервисы. L4-балансировщик видит только IP и порт и не может выполнять content-based routing.',
  },
  {
    id: 'sd-lb-011',
    block: 'sd',
    topic: 'load-balancing',
    topicLabel: 'Балансировка нагрузки',
    difficulty: 'middle',
    type: 'open',
    question: 'Сравните HAProxy и Nginx в роли балансировщиков нагрузки. Каковы ключевые различия и сценарии использования каждого?',
    sampleAnswer:
      'HAProxy — специализированный балансировщик нагрузки и прокси, изначально спроектированный для этой задачи. Преимущества: высокая производительность, детальная конфигурация балансировки (множество алгоритмов, health checks, ACL), поддержка L4 и L7, runtime API для управления, отличный мониторинг (stats page). Nginx — веб-сервер и reverse proxy с функцией балансировки нагрузки. Преимущества: может одновременно раздавать статику, выполнять SSL-терминацию, кэширование, сжатие, rate limiting, поддержка HTTP/2 и gRPC, Lua-скриптинг для кастомной логики. Различия: HAProxy лучше для чистой балансировки нагрузки с продвинутыми health checks и session persistence. Nginx лучше как универсальный reverse proxy, совмещающий балансировку со статикой и кэшированием. На практике часто используют Nginx как edge-прокси (SSL-терминация, статика) и HAProxy для внутренней балансировки между сервисами.',
    explanation:
      'Оба инструмента широко используются и имеют зрелую экосистему. В мире Kubernetes Nginx часто встречается как Ingress Controller (nginx-ingress), а HAProxy — как альтернативный ingress. Envoy Proxy набирает популярность как современная альтернатива обоим, особенно в service mesh архитектурах (Istio).',
  },
  {
    id: 'sd-lb-012',
    block: 'sd',
    topic: 'load-balancing',
    topicLabel: 'Балансировка нагрузки',
    difficulty: 'middle',
    type: 'quiz',
    question: 'Что такое Global Server Load Balancing (GSLB)?',
    options: [
      'Балансировка нагрузки внутри одного дата-центра',
      'Распределение трафика между несколькими географически распределёнными дата-центрами',
      'Ограничение нагрузки на глобальном уровне через rate limiting',
      'Балансировка запросов к глобальной базе данных',
    ],
    correctIndex: 1,
    explanation:
      'GSLB (Global Server Load Balancing) — это распределение трафика между несколькими дата-центрами или регионами. Реализуется обычно через DNS-based routing (AWS Route53, Cloudflare) с учётом: географической близости клиента (geo-routing), здоровья дата-центров (failover), нагрузки на каждый дата-центр. GSLB обеспечивает минимальную задержку для пользователей по всему миру и отказоустойчивость на уровне целых регионов. Технологии: Anycast, GeoDNS, latency-based routing.',
  },
  {
    id: 'sd-lb-013',
    block: 'sd',
    topic: 'load-balancing',
    topicLabel: 'Балансировка нагрузки',
    difficulty: 'senior',
    type: 'open',
    question: 'Опишите, как реализовать zero-downtime deployment с использованием балансировщика нагрузки. Какие стратегии деплоя существуют?',
    sampleAnswer:
      'Zero-downtime deployment — обновление приложения без прерывания обслуживания пользователей. Стратегии с использованием балансировщика нагрузки: 1) Rolling deployment: серверы обновляются по одному. Балансировщик выводит сервер из ротации (connection draining), обновляет его, проверяет health check и возвращает в ротацию. 2) Blue-Green deployment: две идентичные среды (blue — текущая, green — новая). После деплоя на green и проверки, балансировщик переключает весь трафик с blue на green. Откат мгновенный — переключение обратно. 3) Canary deployment: новая версия деплоится на малую часть серверов (1-5%). Балансировщик направляет на них часть трафика. При успешных метриках доля постепенно увеличивается до 100%. 4) Feature flags: не меняя инфраструктуру, новый код активируется для части пользователей через флаги. Все стратегии требуют обратной совместимости API и схемы БД между версиями.',
    explanation:
      'На практике выбор стратегии зависит от рисков и скорости отката. Blue-Green даёт мгновенный откат, но требует двойных ресурсов. Canary минимизирует blast radius, но усложняет мониторинг. Rolling — самый экономичный, но откат медленнее. Kubernetes нативно поддерживает Rolling и, через Istio/Argo Rollouts, Canary и Blue-Green деплои.',
  },
  {
    id: 'sd-lb-014',
    block: 'sd',
    topic: 'load-balancing',
    topicLabel: 'Балансировка нагрузки',
    difficulty: 'senior',
    type: 'quiz',
    question: 'Какой алгоритм балансировки нагрузки используется, когда необходимо минимизировать время отклика?',
    options: [
      'Round Robin',
      'Random',
      'Least Response Time (наименьшее время отклика)',
      'Source IP Hash',
    ],
    correctIndex: 2,
    explanation:
      'Least Response Time — алгоритм, который направляет запрос на сервер с наименьшим текущим временем отклика и минимальным количеством активных соединений. Он учитывает не только количество соединений (как Least Connections), но и реальную скорость ответа сервера. Это позволяет автоматически перенаправлять трафик от деградирующих серверов. Реализован в Nginx (least_time), HAProxy (leastconn с observe-layer) и AWS ALB. Недостаток — необходимость постоянного измерения задержки, что добавляет накладные расходы.',
  },
  {
    id: 'sd-lb-015',
    block: 'sd',
    topic: 'load-balancing',
    topicLabel: 'Балансировка нагрузки',
    difficulty: 'senior',
    type: 'open',
    question: 'Что такое Service Mesh и как он связан с балансировкой нагрузки в микросервисной архитектуре? Приведите примеры реализаций.',
    sampleAnswer:
      'Service Mesh — это инфраструктурный слой для управления коммуникацией между микросервисами. Каждый сервис получает sidecar-прокси (обычно Envoy), который перехватывает весь входящий и исходящий трафик. Service Mesh берёт на себя: 1) Client-side load balancing — sidecar знает обо всех экземплярах целевого сервиса и балансирует между ними. 2) Service discovery — автоматическое обнаружение новых экземпляров. 3) Circuit breaking — защита от каскадных отказов. 4) Retry/timeout — автоматические повторы и таймауты. 5) mTLS — взаимная аутентификация и шифрование трафика. 6) Observability — метрики, трассировка, логирование. Примеры: Istio (на базе Envoy), Linkerd, Consul Connect. Service Mesh переносит логику балансировки и resilience из кода приложения в инфраструктуру, упрощая разработку, но усложняя операционную часть.',
    explanation:
      'Service Mesh стал стандартом де-факто для крупных микросервисных архитектур в Kubernetes. Однако он добавляет операционную сложность и накладные расходы (дополнительный hop через sidecar, потребление ресурсов). Для небольших систем (до 10-20 сервисов) обычно достаточно простого Kubernetes Service с kube-proxy.',
  },
  {
    id: 'sd-lb-016',
    block: 'sd',
    topic: 'load-balancing',
    topicLabel: 'Балансировка нагрузки',
    difficulty: 'junior',
    type: 'quiz',
    question: 'Где обычно размещается балансировщик нагрузки в архитектуре веб-приложения?',
    options: [
      'За серверами приложений, перед базой данных',
      'Между клиентами (пользователями) и серверами приложений',
      'Между базой данных и кэшем',
      'На стороне клиента в браузере',
    ],
    correctIndex: 1,
    explanation:
      'Балансировщик нагрузки обычно размещается между клиентами и серверами приложений, принимая весь входящий трафик и распределяя его по бэкендам. В сложных архитектурах используются несколько уровней балансировки: 1) DNS-уровень — между пользователями и дата-центрами. 2) L4-балансировщик — на входе в дата-центр. 3) L7-балансировщик — перед серверами приложений. 4) Внутренний балансировщик — между микросервисами.',
  },
  {
    id: 'sd-lb-017',
    block: 'sd',
    topic: 'load-balancing',
    topicLabel: 'Балансировка нагрузки',
    difficulty: 'middle',
    type: 'open',
    question: 'Какие типы health checks существуют и как выбрать правильный для вашего сервиса?',
    sampleAnswer:
      'Типы health checks: 1) TCP check — проверяет, открыт ли порт. Самый простой, но не проверяет работоспособность приложения. 2) HTTP check — отправляет HTTP-запрос на endpoint (обычно /health или /healthz) и проверяет код ответа (200 OK). 3) Deep health check (readiness) — проверяет не только приложение, но и его зависимости (БД, кэш, внешние API). Возвращает детальный статус. 4) Shallow health check (liveness) — проверяет, что процесс приложения жив и может обрабатывать запросы, без проверки зависимостей. Выбор зависит от сценария: для балансировщика нагрузки лучше shallow check — если БД недоступна, нет смысла выводить все серверы из ротации. Deep check полезен для мониторинга и алертинга. В Kubernetes liveness probe определяет, нужно ли перезапустить pod, readiness probe — можно ли направлять на него трафик.',
    explanation:
      'Правильная настройка health checks критична: слишком строгие — вызовут ложные срабатывания и каскадное отключение серверов; слишком мягкие — будут направлять трафик на неработающие серверы. Важные параметры: interval (как часто проверять), timeout (сколько ждать ответа), threshold (сколько неудачных проверок до вывода из ротации).',
  },
  {
    id: 'sd-lb-018',
    block: 'sd',
    topic: 'load-balancing',
    topicLabel: 'Балансировка нагрузки',
    difficulty: 'senior',
    type: 'quiz',
    question: 'Что такое Consistent Hashing в контексте балансировки нагрузки и зачем он нужен?',
    options: [
      'Алгоритм шифрования для защиты трафика',
      'Метод распределения запросов, минимизирующий перераспределение при добавлении/удалении серверов',
      'Способ проверки целостности данных при передаче',
      'Алгоритм сжатия HTTP-запросов',
    ],
    correctIndex: 1,
    explanation:
      'Consistent Hashing в балансировке нагрузки используется для привязки определённых запросов (например, по ключу кэша или ID пользователя) к конкретным серверам. При добавлении или удалении сервера перераспределяется только ~1/N часть запросов, а не все. Это особенно важно при балансировке перед распределённым кэшем: минимизируется количество cache miss при изменении топологии. Используется в Nginx (hash upstream), HAProxy, а также в Memcached и Redis Cluster.',
  },
  {
    id: 'sd-lb-019',
    block: 'sd',
    topic: 'load-balancing',
    topicLabel: 'Балансировка нагрузки',
    difficulty: 'middle',
    type: 'quiz',
    question: 'Что такое SSL/TLS-терминация на балансировщике нагрузки?',
    options: [
      'Шифрование трафика между балансировщиком и бэкенд-серверами',
      'Расшифровка HTTPS-трафика на балансировщике, передача незашифрованного HTTP на бэкенды',
      'Генерация SSL-сертификатов на лету',
      'Блокировка незашифрованного HTTP-трафика',
    ],
    correctIndex: 1,
    explanation:
      'SSL/TLS-терминация — это процесс, при котором балансировщик нагрузки расшифровывает входящий HTTPS-трафик и передаёт запросы бэкенд-серверам по обычному HTTP. Преимущества: снимает нагрузку по шифрованию/дешифрованию с серверов приложений, централизованное управление сертификатами, L7-балансировщик может анализировать содержимое запроса. Для повышения безопасности можно использовать SSL re-encryption — повторное шифрование трафика между балансировщиком и бэкендами (но это добавляет накладные расходы).',
  },
  {
    id: 'sd-lb-020',
    block: 'sd',
    topic: 'load-balancing',
    topicLabel: 'Балансировка нагрузки',
    difficulty: 'senior',
    type: 'open',
    question: 'Объясните концепцию «Power of Two Random Choices» в балансировке нагрузки. Почему она может быть лучше, чем Round Robin или Least Connections?',
    sampleAnswer:
      'Power of Two Random Choices — алгоритм балансировки, при котором для каждого запроса случайным образом выбираются два сервера, и запрос направляется на менее загруженный из них. Несмотря на простоту, этот алгоритм обеспечивает экспоненциально лучшее распределение нагрузки по сравнению с чисто случайным выбором. Преимущества: 1) Не требует глобального знания о состоянии всех серверов (в отличие от Least Connections, который должен отслеживать все соединения). 2) Работает в распределённых системах без центрального координатора. 3) Устойчив к устаревшей информации о нагрузке (race conditions). 4) Автоматически избегает перегруженных серверов. Недостатки по сравнению с Least Connections: немного менее оптимальное распределение, но значительно проще в реализации для распределённых систем. Используется в Envoy proxy, Netflix Ribbon, и описан в работах Michael Mitzenmacher.',
    explanation:
      'Power of Two Random Choices — классический пример того, как небольшое изменение алгоритма (выбрать из двух случайных вместо одного) даёт значительное улучшение. Математически доказано, что максимальная нагрузка на сервер снижается с O(log n / log log n) до O(log log n). Этот принцип применяется не только в балансировке, но и в хэш-таблицах (cuckoo hashing) и других распределённых алгоритмах.',
  },
  {
    id: 'sd-lb-021',
    block: 'sd',
    topic: 'load-balancing',
    topicLabel: 'Балансировка нагрузки',
    difficulty: 'junior',
    type: 'quiz',
    question: 'Что такое reverse proxy и чем он отличается от балансировщика нагрузки?',
    options: [
      'Reverse proxy работает на стороне клиента, балансировщик — на стороне сервера',
      'Reverse proxy — прокси-сервер перед бэкендами, балансировка — одна из его функций',
      'Reverse proxy шифрует трафик, балансировщик — распределяет',
      'Это одно и то же, разницы нет',
    ],
    correctIndex: 1,
    explanation:
      'Reverse proxy — сервер, который принимает запросы клиентов и перенаправляет их на бэкенд-серверы. Балансировка нагрузки — одна из функций reverse proxy. Другие функции: SSL-терминация, кэширование, сжатие, защита от DDoS, URL rewriting, добавление заголовков. Nginx и HAProxy могут работать как reverse proxy с функцией балансировки.',
  },
  {
    id: 'sd-lb-022',
    block: 'sd',
    topic: 'load-balancing',
    topicLabel: 'Балансировка нагрузки',
    difficulty: 'junior',
    type: 'quiz',
    question: 'Какой протокол используется для проверки доступности веб-сервера в HTTP health check?',
    options: [
      'FTP-запрос к серверу',
      'HTTP GET-запрос на специальный endpoint (например, /health)',
      'Ping (ICMP) запрос',
      'SSH-подключение к серверу',
    ],
    correctIndex: 1,
    explanation:
      'HTTP health check отправляет HTTP GET-запрос на специальный endpoint (обычно /health, /healthz или /status). Сервер должен вернуть HTTP 200 OK, если он готов обрабатывать запросы. Это позволяет проверить не только сетевую доступность, но и работоспособность приложения. Health endpoint может проверять подключение к БД, доступность зависимых сервисов.',
  },
  {
    id: 'sd-lb-023',
    block: 'sd',
    topic: 'load-balancing',
    topicLabel: 'Балансировка нагрузки',
    difficulty: 'junior',
    type: 'quiz',
    question: 'Что произойдёт с запросами клиентов, если балансировщик обнаружит, что сервер не прошёл health check?',
    options: [
      'Балансировщик продолжит отправлять запросы на этот сервер',
      'Балансировщик исключит сервер из пула и перестанет направлять на него новые запросы',
      'Балансировщик перезагрузит проблемный сервер',
      'Балансировщик уведомит клиента об ошибке и прекратит работу',
    ],
    correctIndex: 1,
    explanation:
      'При неудачном health check балансировщик исключает сервер из пула (помечает как unhealthy) и перестаёт направлять на него новые запросы. Запросы распределяются между оставшимися здоровыми серверами. Балансировщик продолжает периодически проверять unhealthy сервер и вернёт его в пул, когда health check начнёт проходить успешно.',
  },
  {
    id: 'sd-lb-024',
    block: 'sd',
    topic: 'load-balancing',
    topicLabel: 'Балансировка нагрузки',
    difficulty: 'junior',
    type: 'open',
    question: 'Объясните разницу между внешним (external) и внутренним (internal) балансировщиком нагрузки. Где применяется каждый?',
    sampleAnswer:
      'Внешний (external/public) балансировщик нагрузки имеет публичный IP-адрес и принимает трафик из интернета. Он стоит на границе сети и направляет запросы пользователей на внутренние серверы. Обычно выполняет SSL-терминацию, защиту от DDoS. Примеры: AWS ALB/NLB с публичным IP, Cloudflare Load Balancing. Внутренний (internal/private) балансировщик имеет только приватный IP и используется для балансировки трафика между внутренними сервисами (микросервисами). Недоступен из интернета. Примеры: AWS Internal ALB, Kubernetes Service. Типичная архитектура: внешний LB → веб-серверы → внутренний LB → API-сервисы → внутренний LB → база данных.',
    explanation:
      'Разделение на внешние и внутренние балансировщики — важный аспект сетевой безопасности. Внутренние сервисы (БД, кэш, backend API) не должны быть доступны из интернета напрямую. Внутренняя балансировка также позволяет микросервисам находить друг друга (service discovery) и обеспечивает отказоустойчивость внутренней коммуникации.',
  },
  {
    id: 'sd-lb-025',
    block: 'sd',
    topic: 'load-balancing',
    topicLabel: 'Балансировка нагрузки',
    difficulty: 'middle',
    type: 'quiz',
    question: 'Какой алгоритм балансировки использует хэш от URL или заголовка запроса для маршрутизации?',
    options: [
      'Round Robin',
      'Least Connections',
      'URL Hash / Request Hash',
      'Random',
    ],
    correctIndex: 2,
    explanation:
      'URL Hash (или Request Hash) вычисляет хэш от URL, заголовка или другого параметра запроса и направляет запрос на сервер, соответствующий этому хэшу. Это обеспечивает: 1) кэш-локальность — одинаковые запросы идут на один сервер, повышая hit rate локального кэша; 2) сессионную привязку без cookies — запросы одного пользователя (по IP или header) идут на один сервер. В Nginx: hash $request_uri; или hash $remote_addr.',
  },
  {
    id: 'sd-lb-026',
    block: 'sd',
    topic: 'load-balancing',
    topicLabel: 'Балансировка нагрузки',
    difficulty: 'middle',
    type: 'quiz',
    question: 'Что такое health check interval и threshold в настройках балансировщика?',
    options: [
      'Interval — время ответа сервера, threshold — максимально допустимая задержка',
      'Interval — частота проверок, threshold — количество неудачных проверок до исключения сервера',
      'Interval — время жизни соединения, threshold — максимальное количество соединений',
      'Interval — период кэширования, threshold — размер кэша',
    ],
    correctIndex: 1,
    explanation:
      'Health check interval — как часто балансировщик проверяет каждый сервер (например, каждые 5 секунд). Threshold (порог) — количество последовательных неудачных проверок, после которых сервер считается unhealthy (например, 3 неудачи). Аналогично healthy threshold — количество успешных проверок для возврата в пул. Эти параметры балансируют между быстрым обнаружением сбоев и устойчивостью к временным проблемам.',
  },
  {
    id: 'sd-lb-027',
    block: 'sd',
    topic: 'load-balancing',
    topicLabel: 'Балансировка нагрузки',
    difficulty: 'middle',
    type: 'open',
    question: 'Как настроить балансировку нагрузки для gRPC-сервисов? Чем она отличается от HTTP-балансировки?',
    sampleAnswer:
      'gRPC использует HTTP/2 с мультиплексированием запросов в одном соединении. Это создаёт проблему для L4-балансировки: одно долгоживущее соединение не распределяется между серверами. Решения: 1) L7-балансировка с поддержкой HTTP/2 — балансировщик терминирует HTTP/2 и распределяет отдельные gRPC-вызовы. Nginx (с модулем grpc), Envoy, AWS ALB поддерживают это. 2) Client-side балансировка — gRPC-клиент сам знает о всех серверах и распределяет запросы. Используется с service discovery (Consul, etcd). 3) Lookaside балансировка (gRPC-LB) — клиент запрашивает у специального сервиса список бэкендов. 4) Service Mesh (Istio, Linkerd) — sidecar-прокси выполняет балансировку на уровне вызовов. Важно: gRPC health check использует grpc.health.v1.Health сервис, не HTTP.',
    explanation:
      'gRPC-балансировка — частая проблема при миграции на микросервисы. Kubernetes kube-proxy по умолчанию делает L4-балансировку, что неэффективно для gRPC. Решение — использовать headless service + client-side balancing или Service Mesh.',
  },
  {
    id: 'sd-lb-028',
    block: 'sd',
    topic: 'load-balancing',
    topicLabel: 'Балансировка нагрузки',
    difficulty: 'middle',
    type: 'quiz',
    question: 'Что такое Kubernetes Ingress и какую роль он выполняет?',
    options: [
      'Внутренний балансировщик между подами одного сервиса',
      'L7-балансировщик, управляющий внешним доступом к сервисам кластера на основе URL-правил',
      'Механизм автомасштабирования подов',
      'Сервис обнаружения (service discovery) в Kubernetes',
    ],
    correctIndex: 1,
    explanation:
      'Kubernetes Ingress — это L7-балансировщик, который управляет внешним HTTP/HTTPS-трафиком в кластер. Ingress позволяет: маршрутизировать по URL-пути (/api → service-a, /web → service-b), маршрутизировать по hostname (api.example.com → service-a), SSL-терминацию. Ingress Controller (nginx-ingress, traefik, AWS ALB Ingress) реализует эти правила. Без Ingress каждый сервис требовал бы отдельного LoadBalancer.',
  },
  {
    id: 'sd-lb-029',
    block: 'sd',
    topic: 'load-balancing',
    topicLabel: 'Балансировка нагрузки',
    difficulty: 'middle',
    type: 'quiz',
    question: 'Какой тип Kubernetes Service обеспечивает балансировку нагрузки между подами внутри кластера?',
    options: [
      'NodePort',
      'LoadBalancer',
      'ClusterIP',
      'ExternalName',
    ],
    correctIndex: 2,
    explanation:
      'ClusterIP — тип Service по умолчанию в Kubernetes. Он создаёт виртуальный IP-адрес внутри кластера, доступный только изнутри. kube-proxy обеспечивает балансировку (обычно IPVS или iptables) между подами, соответствующими selector сервиса. ClusterIP — основа для внутренней коммуникации между микросервисами. NodePort и LoadBalancer используются для внешнего доступа.',
  },
  {
    id: 'sd-lb-030',
    block: 'sd',
    topic: 'load-balancing',
    topicLabel: 'Балансировка нагрузки',
    difficulty: 'middle',
    type: 'open',
    question: 'Опишите паттерн Circuit Breaker в контексте балансировки нагрузки между микросервисами. Как он предотвращает каскадные отказы?',
    sampleAnswer:
      'Circuit Breaker — паттерн, предотвращающий каскадные отказы при недоступности сервиса. Три состояния: 1) Closed (замкнут) — запросы проходят нормально; ошибки подсчитываются. 2) Open (разомкнут) — после превышения порога ошибок все запросы немедленно отклоняются без попытки вызова сервиса. Это предотвращает накопление запросов и истощение ресурсов. 3) Half-Open (полуоткрыт) — через timeout пропускается тестовый запрос; если успешен — переход в Closed, если нет — обратно в Open. Преимущества: быстрый fail (не ждём timeout каждый раз), защита от перегрузки умирающего сервиса, возможность fallback (вернуть кэшированные данные или заглушку). Реализации: Resilience4j, Polly, Hystrix (deprecated), Envoy/Istio circuit breaker.',
    explanation:
      'Circuit Breaker — важный паттерн resilience. Без него один медленный сервис может заблокировать все потоки вызывающего сервиса, вызывая каскадный отказ всей системы. Netflix популяризировал этот паттерн через Hystrix.',
  },
  {
    id: 'sd-lb-031',
    block: 'sd',
    topic: 'load-balancing',
    topicLabel: 'Балансировка нагрузки',
    difficulty: 'senior',
    type: 'quiz',
    question: 'Что такое Anycast и как он используется для глобальной балансировки нагрузки?',
    options: [
      'Технология multicast для отправки данных нескольким получателям',
      'Один IP-адрес объявляется из нескольких географических локаций, трафик идёт к ближайшей',
      'Протокол для синхронизации данных между дата-центрами',
      'Метод шифрования трафика между балансировщиками',
    ],
    correctIndex: 1,
    explanation:
      'Anycast — техника, при которой один IP-адрес объявляется (через BGP) из нескольких географических точек присутствия. Сеть автоматически маршрутизирует трафик к ближайшей точке по метрикам BGP. Преимущества: низкая latency (ближайший сервер), автоматический failover (при отказе точки трафик идёт к следующей ближайшей), защита от DDoS (атака распределяется между точками). Используется: Cloudflare, Google DNS (8.8.8.8), AWS Global Accelerator, большинство CDN.',
  },
  {
    id: 'sd-lb-032',
    block: 'sd',
    topic: 'load-balancing',
    topicLabel: 'Балансировка нагрузки',
    difficulty: 'senior',
    type: 'quiz',
    question: 'Какой режим работы HAProxy обеспечивает L4-балансировку с минимальными накладными расходами?',
    options: [
      'HTTP mode',
      'TCP mode',
      'Health mode',
      'Proxy Protocol mode',
    ],
    correctIndex: 1,
    explanation:
      'TCP mode в HAProxy обеспечивает L4-балансировку: HAProxy работает на транспортном уровне, не анализируя содержимое пакетов. Это даёт минимальные накладные расходы и максимальную производительность. Подходит для: не-HTTP протоколов (MySQL, Redis, gRPC без парсинга), когда не нужна маршрутизация по содержимому, для SSL passthrough (SSL терминируется на бэкенде). HTTP mode анализирует HTTP-запросы и поддерживает content-based routing, но медленнее.',
  },
  {
    id: 'sd-lb-033',
    block: 'sd',
    topic: 'load-balancing',
    topicLabel: 'Балансировка нагрузки',
    difficulty: 'senior',
    type: 'open',
    question: 'Как реализовать weighted load balancing на основе текущей производительности серверов (adaptive load balancing)?',
    sampleAnswer:
      'Adaptive (или dynamic) load balancing автоматически корректирует веса серверов на основе их текущей производительности. Подходы: 1) Response time tracking — балансировщик измеряет время ответа каждого сервера и уменьшает вес медленных. Nginx Plus и HAProxy поддерживают это (observe layer7). 2) Active health scores — комбинация метрик (latency, error rate, active connections) формирует score, влияющий на вес. 3) Exponential weighted moving average (EWMA) — сглаживание измерений для устойчивости к выбросам. 4) Server-reported load — серверы сообщают свою нагрузку через health endpoint или заголовки. 5) External metrics — получение метрик из Prometheus/CloudWatch для корректировки весов через API балансировщика. Envoy поддерживает locality-weighted load balancing на основе метрик зон.',
    explanation:
      'Adaptive load balancing — следующий уровень после статических весов. Он автоматически реагирует на деградацию серверов (GC-паузы, сетевые проблемы, ресурсные ограничения), не дожидаясь health check failure. Netflix использует adaptive балансировку в своих системах.',
  },
  {
    id: 'sd-lb-034',
    block: 'sd',
    topic: 'load-balancing',
    topicLabel: 'Балансировка нагрузки',
    difficulty: 'senior',
    type: 'quiz',
    question: 'Что такое proxy protocol и зачем он нужен?',
    options: [
      'Протокол шифрования между балансировщиком и бэкендом',
      'Протокол для передачи информации об исходном клиенте (IP, порт) через прокси/балансировщик',
      'Протокол health check для проверки доступности прокси',
      'Протокол синхронизации конфигурации между балансировщиками',
    ],
    correctIndex: 1,
    explanation:
      'Proxy Protocol (v1 и v2) — протокол для передачи информации об оригинальном клиенте (source IP, destination IP, порты) при проксировании. При L4-балансировке бэкенд видит IP балансировщика, а не клиента. Proxy Protocol добавляет заголовок с информацией о клиенте в начало соединения. Поддерживается: HAProxy, AWS NLB, Nginx, ELB. Важно: бэкенд должен поддерживать Proxy Protocol, иначе он получит мусорные данные.',
  },
  {
    id: 'sd-lb-035',
    block: 'sd',
    topic: 'load-balancing',
    topicLabel: 'Балансировка нагрузки',
    difficulty: 'senior',
    type: 'open',
    question: 'Опишите архитектуру балансировки нагрузки для WebSocket-приложения с миллионами одновременных соединений.',
    sampleAnswer:
      'Архитектура для масштабируемых WebSocket: 1) L4-балансировка на входе — NLB/HAProxy в TCP-режиме для минимальной задержки. L7 не обязателен, так как после handshake соединение стабильно. 2) Sticky sessions — WebSocket-соединение должно сохраняться на одном сервере. IP hash или cookie-based persistence. 3) Connection-aware routing — хранение маппинга user_id → server в Redis для маршрутизации сообщений. 4) Pub/Sub для межсерверной доставки — Redis Pub/Sub или Kafka для доставки сообщений между серверами. Если user A на server 1 отправляет сообщение user B на server 2, оно идёт через pub/sub. 5) Graceful draining — при выводе сервера уведомить клиентов о reconnect на другой сервер. 6) Connection limits — OS tuning (ulimit, net.core.somaxconn) для поддержки миллионов соединений на сервере.',
    explanation:
      'WebSocket масштабируется сложнее, чем stateless HTTP. Discord, Slack используют подобные архитектуры. Важно минимизировать cross-server коммуникацию через умное шардирование (по chat room, guild) — сообщения внутри шарда не требуют pub/sub.',
  },
  {
    id: 'sd-lb-036',
    block: 'sd',
    topic: 'load-balancing',
    topicLabel: 'Балансировка нагрузки',
    difficulty: 'junior',
    type: 'quiz',
    question: 'Что такое upstream в конфигурации Nginx?',
    options: [
      'Клиент, отправляющий запросы к Nginx',
      'Группа бэкенд-серверов, между которыми Nginx распределяет запросы',
      'Внешний DNS-сервер',
      'Лог-файл для записи запросов',
    ],
    correctIndex: 1,
    explanation:
      'Upstream в Nginx — это блок конфигурации, определяющий группу бэкенд-серверов для балансировки нагрузки. В upstream указываются адреса серверов, их веса, параметры health check, алгоритм балансировки. Например: upstream backend { server 10.0.0.1:8080 weight=3; server 10.0.0.2:8080; } — запросы распределяются между двумя серверами с весами 3:1.',
  },
  {
    id: 'sd-lb-037',
    block: 'sd',
    topic: 'load-balancing',
    topicLabel: 'Балансировка нагрузки',
    difficulty: 'junior',
    type: 'quiz',
    question: 'Какой HTTP-код возвращает балансировщик, если все бэкенд-серверы недоступны?',
    options: [
      '404 Not Found',
      '500 Internal Server Error',
      '502 Bad Gateway или 503 Service Unavailable',
      '401 Unauthorized',
    ],
    correctIndex: 2,
    explanation:
      '502 Bad Gateway возвращается, когда балансировщик не может получить валидный ответ от бэкенда (ошибка соединения, таймаут). 503 Service Unavailable — когда все серверы помечены как unhealthy и некому обрабатывать запрос. Разница: 502 — попытка связаться была, но неудачна; 503 — серверы недоступны по результатам health check. Оба кода означают временную проблему — клиент может retry.',
  },
  {
    id: 'sd-lb-038',
    block: 'sd',
    topic: 'load-balancing',
    topicLabel: 'Балансировка нагрузки',
    difficulty: 'middle',
    type: 'quiz',
    question: 'Что такое failover в контексте балансировки нагрузки?',
    options: [
      'Распределение нагрузки между серверами',
      'Автоматическое переключение на резервный сервер при отказе основного',
      'Отключение балансировщика при перегрузке',
      'Шифрование трафика при передаче',
    ],
    correctIndex: 1,
    explanation:
      'Failover — автоматическое переключение на резервный ресурс при отказе основного. В контексте балансировки: при отказе бэкенд-сервера трафик автоматически перенаправляется на здоровые серверы. На уровне самого балансировщика: при отказе active балансировщика passive (standby) берёт на себя его IP через VRRP. Failover обеспечивает высокую доступность (HA) системы.',
  },
  {
    id: 'sd-lb-039',
    block: 'sd',
    topic: 'load-balancing',
    topicLabel: 'Балансировка нагрузки',
    difficulty: 'middle',
    type: 'open',
    question: 'Как балансировщик нагрузки помогает реализовать A/B-тестирование и canary deployments?',
    sampleAnswer:
      'L7-балансировщик может маршрутизировать запросы на основе headers, cookies или процентного распределения: 1) A/B-тестирование — балансировщик проверяет cookie (ab_variant=B) или header и направляет пользователя на соответствующую версию. Если cookie нет — случайно назначает вариант и устанавливает cookie для консистентности. 2) Canary deployment — процентное распределение: 95% трафика на stable версию, 5% на canary. Постепенное увеличение доли при успешных метриках. 3) Feature flags через headers — приложение устанавливает header (X-Feature: new-checkout), балансировщик направляет на сервер с этой функцией. Инструменты: Nginx split_clients, HAProxy ACL, AWS ALB weighted target groups, Istio VirtualService, Envoy route matching.',
    explanation:
      'Балансировщик — удобное место для A/B и canary, потому что он видит весь трафик и может принимать решения централизованно. Однако сложные эксперименты лучше управлять через feature flag системы (LaunchDarkly, Split.io), которые дают больше гибкости.',
  },
  {
    id: 'sd-lb-040',
    block: 'sd',
    topic: 'load-balancing',
    topicLabel: 'Балансировка нагрузки',
    difficulty: 'middle',
    type: 'quiz',
    question: 'Какое преимущество даёт использование Envoy proxy перед традиционными балансировщиками?',
    options: [
      'Envoy проще в настройке, чем Nginx',
      'Envoy разработан для микросервисов: динамическая конфигурация, observability, поддержка service mesh',
      'Envoy работает только на L4-уровне',
      'Envoy не требует ресурсов для работы',
    ],
    correctIndex: 1,
    explanation:
      'Envoy — современный proxy, созданный Lyft для микросервисной архитектуры. Ключевые преимущества: 1) Динамическая конфигурация через xDS API — не нужен reload. 2) Встроенная observability — метрики (Prometheus), трейсинг (Jaeger, Zipkin), логи. 3) Поддержка современных протоколов — HTTP/2, gRPC, WebSocket из коробки. 4) Service mesh ready — основа для Istio, AWS App Mesh. 5) Advanced load balancing — zone-aware, locality, circuit breaking. Используется в Istio, Contour, Ambassador, AWS App Mesh.',
  },
  {
    id: 'sd-lb-041',
    block: 'sd',
    topic: 'load-balancing',
    topicLabel: 'Балансировка нагрузки',
    difficulty: 'senior',
    type: 'open',
    question: 'Как реализовать географическую балансировку нагрузки (Geo Load Balancing) для глобального приложения?',
    sampleAnswer:
      'Geo Load Balancing направляет пользователей в ближайший дата-центр: 1) GeoDNS — DNS-сервер определяет регион клиента по IP и возвращает IP ближайшего дата-центра. AWS Route53 Geolocation/Latency routing, Cloudflare. 2) Anycast — один IP объявляется из всех регионов, BGP маршрутизирует к ближайшему. 3) Global Load Balancer — Google Cloud Global LB, AWS Global Accelerator. Обеспечивают единую точку входа с автоматическим geo-routing. 4) CDN с origin shield — Cloudflare, CloudFront кэшируют контент на edge и направляют к ближайшему origin. Критерии маршрутизации: географическая близость, измеренная latency, стоимость трафика, compliance (данные EU в EU). Failover: при недоступности ближайшего региона — направление в следующий.',
    explanation:
      'Geo-балансировка критична для глобальных приложений: разница в latency между континентами — сотни миллисекунд. Google, Netflix используют комбинацию подходов: Anycast для DNS, Global LB для API, CDN для контента. Важно учитывать compliance: GDPR требует обработки данных EU в EU.',
  },
  {
    id: 'sd-lb-042',
    block: 'sd',
    topic: 'load-balancing',
    topicLabel: 'Балансировка нагрузки',
    difficulty: 'senior',
    type: 'quiz',
    question: 'Что такое locality-aware load balancing в Envoy/Istio?',
    options: [
      'Балансировка только между локальными серверами',
      'Приоритизация серверов в той же зоне/регионе для уменьшения latency и стоимости',
      'Балансировка на основе языка пользователя',
      'Распределение данных по географическим локациям',
    ],
    correctIndex: 1,
    explanation:
      'Locality-aware load balancing приоритизирует endpoints в том же zone/region, что и вызывающий сервис. Преимущества: 1) Меньше latency — нет cross-zone/region задержек. 2) Меньше стоимость — cross-AZ трафик в AWS платный. 3) Blast radius — проблемы в одной зоне не влияют на другие. Конфигурируется через приоритеты локальности и веса. При отказе локальных endpoints — failover на другие зоны. Envoy поддерживает locality weighting и priority levels.',
  },
  {
    id: 'sd-lb-043',
    block: 'sd',
    topic: 'load-balancing',
    topicLabel: 'Балансировка нагрузки',
    difficulty: 'senior',
    type: 'open',
    question: 'Объясните концепцию client-side load balancing и когда она предпочтительнее server-side.',
    sampleAnswer:
      'Client-side load balancing — клиент (вызывающий сервис) сам выбирает, на какой бэкенд отправить запрос, зная обо всех доступных инстансах. Как работает: 1) Service Discovery — клиент получает список endpoints из реестра (Consul, etcd, Kubernetes API). 2) Load Balancing — клиент применяет алгоритм (round robin, least connections) локально. 3) Health tracking — клиент отслеживает успешность запросов и исключает проблемные endpoints. Преимущества: нет single point of failure (балансировщика), меньше network hops, лучшая адаптивность (клиент знает о latency). Недостатки: сложность в клиенте, дублирование логики, сложнее обновлять алгоритмы. Реализации: gRPC client-side LB, Netflix Ribbon, Envoy sidecar (формально server-side, но рядом с клиентом). Предпочтительнее: внутренняя коммуникация в микросервисах, gRPC (проблемы с L4 LB), когда важна минимальная latency.',
    explanation:
      'Client-side LB vs centralized LB — architectural trade-off. Service mesh (Istio, Linkerd) — компромисс: балансировка выполняется sidecar-proxy рядом с клиентом, но логика централизованно управляется control plane. Это даёт преимущества обоих подходов.',
  },
  {
    id: 'sd-lb-044',
    block: 'sd',
    topic: 'load-balancing',
    topicLabel: 'Балансировка нагрузки',
    difficulty: 'junior',
    type: 'quiz',
    question: 'Что произойдёт, если использовать алгоритм Round Robin для серверов с разной производительностью?',
    options: [
      'Нагрузка автоматически выровняется',
      'Медленные серверы будут перегружены, а быстрые — недогружены',
      'Балансировщик автоматически исключит медленные серверы',
      'Алгоритм адаптируется к производительности серверов',
    ],
    correctIndex: 1,
    explanation:
      'Round Robin распределяет запросы равномерно, не учитывая производительность серверов. Если один сервер обрабатывает запросы в 2 раза медленнее, он будет накапливать очередь и перегружаться, в то время как быстрый сервер будет простаивать. Решения: Weighted Round Robin (задать веса вручную), Least Connections (автоматически направляет меньше запросов на загруженные серверы), Least Response Time (учитывает время ответа).',
  },
  {
    id: 'sd-lb-045',
    block: 'sd',
    topic: 'load-balancing',
    topicLabel: 'Балансировка нагрузки',
    difficulty: 'middle',
    type: 'quiz',
    question: 'Какой компонент Kubernetes отвечает за L4-балансировку трафика к сервисам?',
    options: [
      'Ingress Controller',
      'kube-proxy',
      'kubelet',
      'etcd',
    ],
    correctIndex: 1,
    explanation:
      'kube-proxy — компонент, работающий на каждом узле Kubernetes, который реализует L4-балансировку для Services. Он настраивает правила iptables или IPVS для перенаправления трафика к ClusterIP на реальные pod IP. Режимы: iptables (по умолчанию) — цепочки правил для NAT; IPVS — более производительный, поддерживает больше алгоритмов балансировки. Ingress Controller — L7-балансировка для HTTP.',
  },
  {
    id: 'sd-lb-046',
    block: 'sd',
    topic: 'load-balancing',
    topicLabel: 'Балансировка нагрузки',
    difficulty: 'middle',
    type: 'open',
    question: 'Как настроить rate limiting на балансировщике нагрузки и зачем это нужно?',
    sampleAnswer:
      'Rate limiting на балансировщике ограничивает количество запросов от клиента за период времени. Зачем: 1) Защита от DDoS и злоупотреблений. 2) Fair usage — один клиент не может забрать все ресурсы. 3) Защита бэкендов от перегрузки. 4) Соблюдение SLA и квот API. Реализация в Nginx: limit_req_zone по IP или API key, limit_req в location. В HAProxy: stick-table для трекинга, http-request deny при превышении. В AWS ALB: правила WAF. Конфигурация: rate (запросов в секунду), burst (допустимый всплеск), действие при превышении (429 Too Many Requests, delay, drop). Важно: rate limiting по IP неэффективен за NAT; лучше по API key или user ID.',
    explanation:
      'Rate limiting — важная часть API Gateway функциональности. Часто комбинируется с throttling (замедление вместо отказа) и quota management (лимиты за день/месяц). Для распределённого rate limiting (несколько балансировщиков) используется Redis для хранения счётчиков.',
  },
  {
    id: 'sd-lb-047',
    block: 'sd',
    topic: 'load-balancing',
    topicLabel: 'Балансировка нагрузки',
    difficulty: 'senior',
    type: 'quiz',
    question: 'Что такое Direct Server Return (DSR) в балансировке нагрузки?',
    options: [
      'Прямое соединение между клиентом и сервером без балансировщика',
      'Ответ сервера идёт напрямую клиенту, минуя балансировщик',
      'Автоматический restart сервера при сбое',
      'Резервное копирование данных на сервере',
    ],
    correctIndex: 1,
    explanation:
      'Direct Server Return (DSR) — техника L4-балансировки, при которой запрос идёт через балансировщик, но ответ сервер отправляет напрямую клиенту, минуя балансировщик. Преимущества: разгрузка балансировщика (обычно ответ больше запроса), меньше latency на response path. Требования: серверы должны иметь VIP на loopback (не отвечать на ARP), работает только для L4, не работает для NAT/SNAT. Используется для high-throughput сценариев: стриминг видео, передача больших файлов.',
  },
  {
    id: 'sd-lb-048',
    block: 'sd',
    topic: 'load-balancing',
    topicLabel: 'Балансировка нагрузки',
    difficulty: 'senior',
    type: 'open',
    question: 'Как обеспечить zero-downtime при обновлении самого балансировщика нагрузки?',
    sampleAnswer:
      'Обновление балансировщика без простоя: 1) Active-Passive с VRRP — обновить passive, переключить VIP, обновить бывший active. Keepalived для Linux. 2) Active-Active с DNS — несколько A-записей, убрать обновляемый из DNS, дождаться TTL, обновить, вернуть в DNS. 3) Rolling update в Kubernetes — Ingress Controller как Deployment с несколькими репликами. При обновлении создаётся новый pod, затем удаляется старый. 4) Blue-Green балансировщиков — две группы LB, переключение через глобальный LB или DNS. 5) Graceful reload — Nginx: nginx -s reload создаёт новые worker-процессы, старые обслуживают существующие соединения до завершения. HAProxy: hot reload через systemd или socket. 6) Облачные LB — AWS ALB обновляются автоматически AWS без даунтайма.',
    explanation:
      'Балансировщик — критический компонент. Его даунтайм = даунтайм всего сервиса. Облачные managed балансировщики (ALB, GCP LB) упрощают эту задачу — провайдер обеспечивает обновления. Для self-managed важно иметь HA-пару и отработанную процедуру failover.',
  },
  {
    id: 'sd-lb-049',
    block: 'sd',
    topic: 'load-balancing',
    topicLabel: 'Балансировка нагрузки',
    difficulty: 'junior',
    type: 'open',
    question: 'Какие метрики важно мониторить на балансировщике нагрузки?',
    sampleAnswer:
      'Ключевые метрики балансировщика: 1) Request rate — количество запросов в секунду (общее и per backend). 2) Latency — время обработки запроса (p50, p95, p99); отдельно время балансировщика и backend response time. 3) Error rate — процент 4xx и 5xx ответов; 502/503 указывают на проблемы с бэкендами. 4) Active connections — текущее количество соединений; приближение к лимиту — проблема. 5) Backend health — количество healthy/unhealthy серверов. 6) Bandwidth — входящий и исходящий трафик. 7) Queue depth — если балансировщик имеет очередь ожидания. 8) SSL handshake time — для HTTPS-терминации. 9) Connection reuse rate — эффективность keep-alive. Алертинг: error rate > 1%, p99 latency > SLA, healthy backends < minimum.',
    explanation:
      'Мониторинг балансировщика даёт первое представление о здоровье системы. Рост latency или error rate на LB — первый симптом проблем. Инструменты: встроенные метрики (HAProxy stats, Nginx status), экспорт в Prometheus, облачные CloudWatch/Stackdriver.',
  },
  {
    id: 'sd-lb-050',
    block: 'sd',
    topic: 'load-balancing',
    topicLabel: 'Балансировка нагрузки',
    difficulty: 'senior',
    type: 'quiz',
    question: 'Какой алгоритм балансировки рекомендуется для stateless REST API с однородными серверами?',
    options: [
      'IP Hash — для сохранения сессий',
      'Least Connections — для длительных соединений',
      'Round Robin — простой и эффективный для равномерной нагрузки',
      'Random — для максимальной непредсказуемости',
    ],
    correctIndex: 2,
    explanation:
      'Для stateless REST API с однородными серверами Round Robin — оптимальный выбор. Преимущества: простота, предсказуемость, равномерное распределение, минимальные накладные расходы. Не нужен: IP Hash (нет сессий), Least Connections (запросы короткие, connections не накапливаются). Least Connections лучше для WebSocket или длительных запросов. При разной производительности серверов — Weighted Round Robin или Least Response Time.',
  },
];
