import type { Question } from '../types';

export const loadBalancingQuestions: Question[] = [
  {
    id: 'sd-lb-001',
    block: 'sd',
    topic: 'load-balancing',
    topicLabel: 'Балансировка нагрузки',
    difficulty: 'junior',
    type: 'quiz',
    question: 'Какова основная задача балансировщика нагрузки (Load Balancer)?',
    options: [
      'Шифрование трафика между клиентом и сервером',
      'Распределение входящих запросов между несколькими серверами',
      'Кэширование ответов для ускорения отклика',
      'Мониторинг состояния здоровья серверов',
    ],
    correctIndex: 1,
    explanation:
      'Основная задача балансировщика нагрузки -- распределение входящего сетевого трафика между несколькими серверами (бэкендами). Это позволяет увеличить пропускную способность системы, обеспечить высокую доступность и отказоустойчивость. Хотя балансировщики часто выполняют и дополнительные функции (SSL-терминация, health-checks, кэширование), распределение нагрузки -- их первичная задача.',
  },
  {
    id: 'sd-lb-002',
    block: 'sd',
    topic: 'load-balancing',
    topicLabel: 'Балансировка нагрузки',
    difficulty: 'middle',
    type: 'quiz',
    question: 'Какой алгоритм балансировки нагрузки лучше всего подходит для серверов с разной производительностью?',
    options: [
      'Round Robin -- запросы распределяются по кругу',
      'Weighted Round Robin -- запросы распределяются с учётом весов серверов',
      'Random -- запросы направляются на случайный сервер',
      'IP Hash -- сервер выбирается на основе хэша IP-адреса клиента',
    ],
    correctIndex: 1,
    explanation:
      'Weighted Round Robin назначает каждому серверу вес, пропорциональный его производительности. Сервер с весом 3 получит в три раза больше запросов, чем сервер с весом 1. Это позволяет эффективно использовать гетерогенную инфраструктуру, где серверы имеют разные характеристики CPU, RAM и производительности. Обычный Round Robin распределяет нагрузку равномерно и не учитывает различия в мощности серверов.',
  },
  {
    id: 'sd-lb-003',
    block: 'sd',
    topic: 'load-balancing',
    topicLabel: 'Балансировка нагрузки',
    difficulty: 'middle',
    type: 'open',
    question: 'Объясните разницу между балансировкой нагрузки на уровне L4 и L7 модели OSI. В каких сценариях предпочтительнее каждый из вариантов?',
    sampleAnswer:
      'L4 (транспортный уровень) балансировка работает на уровне TCP/UDP: решение о маршрутизации принимается на основе IP-адреса и порта без анализа содержимого запроса. Она быстрее, потребляет меньше ресурсов и подходит для высоконагруженных сценариев, где не нужна маршрутизация на основе содержимого. L7 (уровень приложения) балансировка анализирует содержимое HTTP-запроса: URL, заголовки, куки. Она позволяет маршрутизировать запросы на основе пути (/api на один бэкенд, /static на другой), делать content-based routing, SSL-терминацию, модификацию заголовков. L4 предпочтителен для протоколов, отличных от HTTP, и для максимальной производительности. L7 -- для веб-приложений, где нужна гибкая маршрутизация, A/B-тестирование, канареечные деплои.',
    explanation:
      'Выбор между L4 и L7 балансировкой -- это компромисс между производительностью и функциональностью. На практике часто используют оба уровня: L4 на внешнем периметре для распределения трафика между кластерами, L7 внутри кластера для интеллектуальной маршрутизации. Примеры L4: AWS NLB, HAProxy в режиме TCP. Примеры L7: Nginx, HAProxy в режиме HTTP, AWS ALB, Envoy.',
  },
  {
    id: 'sd-lb-004',
    block: 'sd',
    topic: 'load-balancing',
    topicLabel: 'Балансировка нагрузки',
    difficulty: 'senior',
    type: 'open',
    question: 'Как обеспечить высокую доступность самого балансировщика нагрузки? Что произойдёт, если балансировщик выйдет из строя?',
    sampleAnswer:
      'Балансировщик нагрузки сам может стать единой точкой отказа (SPOF), поэтому необходимо обеспечить его отказоустойчивость. Основные подходы: 1) Active-Passive (горячий резерв): два балансировщика, один активный, второй в режиме ожидания. Используется протокол VRRP (Virtual Router Redundancy Protocol) для автоматического переключения виртуального IP (VIP) при отказе активного узла. Время переключения -- несколько секунд. 2) Active-Active: несколько балансировщиков работают одновременно, трафик распределяется между ними через DNS Round Robin или Anycast. Обеспечивает лучшее использование ресурсов. 3) DNS-based failover: несколько A-записей указывают на разные балансировщики, при отказе одного DNS обновляется (но TTL может замедлить переключение). 4) Облачные решения (AWS ELB, GCP LB): провайдер автоматически обеспечивает отказоустойчивость.',
    explanation:
      'На практике для критически важных систем используется комбинация подходов. Например, Anycast DNS направляет трафик на ближайший кластер, внутри кластера Active-Passive пара балансировщиков обрабатывает трафик. Важно проводить регулярные учения (chaos engineering) по отказу балансировщиков, чтобы убедиться в корректности переключения.',
  },
  {
    id: 'sd-lb-005',
    block: 'sd',
    topic: 'load-balancing',
    topicLabel: 'Балансировка нагрузки',
    difficulty: 'junior',
    type: 'quiz',
    question: 'Что такое health check в контексте балансировки нагрузки?',
    options: [
      'Проверка SSL-сертификата сервера',
      'Периодическая проверка доступности и работоспособности серверов за балансировщиком',
      'Анализ нагрузки на CPU и память серверов',
      'Проверка корректности HTTP-ответов на стороне клиента',
    ],
    correctIndex: 1,
    explanation:
      'Health check -- это механизм, с помощью которого балансировщик нагрузки периодически проверяет доступность и работоспособность бэкенд-серверов. Обычно это HTTP-запрос на специальный endpoint (например, /health), TCP-проверка соединения или выполнение скрипта. Если сервер не отвечает или отвечает с ошибкой, балансировщик перестаёт направлять на него трафик до восстановления. Это ключевой механизм обеспечения высокой доступности.',
  },
  {
    id: 'sd-lb-006',
    block: 'sd',
    topic: 'load-balancing',
    topicLabel: 'Балансировка нагрузки',
    difficulty: 'junior',
    type: 'quiz',
    question: 'Что такое sticky sessions (привязка сессий) в контексте балансировки нагрузки?',
    options: [
      'Механизм шифрования сессионных данных',
      'Привязка клиента к одному и тому же серверу на протяжении всей сессии',
      'Автоматическое продление времени жизни сессии',
      'Копирование сессии на все серверы кластера',
    ],
    correctIndex: 1,
    explanation:
      'Sticky sessions (session affinity) — это механизм, при котором балансировщик нагрузки направляет все запросы одного клиента на один и тот же бэкенд-сервер. Реализуется через cookie (балансировщик добавляет cookie с идентификатором сервера) или по IP-адресу клиента. Sticky sessions необходимы, когда приложение хранит состояние сессии в памяти сервера. Однако они создают неравномерную нагрузку и затрудняют масштабирование. Лучшая альтернатива — вынести состояние сессии в внешнее хранилище (Redis) и использовать stateless-серверы.',
  },
  {
    id: 'sd-lb-007',
    block: 'sd',
    topic: 'load-balancing',
    topicLabel: 'Балансировка нагрузки',
    difficulty: 'junior',
    type: 'quiz',
    question: 'Какой алгоритм балансировки направляет каждый новый запрос на сервер с наименьшим количеством активных соединений?',
    options: [
      'Round Robin',
      'Weighted Round Robin',
      'Least Connections',
      'IP Hash',
    ],
    correctIndex: 2,
    explanation:
      'Least Connections — алгоритм балансировки, который направляет новый запрос на сервер с наименьшим количеством текущих активных соединений. Он лучше, чем Round Robin, когда запросы имеют разную длительность обработки: сервер с долгими запросами будет получать меньше новых. Это особенно полезно для WebSocket-соединений и длительных операций. Существует также вариант Weighted Least Connections, учитывающий производительность серверов.',
  },
  {
    id: 'sd-lb-008',
    block: 'sd',
    topic: 'load-balancing',
    topicLabel: 'Балансировка нагрузки',
    difficulty: 'junior',
    type: 'quiz',
    question: 'Что такое DNS-based балансировка нагрузки?',
    options: [
      'Шифрование DNS-запросов для защиты от атак',
      'Распределение трафика между серверами путём возврата разных IP-адресов в DNS-ответах',
      'Кэширование DNS-записей на стороне балансировщика',
      'Использование DNS для мониторинга здоровья серверов',
    ],
    correctIndex: 1,
    explanation:
      'DNS-based балансировка работает на уровне DNS-резолвинга: DNS-сервер возвращает разные IP-адреса (A-записи) для одного доменного имени, распределяя клиентов между серверами. Простейшая реализация — DNS Round Robin (несколько A-записей ротируются). Более продвинутые решения (Route53, Cloudflare) учитывают географию клиента, здоровье серверов и нагрузку. Недостаток — DNS-кэширование (TTL) замедляет реакцию на отказы.',
  },
  {
    id: 'sd-lb-009',
    block: 'sd',
    topic: 'load-balancing',
    topicLabel: 'Балансировка нагрузки',
    difficulty: 'middle',
    type: 'quiz',
    question: 'Что такое connection draining (deregistration delay) в балансировке нагрузки?',
    options: [
      'Удаление всех соединений при перезагрузке балансировщика',
      'Завершение существующих соединений перед выводом сервера из обслуживания, без приёма новых запросов',
      'Ограничение максимального количества соединений на один сервер',
      'Перенаправление соединений с медленного сервера на быстрый',
    ],
    correctIndex: 1,
    explanation:
      'Connection draining — механизм плавного вывода сервера из обслуживания. Когда сервер помечается для вывода (при деплое, масштабировании вниз или по результатам health check), балансировщик перестаёт направлять на него новые запросы, но даёт время завершить обработку текущих. Обычно настраивается таймаут (например, 30 секунд), после которого оставшиеся соединения принудительно закрываются. Это предотвращает ошибки у клиентов при обновлении или обслуживании серверов.',
  },
  {
    id: 'sd-lb-010',
    block: 'sd',
    topic: 'load-balancing',
    topicLabel: 'Балансировка нагрузки',
    difficulty: 'middle',
    type: 'quiz',
    question: 'Какое основное преимущество L7-балансировщика нагрузки перед L4 при развёртывании микросервисов?',
    options: [
      'Более высокая пропускная способность',
      'Меньшее потребление ресурсов',
      'Возможность маршрутизации запросов на основе URL-пути, заголовков и содержимого запроса',
      'Отсутствие необходимости в SSL-сертификатах',
    ],
    correctIndex: 2,
    explanation:
      'L7-балансировщик анализирует содержимое HTTP-запроса и может маршрутизировать на основе URL-пути (/api/users → user-service, /api/orders → order-service), заголовков (A/B-тестирование по cookie), метода запроса, и даже тела запроса. Это критически важно для микросервисной архитектуры, где один входной URL должен быть направлен на разные сервисы. L4-балансировщик видит только IP и порт и не может выполнять content-based routing.',
  },
  {
    id: 'sd-lb-011',
    block: 'sd',
    topic: 'load-balancing',
    topicLabel: 'Балансировка нагрузки',
    difficulty: 'middle',
    type: 'open',
    question: 'Сравните HAProxy и Nginx в роли балансировщиков нагрузки. Каковы ключевые различия и сценарии использования каждого?',
    sampleAnswer:
      'HAProxy — специализированный балансировщик нагрузки и прокси, изначально спроектированный для этой задачи. Преимущества: высокая производительность, детальная конфигурация балансировки (множество алгоритмов, health checks, ACL), поддержка L4 и L7, runtime API для управления, отличный мониторинг (stats page). Nginx — веб-сервер и reverse proxy с функцией балансировки нагрузки. Преимущества: может одновременно раздавать статику, выполнять SSL-терминацию, кэширование, сжатие, rate limiting, поддержка HTTP/2 и gRPC, Lua-скриптинг для кастомной логики. Различия: HAProxy лучше для чистой балансировки нагрузки с продвинутыми health checks и session persistence. Nginx лучше как универсальный reverse proxy, совмещающий балансировку со статикой и кэшированием. На практике часто используют Nginx как edge-прокси (SSL-терминация, статика) и HAProxy для внутренней балансировки между сервисами.',
    explanation:
      'Оба инструмента широко используются и имеют зрелую экосистему. В мире Kubernetes Nginx часто встречается как Ingress Controller (nginx-ingress), а HAProxy — как альтернативный ingress. Envoy Proxy набирает популярность как современная альтернатива обоим, особенно в service mesh архитектурах (Istio).',
  },
  {
    id: 'sd-lb-012',
    block: 'sd',
    topic: 'load-balancing',
    topicLabel: 'Балансировка нагрузки',
    difficulty: 'middle',
    type: 'quiz',
    question: 'Что такое Global Server Load Balancing (GSLB)?',
    options: [
      'Балансировка нагрузки внутри одного дата-центра',
      'Распределение трафика между несколькими географически распределёнными дата-центрами',
      'Ограничение нагрузки на глобальном уровне через rate limiting',
      'Балансировка запросов к глобальной базе данных',
    ],
    correctIndex: 1,
    explanation:
      'GSLB (Global Server Load Balancing) — это распределение трафика между несколькими дата-центрами или регионами. Реализуется обычно через DNS-based routing (AWS Route53, Cloudflare) с учётом: географической близости клиента (geo-routing), здоровья дата-центров (failover), нагрузки на каждый дата-центр. GSLB обеспечивает минимальную задержку для пользователей по всему миру и отказоустойчивость на уровне целых регионов. Технологии: Anycast, GeoDNS, latency-based routing.',
  },
  {
    id: 'sd-lb-013',
    block: 'sd',
    topic: 'load-balancing',
    topicLabel: 'Балансировка нагрузки',
    difficulty: 'senior',
    type: 'open',
    question: 'Опишите, как реализовать zero-downtime deployment с использованием балансировщика нагрузки. Какие стратегии деплоя существуют?',
    sampleAnswer:
      'Zero-downtime deployment — обновление приложения без прерывания обслуживания пользователей. Стратегии с использованием балансировщика нагрузки: 1) Rolling deployment: серверы обновляются по одному. Балансировщик выводит сервер из ротации (connection draining), обновляет его, проверяет health check и возвращает в ротацию. 2) Blue-Green deployment: две идентичные среды (blue — текущая, green — новая). После деплоя на green и проверки, балансировщик переключает весь трафик с blue на green. Откат мгновенный — переключение обратно. 3) Canary deployment: новая версия деплоится на малую часть серверов (1-5%). Балансировщик направляет на них часть трафика. При успешных метриках доля постепенно увеличивается до 100%. 4) Feature flags: не меняя инфраструктуру, новый код активируется для части пользователей через флаги. Все стратегии требуют обратной совместимости API и схемы БД между версиями.',
    explanation:
      'На практике выбор стратегии зависит от рисков и скорости отката. Blue-Green даёт мгновенный откат, но требует двойных ресурсов. Canary минимизирует blast radius, но усложняет мониторинг. Rolling — самый экономичный, но откат медленнее. Kubernetes нативно поддерживает Rolling и, через Istio/Argo Rollouts, Canary и Blue-Green деплои.',
  },
  {
    id: 'sd-lb-014',
    block: 'sd',
    topic: 'load-balancing',
    topicLabel: 'Балансировка нагрузки',
    difficulty: 'senior',
    type: 'quiz',
    question: 'Какой алгоритм балансировки нагрузки используется, когда необходимо минимизировать время отклика?',
    options: [
      'Round Robin',
      'Random',
      'Least Response Time (наименьшее время отклика)',
      'Source IP Hash',
    ],
    correctIndex: 2,
    explanation:
      'Least Response Time — алгоритм, который направляет запрос на сервер с наименьшим текущим временем отклика и минимальным количеством активных соединений. Он учитывает не только количество соединений (как Least Connections), но и реальную скорость ответа сервера. Это позволяет автоматически перенаправлять трафик от деградирующих серверов. Реализован в Nginx (least_time), HAProxy (leastconn с observe-layer) и AWS ALB. Недостаток — необходимость постоянного измерения задержки, что добавляет накладные расходы.',
  },
  {
    id: 'sd-lb-015',
    block: 'sd',
    topic: 'load-balancing',
    topicLabel: 'Балансировка нагрузки',
    difficulty: 'senior',
    type: 'open',
    question: 'Что такое Service Mesh и как он связан с балансировкой нагрузки в микросервисной архитектуре? Приведите примеры реализаций.',
    sampleAnswer:
      'Service Mesh — это инфраструктурный слой для управления коммуникацией между микросервисами. Каждый сервис получает sidecar-прокси (обычно Envoy), который перехватывает весь входящий и исходящий трафик. Service Mesh берёт на себя: 1) Client-side load balancing — sidecar знает обо всех экземплярах целевого сервиса и балансирует между ними. 2) Service discovery — автоматическое обнаружение новых экземпляров. 3) Circuit breaking — защита от каскадных отказов. 4) Retry/timeout — автоматические повторы и таймауты. 5) mTLS — взаимная аутентификация и шифрование трафика. 6) Observability — метрики, трассировка, логирование. Примеры: Istio (на базе Envoy), Linkerd, Consul Connect. Service Mesh переносит логику балансировки и resilience из кода приложения в инфраструктуру, упрощая разработку, но усложняя операционную часть.',
    explanation:
      'Service Mesh стал стандартом де-факто для крупных микросервисных архитектур в Kubernetes. Однако он добавляет операционную сложность и накладные расходы (дополнительный hop через sidecar, потребление ресурсов). Для небольших систем (до 10-20 сервисов) обычно достаточно простого Kubernetes Service с kube-proxy.',
  },
  {
    id: 'sd-lb-016',
    block: 'sd',
    topic: 'load-balancing',
    topicLabel: 'Балансировка нагрузки',
    difficulty: 'junior',
    type: 'quiz',
    question: 'Где обычно размещается балансировщик нагрузки в архитектуре веб-приложения?',
    options: [
      'За серверами приложений, перед базой данных',
      'Между клиентами (пользователями) и серверами приложений',
      'Между базой данных и кэшем',
      'На стороне клиента в браузере',
    ],
    correctIndex: 1,
    explanation:
      'Балансировщик нагрузки обычно размещается между клиентами и серверами приложений, принимая весь входящий трафик и распределяя его по бэкендам. В сложных архитектурах используются несколько уровней балансировки: 1) DNS-уровень — между пользователями и дата-центрами. 2) L4-балансировщик — на входе в дата-центр. 3) L7-балансировщик — перед серверами приложений. 4) Внутренний балансировщик — между микросервисами.',
  },
  {
    id: 'sd-lb-017',
    block: 'sd',
    topic: 'load-balancing',
    topicLabel: 'Балансировка нагрузки',
    difficulty: 'middle',
    type: 'open',
    question: 'Какие типы health checks существуют и как выбрать правильный для вашего сервиса?',
    sampleAnswer:
      'Типы health checks: 1) TCP check — проверяет, открыт ли порт. Самый простой, но не проверяет работоспособность приложения. 2) HTTP check — отправляет HTTP-запрос на endpoint (обычно /health или /healthz) и проверяет код ответа (200 OK). 3) Deep health check (readiness) — проверяет не только приложение, но и его зависимости (БД, кэш, внешние API). Возвращает детальный статус. 4) Shallow health check (liveness) — проверяет, что процесс приложения жив и может обрабатывать запросы, без проверки зависимостей. Выбор зависит от сценария: для балансировщика нагрузки лучше shallow check — если БД недоступна, нет смысла выводить все серверы из ротации. Deep check полезен для мониторинга и алертинга. В Kubernetes liveness probe определяет, нужно ли перезапустить pod, readiness probe — можно ли направлять на него трафик.',
    explanation:
      'Правильная настройка health checks критична: слишком строгие — вызовут ложные срабатывания и каскадное отключение серверов; слишком мягкие — будут направлять трафик на неработающие серверы. Важные параметры: interval (как часто проверять), timeout (сколько ждать ответа), threshold (сколько неудачных проверок до вывода из ротации).',
  },
  {
    id: 'sd-lb-018',
    block: 'sd',
    topic: 'load-balancing',
    topicLabel: 'Балансировка нагрузки',
    difficulty: 'senior',
    type: 'quiz',
    question: 'Что такое Consistent Hashing в контексте балансировки нагрузки и зачем он нужен?',
    options: [
      'Алгоритм шифрования для защиты трафика',
      'Метод распределения запросов, минимизирующий перераспределение при добавлении/удалении серверов',
      'Способ проверки целостности данных при передаче',
      'Алгоритм сжатия HTTP-запросов',
    ],
    correctIndex: 1,
    explanation:
      'Consistent Hashing в балансировке нагрузки используется для привязки определённых запросов (например, по ключу кэша или ID пользователя) к конкретным серверам. При добавлении или удалении сервера перераспределяется только ~1/N часть запросов, а не все. Это особенно важно при балансировке перед распределённым кэшем: минимизируется количество cache miss при изменении топологии. Используется в Nginx (hash upstream), HAProxy, а также в Memcached и Redis Cluster.',
  },
  {
    id: 'sd-lb-019',
    block: 'sd',
    topic: 'load-balancing',
    topicLabel: 'Балансировка нагрузки',
    difficulty: 'middle',
    type: 'quiz',
    question: 'Что такое SSL/TLS-терминация на балансировщике нагрузки?',
    options: [
      'Шифрование трафика между балансировщиком и бэкенд-серверами',
      'Расшифровка HTTPS-трафика на балансировщике, передача незашифрованного HTTP на бэкенды',
      'Генерация SSL-сертификатов на лету',
      'Блокировка незашифрованного HTTP-трафика',
    ],
    correctIndex: 1,
    explanation:
      'SSL/TLS-терминация — это процесс, при котором балансировщик нагрузки расшифровывает входящий HTTPS-трафик и передаёт запросы бэкенд-серверам по обычному HTTP. Преимущества: снимает нагрузку по шифрованию/дешифрованию с серверов приложений, централизованное управление сертификатами, L7-балансировщик может анализировать содержимое запроса. Для повышения безопасности можно использовать SSL re-encryption — повторное шифрование трафика между балансировщиком и бэкендами (но это добавляет накладные расходы).',
  },
  {
    id: 'sd-lb-020',
    block: 'sd',
    topic: 'load-balancing',
    topicLabel: 'Балансировка нагрузки',
    difficulty: 'senior',
    type: 'open',
    question: 'Объясните концепцию «Power of Two Random Choices» в балансировке нагрузки. Почему она может быть лучше, чем Round Robin или Least Connections?',
    sampleAnswer:
      'Power of Two Random Choices — алгоритм балансировки, при котором для каждого запроса случайным образом выбираются два сервера, и запрос направляется на менее загруженный из них. Несмотря на простоту, этот алгоритм обеспечивает экспоненциально лучшее распределение нагрузки по сравнению с чисто случайным выбором. Преимущества: 1) Не требует глобального знания о состоянии всех серверов (в отличие от Least Connections, который должен отслеживать все соединения). 2) Работает в распределённых системах без центрального координатора. 3) Устойчив к устаревшей информации о нагрузке (race conditions). 4) Автоматически избегает перегруженных серверов. Недостатки по сравнению с Least Connections: немного менее оптимальное распределение, но значительно проще в реализации для распределённых систем. Используется в Envoy proxy, Netflix Ribbon, и описан в работах Michael Mitzenmacher.',
    explanation:
      'Power of Two Random Choices — классический пример того, как небольшое изменение алгоритма (выбрать из двух случайных вместо одного) даёт значительное улучшение. Математически доказано, что максимальная нагрузка на сервер снижается с O(log n / log log n) до O(log log n). Этот принцип применяется не только в балансировке, но и в хэш-таблицах (cuckoo hashing) и других распределённых алгоритмах.',
  },
];
