import type { Question } from '../types';

export const messageQueuesQuestions: Question[] = [
  {
    id: 'sd-mq-001',
    block: 'sd',
    topic: 'message-queues',
    topicLabel: 'Очереди сообщений',
    difficulty: 'junior',
    type: 'quiz',
    question: 'Какую основную проблему решают очереди сообщений в распределённых системах?',
    options: [
      'Шифрование данных при передаче между сервисами',
      'Асинхронная коммуникация между сервисами и развязка (decoupling) компонентов',
      'Хранение постоянных данных вместо базы данных',
      'Балансировка нагрузки между серверами',
    ],
    correctIndex: 1,
    explanation:
      'Очереди сообщений (Message Queues) позволяют сервисам обмениваться данными асинхронно: отправитель помещает сообщение в очередь и продолжает работу, не дожидаясь обработки. Это обеспечивает decoupling (развязку) -- сервисы не зависят друг от друга напрямую, что повышает отказоустойчивость и масштабируемость. Также очереди сглаживают пики нагрузки (load leveling): при всплеске запросов сообщения накапливаются в очереди и обрабатываются по мере доступности ресурсов.',
  },
  {
    id: 'sd-mq-002',
    block: 'sd',
    topic: 'message-queues',
    topicLabel: 'Очереди сообщений',
    difficulty: 'middle',
    type: 'quiz',
    question: 'Чем отличается модель «очередь» (Point-to-Point) от модели «публикация-подписка» (Pub/Sub)?',
    options: [
      'В очереди сообщение обрабатывается одним потребителем, в Pub/Sub -- доставляется всем подписчикам',
      'Очередь работает синхронно, Pub/Sub -- асинхронно',
      'Pub/Sub гарантирует порядок сообщений, а очередь -- нет',
      'В очереди нельзя фильтровать сообщения, а в Pub/Sub -- можно',
    ],
    correctIndex: 0,
    explanation:
      'В модели Point-to-Point (очередь) каждое сообщение обрабатывается ровно одним потребителем (consumer). Это подходит для распределения задач: например, обработка заказов, где каждый заказ должен быть обработан один раз. В модели Pub/Sub (публикация-подписка) сообщение доставляется всем подписчикам (subscribers) топика. Это подходит для рассылки событий: например, событие «заказ создан» может получить сервис уведомлений, сервис аналитики и сервис складского учёта.',
  },
  {
    id: 'sd-mq-003',
    block: 'sd',
    topic: 'message-queues',
    topicLabel: 'Очереди сообщений',
    difficulty: 'middle',
    type: 'open',
    question: 'Сравните Apache Kafka и RabbitMQ. В каких сценариях каждый из них предпочтительнее?',
    sampleAnswer:
      'Apache Kafka -- это распределённая платформа потоковой обработки с лог-архитектурой. Сообщения хранятся на диске в упорядоченных логах, потребители читают по смещению (offset). Kafka оптимальна для: потоковой обработки данных, event sourcing, лог-агрегации, высокой пропускной способности (миллионы сообщений/сек), когда нужно хранить историю сообщений и повторно их читать. RabbitMQ -- классический брокер сообщений с поддержкой протокола AMQP. Он обеспечивает гибкую маршрутизацию через exchange (direct, topic, fanout, headers), подтверждение доставки, TTL и dead-letter очереди. RabbitMQ лучше для: традиционных очередей задач, сложной маршрутизации сообщений, когда нужны приоритеты сообщений, когда объём данных умеренный и каждое сообщение обрабатывается один раз.',
    explanation:
      'Kafka и RabbitMQ решают разные задачи, хотя области применения частично пересекаются. Ключевое архитектурное различие: в Kafka потребители управляют своим смещением (pull-модель), в RabbitMQ брокер отправляет сообщения потребителям (push-модель). Kafka лучше подходит для больших данных и потоковой обработки, RabbitMQ -- для микросервисной коммуникации и task queues.',
  },
  {
    id: 'sd-mq-004',
    block: 'sd',
    topic: 'message-queues',
    topicLabel: 'Очереди сообщений',
    difficulty: 'senior',
    type: 'open',
    question: 'Что такое гарантии доставки сообщений (delivery guarantees)? Объясните разницу между at-most-once, at-least-once и exactly-once. Почему exactly-once так сложно реализовать?',
    sampleAnswer:
      'At-most-once: сообщение доставляется не более одного раза. Отправитель не повторяет отправку при ошибке, возможна потеря сообщений. Самая простая и быстрая реализация. Подходит для не критичных данных (метрики, логи). At-least-once: сообщение доставляется хотя бы один раз. Отправитель повторяет отправку до получения подтверждения, возможны дубликаты. Потребитель должен быть идемпотентным. Наиболее распространённая гарантия. Exactly-once: сообщение доставляется ровно один раз. Сложно реализовать, потому что в распределённой системе невозможно атомарно выполнить «получить сообщение + обработать + подтвердить». Любой шаг может упасть. Реализуется через комбинацию: идемпотентный продюсер (Kafka с идемпотентностью), транзакции (Kafka Transactions), дедупликацию на стороне потребителя (по уникальному ID сообщения). На практике «exactly-once» часто означает «at-least-once delivery + idempotent processing».',
    explanation:
      'Exactly-once semantics -- это «святой Грааль» распределённых систем. Теоретически она невозможна в общем случае (по сути, это задача двух генералов). На практике системы вроде Apache Kafka обеспечивают exactly-once в пределах своей экосистемы (Kafka Streams, Kafka Connect), но при взаимодействии с внешними системами приходится полагаться на идемпотентность операций.',
  },
  {
    id: 'sd-mq-005',
    block: 'sd',
    topic: 'message-queues',
    topicLabel: 'Очереди сообщений',
    difficulty: 'junior',
    type: 'quiz',
    question: 'Что такое Dead Letter Queue (DLQ)?',
    options: [
      'Очередь для хранения зашифрованных сообщений',
      'Специальная очередь для сообщений, которые не удалось обработать после нескольких попыток',
      'Очередь с максимальным приоритетом обработки',
      'Временная очередь, удаляемая после обработки всех сообщений',
    ],
    correctIndex: 1,
    explanation:
      'Dead Letter Queue (DLQ) -- это специальная очередь, куда перенаправляются сообщения, которые не удалось успешно обработать после заданного количества попыток. Причины попадания в DLQ: ошибки десериализации, бизнес-валидации, недоступность зависимых сервисов. DLQ позволяет не потерять проблемные сообщения и проанализировать их позже, не блокируя обработку остальных сообщений в основной очереди.',
  },
  {
    id: 'sd-mq-006',
    block: 'sd',
    topic: 'message-queues',
    topicLabel: 'Очереди сообщений',
    difficulty: 'junior',
    type: 'quiz',
    question: 'Что такое producer (продюсер) и consumer (потребитель) в контексте очередей сообщений?',
    options: [
      'Producer — администратор очереди, consumer — мониторинг очереди',
      'Producer — компонент, отправляющий сообщения в очередь, consumer — компонент, читающий и обрабатывающий сообщения из очереди',
      'Producer — создатель очереди, consumer — удаляющий очередь',
      'Producer — шифрует сообщения, consumer — дешифрует',
    ],
    correctIndex: 1,
    explanation:
      'Producer (продюсер, издатель) — это компонент системы, который создаёт и отправляет сообщения в очередь или топик. Consumer (потребитель, подписчик) — компонент, который читает сообщения из очереди и обрабатывает их. Продюсер и потребитель работают независимо (decoupling): продюсер не знает, кто и когда обработает сообщение. Это позволяет масштабировать продюсеров и потребителей независимо, а также обеспечивает устойчивость к временной недоступности одного из компонентов.',
  },
  {
    id: 'sd-mq-007',
    block: 'sd',
    topic: 'message-queues',
    topicLabel: 'Очереди сообщений',
    difficulty: 'junior',
    type: 'quiz',
    question: 'Какое основное преимущество асинхронной коммуникации через очереди сообщений перед синхронными HTTP-вызовами?',
    options: [
      'Асинхронная коммуникация всегда быстрее синхронной',
      'Очереди обеспечивают развязку сервисов, сглаживание пиков нагрузки и отказоустойчивость',
      'Очереди не требуют сетевого соединения',
      'Асинхронная коммуникация проще в отладке',
    ],
    correctIndex: 1,
    explanation:
      'Основные преимущества очередей: 1) Развязка (decoupling) — отправитель не зависит от доступности получателя. 2) Сглаживание пиков (load leveling) — при всплеске нагрузки сообщения буферизуются в очереди и обрабатываются по мере доступности ресурсов. 3) Отказоустойчивость — если потребитель упал, сообщения сохраняются в очереди. 4) Масштабирование — можно добавлять потребителей для увеличения пропускной способности. Недостатки: сложность отладки, eventual consistency, дополнительная инфраструктура.',
  },
  {
    id: 'sd-mq-008',
    block: 'sd',
    topic: 'message-queues',
    topicLabel: 'Очереди сообщений',
    difficulty: 'junior',
    type: 'quiz',
    question: 'Что означает гарантия доставки «at-least-once»?',
    options: [
      'Сообщение гарантированно доставлено ровно один раз',
      'Сообщение доставлено хотя бы один раз, но возможны дубликаты',
      'Сообщение может быть потеряно, но не дублируется',
      'Сообщение доставлено всем подписчикам одновременно',
    ],
    correctIndex: 1,
    explanation:
      'At-least-once — гарантия, что сообщение будет доставлено потребителю хотя бы один раз. Если подтверждение (ack) от потребителя не получено (из-за сбоя сети или потребителя), брокер повторно отправит сообщение. Это может привести к дубликатам, поэтому потребитель должен быть идемпотентным — обработка одного и того же сообщения несколько раз не должна изменять результат. Способы обеспечения идемпотентности: уникальный ID сообщения + таблица обработанных ID, использование UPSERT вместо INSERT.',
  },
  {
    id: 'sd-mq-009',
    block: 'sd',
    topic: 'message-queues',
    topicLabel: 'Очереди сообщений',
    difficulty: 'middle',
    type: 'quiz',
    question: 'Что такое partition (партиция) в Apache Kafka?',
    options: [
      'Раздел для хранения метаданных кластера',
      'Упорядоченная, неизменяемая последовательность сообщений внутри топика, обеспечивающая параллельную обработку',
      'Механизм изоляции топиков друг от друга',
      'Резервная копия топика на другом брокере',
    ],
    correctIndex: 1,
    explanation:
      'Partition (партиция) — основная единица параллелизма в Kafka. Каждый топик разделён на одну или несколько партиций. Партиция — это упорядоченный, append-only лог сообщений. Сообщения в пределах одной партиции строго упорядочены и имеют уникальный offset. Разные партиции могут обрабатываться разными потребителями параллельно. Ключ сообщения определяет, в какую партицию оно попадёт (hash(key) mod num_partitions), что гарантирует порядок для сообщений с одним ключом.',
  },
  {
    id: 'sd-mq-010',
    block: 'sd',
    topic: 'message-queues',
    topicLabel: 'Очереди сообщений',
    difficulty: 'middle',
    type: 'quiz',
    question: 'Что такое consumer group (группа потребителей) в Apache Kafka?',
    options: [
      'Группа топиков, объединённых по бизнес-логике',
      'Набор потребителей, совместно читающих топик, где каждая партиция обрабатывается только одним потребителем из группы',
      'Группа продюсеров, отправляющих сообщения в один топик',
      'Кластер брокеров, обслуживающих одну группу клиентов',
    ],
    correctIndex: 1,
    explanation:
      'Consumer group — это логическая группа потребителей, которые совместно читают топик. Kafka гарантирует, что каждая партиция назначена ровно одному потребителю в группе. Это обеспечивает: 1) Параллельную обработку — каждый потребитель обрабатывает свои партиции. 2) Масштабирование — добавление потребителей увеличивает пропускную способность (до количества партиций). 3) Отказоустойчивость — при падении потребителя его партиции автоматически перераспределяются (rebalancing). Разные consumer group-ы читают данные независимо — каждая получает все сообщения (паттерн pub/sub).',
  },
  {
    id: 'sd-mq-011',
    block: 'sd',
    topic: 'message-queues',
    topicLabel: 'Очереди сообщений',
    difficulty: 'middle',
    type: 'open',
    question: 'Какие типы exchange существуют в RabbitMQ и чем они отличаются? Приведите практические примеры использования каждого типа.',
    sampleAnswer:
      'Exchange в RabbitMQ — это компонент, который получает сообщения от продюсера и маршрутизирует их в очереди по определённым правилам. Типы exchange: 1) Direct — маршрутизация по точному совпадению routing key. Сообщение с routing key "order.created" попадёт только в очереди, привязанные с тем же ключом. Пример: распределение задач по типу (email-очередь, sms-очередь). 2) Fanout — сообщение копируется во все привязанные очереди, routing key игнорируется. Пример: рассылка уведомлений всем подсистемам (аналитика, логирование, мониторинг). 3) Topic — маршрутизация по шаблону routing key с wildcards (* — одно слово, # — ноль или более слов). Ключ "order.eu.created" совпадёт с "order.*.created" и "order.#". Пример: региональная обработка заказов. 4) Headers — маршрутизация по заголовкам сообщения, а не по routing key. Пример: фильтрация по формату данных (JSON vs XML) или приоритету.',
    explanation:
      'Exchange-модель RabbitMQ обеспечивает гибкую маршрутизацию, которой нет в Kafka (где маршрутизация идёт только по топику и партиции). Это преимущество RabbitMQ для сценариев сложной маршрутизации. На практике чаще всего используются Direct (для point-to-point) и Topic (для pub/sub с фильтрацией) exchange-ы.',
  },
  {
    id: 'sd-mq-012',
    block: 'sd',
    topic: 'message-queues',
    topicLabel: 'Очереди сообщений',
    difficulty: 'middle',
    type: 'quiz',
    question: 'Что такое offset в Apache Kafka?',
    options: [
      'Временная задержка между отправкой и получением сообщения',
      'Уникальный последовательный номер сообщения в партиции, по которому потребитель отслеживает свою позицию чтения',
      'Расстояние между продюсером и потребителем в сети',
      'Количество пропущенных сообщений при ошибке',
    ],
    correctIndex: 1,
    explanation:
      'Offset — это уникальный последовательный номер (0, 1, 2, ...), присваиваемый каждому сообщению в партиции. Потребитель отслеживает свой текущий offset для каждой партиции — это его «закладка» в логе. Kafka не удаляет сообщения после прочтения (в отличие от традиционных очередей) — они хранятся до истечения retention period. Это позволяет: перечитывать сообщения (replay), нескольким consumer group-ам читать независимо, восстанавливаться после сбоев. Offset-ы коммитятся (сохраняются) потребителем в Kafka (__consumer_offsets topic) или во внешнее хранилище.',
  },
  {
    id: 'sd-mq-013',
    block: 'sd',
    topic: 'message-queues',
    topicLabel: 'Очереди сообщений',
    difficulty: 'middle',
    type: 'quiz',
    question: 'Как обеспечить порядок обработки сообщений в распределённой системе с очередью?',
    options: [
      'Порядок гарантируется автоматически в любой конфигурации',
      'Использовать одну партицию/очередь, но это ограничивает пропускную способность',
      'Отправлять сообщения с одинаковым ключом, чтобы они попадали в одну партицию — порядок гарантируется в пределах партиции',
      'Порядок невозможно гарантировать в распределённой системе',
    ],
    correctIndex: 2,
    explanation:
      'В Kafka порядок сообщений гарантируется только в пределах одной партиции. Чтобы обеспечить порядок для связанных сообщений (например, все события одного заказа), нужно отправлять их с одним ключом (order_id) — тогда они попадут в одну партицию. Это позволяет масштабировать обработку (много партиций), сохраняя порядок для логически связанных сообщений. Глобальный порядок всех сообщений требует одной партиции, что ограничивает параллелизм. В RabbitMQ порядок гарантируется в пределах одной очереди при одном потребителе.',
  },
  {
    id: 'sd-mq-014',
    block: 'sd',
    topic: 'message-queues',
    topicLabel: 'Очереди сообщений',
    difficulty: 'senior',
    type: 'open',
    question: 'Что такое backpressure в системах обмена сообщениями и как её реализовать? Какие последствия отсутствия backpressure?',
    sampleAnswer:
      'Backpressure (обратное давление) — механизм, при котором потребитель или брокер сигнализирует продюсеру о необходимости замедлить отправку сообщений, чтобы не перегрузить систему. Без backpressure продюсер может отправлять сообщения быстрее, чем потребитель их обрабатывает, что приводит к: переполнению очереди (OOM), росту задержки обработки, потере сообщений, каскадным отказам. Реализация: 1) Ограничение размера очереди — при заполнении брокер отклоняет новые сообщения (RabbitMQ: x-max-length policy, Kafka: producer получает ошибку при полном буфере). 2) Rate limiting на продюсере — ограничение скорости отправки (Kafka: max.in.flight.requests.per.connection, linger.ms). 3) Credit-based flow control — RabbitMQ использует TCP credit flow для ограничения скорости продюсера. 4) Consumer-side throttling — потребитель контролирует скорость чтения (Kafka pull-модель). 5) Prefetch limit — ограничение количества неподтверждённых сообщений (RabbitMQ: prefetch count). 6) Мониторинг lag — алертинг при росте отставания потребителя (Kafka consumer lag).',
    explanation:
      'Backpressure — критический механизм для production-систем. Без него любая разница в скорости между продюсером и потребителем неизбежно приведёт к проблемам. Kafka по дизайну обеспечивает естественный backpressure через pull-модель: потребитель сам определяет скорость чтения. RabbitMQ использует push-модель, поэтому backpressure реализуется через prefetch и credit flow.',
  },
  {
    id: 'sd-mq-015',
    block: 'sd',
    topic: 'message-queues',
    topicLabel: 'Очереди сообщений',
    difficulty: 'senior',
    type: 'quiz',
    question: 'Какой формат сериализации обеспечивает наилучшую производительность и поддержку эволюции схемы для сообщений в Kafka?',
    options: [
      'JSON — универсальный и читаемый формат',
      'XML — стандарт для enterprise-систем',
      'Apache Avro с Schema Registry — компактный бинарный формат с управлением версиями схемы',
      'Plain Text — простейший формат',
    ],
    correctIndex: 2,
    explanation:
      'Apache Avro в сочетании с Confluent Schema Registry — рекомендуемый подход для Kafka. Avro обеспечивает: компактную бинарную сериализацию (меньше трафика и хранения, чем JSON), эволюцию схемы (backward/forward compatibility — можно добавлять/удалять поля без поломки потребителей), строгую типизацию. Schema Registry хранит и версионирует схемы, проверяя совместимость при регистрации новых версий. Альтернативы: Protocol Buffers (Google, популярен в gRPC), Thrift (Facebook), MessagePack. JSON проще для отладки, но менее эффективен и не поддерживает нативную эволюцию схемы.',
  },
  {
    id: 'sd-mq-016',
    block: 'sd',
    topic: 'message-queues',
    topicLabel: 'Очереди сообщений',
    difficulty: 'senior',
    type: 'open',
    question: 'Как Kafka обеспечивает exactly-once семантику через идемпотентного продюсера и транзакции? Какие ограничения существуют?',
    sampleAnswer:
      'Kafka реализует exactly-once через два механизма: 1) Идемпотентный продюсер (enable.idempotence=true): Kafka присваивает каждому продюсеру Producer ID (PID) и каждому сообщению Sequence Number. Брокер отслеживает последний sequence number для каждого PID и партиции, отклоняя дубликаты при повторной отправке. Это обеспечивает exactly-once для одного продюсера в одну партицию. 2) Транзакции (Kafka Transactions): продюсер может атомарно записать сообщения в несколько партиций/топиков и закоммитить offset потребителя — либо все записи применяются, либо ни одна. Потребитель с isolation.level=read_committed видит только закоммиченные сообщения. Ограничения: exactly-once работает только в рамках экосистемы Kafka (Kafka → Kafka). При взаимодействии с внешними системами (БД, HTTP API) нужна дополнительная идемпотентность. Транзакции увеличивают задержку и снижают пропускную способность. Максимальное количество партиций в одной транзакции ограничено.',
    explanation:
      'Exactly-once в Kafka — это инженерное достижение, но важно понимать его границы. Оно работает для паттерна «read-process-write» внутри Kafka (Kafka Streams). Для внешних систем (запись в PostgreSQL, отправка HTTP) нужен Transactional Outbox Pattern или идемпотентные операции. На практике большинство систем используют at-least-once + idempotency как более простой и надёжный подход.',
  },
  {
    id: 'sd-mq-017',
    block: 'sd',
    topic: 'message-queues',
    topicLabel: 'Очереди сообщений',
    difficulty: 'junior',
    type: 'quiz',
    question: 'Что такое acknowledgement (ack) при обработке сообщений?',
    options: [
      'Шифрование сообщения перед отправкой',
      'Подтверждение от потребителя брокеру, что сообщение успешно обработано',
      'Проверка целостности сообщения при передаче',
      'Запись лога о получении сообщения',
    ],
    correctIndex: 1,
    explanation:
      'Acknowledgement (ack, подтверждение) — это сигнал от потребителя брокеру о том, что сообщение было успешно получено и обработано. После получения ack брокер удаляет сообщение из очереди (в RabbitMQ) или фиксирует offset (в Kafka). Если ack не получен (потребитель упал), брокер считает сообщение необработанным и доставит его повторно (другому потребителю или тому же после восстановления). Важно отправлять ack только после полной обработки, иначе сообщение может быть потеряно. Auto-ack (подтверждение сразу при получении) быстрее, но рискует потерей данных.',
  },
  {
    id: 'sd-mq-018',
    block: 'sd',
    topic: 'message-queues',
    topicLabel: 'Очереди сообщений',
    difficulty: 'middle',
    type: 'open',
    question: 'Что такое паттерн Transactional Outbox и какую проблему он решает при работе с очередями сообщений?',
    sampleAnswer:
      'Transactional Outbox решает проблему атомарности операции «обновить БД + отправить сообщение в очередь». Проблема: при обновлении заказа нужно сохранить изменения в БД и отправить событие в Kafka. Если сохранить в БД и затем отправить в Kafka — при падении между шагами данные обновлены, но событие потеряно. Если сначала отправить в Kafka — событие отправлено, но БД не обновлена. Решение Transactional Outbox: 1) Сервис записывает бизнес-данные И событие в таблицу outbox в одной БД-транзакции. 2) Отдельный процесс (relay/poller) читает новые записи из outbox и отправляет их в Kafka. 3) После успешной отправки помечает запись как обработанную. Альтернатива — Change Data Capture (CDC): инструмент вроде Debezium читает WAL базы данных и публикует изменения в Kafka, включая записи outbox таблицы. CDC надёжнее polling-а и не нагружает БД дополнительными запросами.',
    explanation:
      'Transactional Outbox — один из важнейших паттернов в событийно-ориентированных архитектурах. Без него невозможно гарантировать консистентность между базой данных и очередью сообщений. Debezium + Kafka Connect — популярная реализация CDC-подхода. Паттерн особенно важен при использовании Database per Service, где нельзя использовать распределённые транзакции.',
  },
  {
    id: 'sd-mq-019',
    block: 'sd',
    topic: 'message-queues',
    topicLabel: 'Очереди сообщений',
    difficulty: 'senior',
    type: 'quiz',
    question: 'Как Kafka обеспечивает высокую доступность данных при отказе брокера?',
    options: [
      'Данные хранятся только в памяти и не переживают отказ',
      'Через репликацию партиций — каждая партиция имеет leader и несколько follower-реплик на разных брокерах',
      'Через автоматическое резервное копирование в облачное хранилище',
      'Через зеркалирование всего кластера на резервный дата-центр',
    ],
    correctIndex: 1,
    explanation:
      'Kafka реплицирует данные через механизм In-Sync Replicas (ISR). Каждая партиция имеет одного leader-а (обслуживает чтение и запись) и несколько follower-реплик на других брокерах. Follower-ы синхронно или асинхронно реплицируют данные с leader-а. ISR — множество реплик, которые «догнали» leader-а. При настройке acks=all продюсер получает подтверждение только после записи на все ISR-реплики. При отказе leader-а контроллер кластера автоматически выбирает нового leader-а из ISR. Параметры min.insync.replicas и acks определяют баланс между durability и производительностью.',
  },
  {
    id: 'sd-mq-020',
    block: 'sd',
    topic: 'message-queues',
    topicLabel: 'Очереди сообщений',
    difficulty: 'senior',
    type: 'open',
    question: 'Опишите архитектуру обработки событий с использованием Event Sourcing и Kafka. Какие преимущества и сложности создаёт этот подход?',
    sampleAnswer:
      'Event Sourcing — паттерн, при котором состояние системы определяется последовательностью событий (event log), а не текущим снимком. Kafka идеально подходит как event store благодаря: append-only логу, долгосрочному хранению (retention), replay возможности, упорядоченности в пределах партиции. Архитектура: 1) Команда (Command) валидируется и создаёт событие (Event). 2) Событие записывается в Kafka топик (event store). 3) Проекции (read models) строятся из потока событий для разных представлений: одна проекция в PostgreSQL для запросов, другая в Elasticsearch для поиска, третья в Redis для кэша. 4) При сбое проекция перестраивается из Kafka (replay). Преимущества: полная история изменений (audit log), возможность восстановить любое прошлое состояние, естественная интеграция с CQRS, temporal queries. Сложности: eventual consistency, сложность обработки ошибок (компенсирующие события вместо DELETE/UPDATE), рост объёма данных (compaction помогает частично), сложность миграции схемы событий, крутая кривая обучения.',
    explanation:
      'Event Sourcing + Kafka — мощная комбинация, но подходит не для всех систем. Она оправдана для: финансовых систем (аудит всех транзакций), систем с конкурентными обновлениями (CRDTs, collaborative editing), аналитических платформ. Для простых CRUD-приложений Event Sourcing избыточен. Важно помнить: Kafka не является полноценным event store (нет поддержки optimistic concurrency), для этого существуют специализированные решения вроде EventStoreDB.',
  },
  {
    id: 'sd-mq-021',
    block: 'sd',
    topic: 'message-queues',
    topicLabel: 'Очереди сообщений',
    difficulty: 'junior',
    type: 'quiz',
    question: 'Что такое broker (брокер) в системе обмена сообщениями?',
    options: [
      'Клиент, отправляющий сообщения',
      'Сервер, который принимает, хранит и доставляет сообщения',
      'Библиотека для работы с очередями',
      'Формат сериализации сообщений',
    ],
    correctIndex: 1,
    explanation:
      'Message broker — сервер-посредник, который принимает сообщения от продюсеров, хранит их и доставляет потребителям. Брокер обеспечивает: decoupling (отправитель не знает о получателях), durability (сообщения не теряются), routing (направление сообщений по правилам). Примеры брокеров: RabbitMQ, Apache Kafka, Apache ActiveMQ, Amazon SQS.',
  },
  {
    id: 'sd-mq-022',
    block: 'sd',
    topic: 'message-queues',
    topicLabel: 'Очереди сообщений',
    difficulty: 'junior',
    type: 'quiz',
    question: 'Что такое topic (топик) в Apache Kafka?',
    options: [
      'Тема для обсуждения между разработчиками',
      'Категория или канал, в который публикуются сообщения',
      'Файл конфигурации Kafka',
      'Метрика производительности',
    ],
    correctIndex: 1,
    explanation:
      'Topic в Kafka — именованный канал (категория) для публикации сообщений. Продюсеры отправляют сообщения в топик, потребители читают из топика. Топик разделён на партиции для параллелизма. Примеры топиков: orders, user-events, logs. Топики могут иметь разные настройки retention, replication factor.',
  },
  {
    id: 'sd-mq-023',
    block: 'sd',
    topic: 'message-queues',
    topicLabel: 'Очереди сообщений',
    difficulty: 'junior',
    type: 'quiz',
    question: 'Какое преимущество даёт использование очередей для email-рассылки вместо синхронной отправки?',
    options: [
      'Email отправляется быстрее',
      'Пользователь не ждёт отправки, система устойчива к сбоям email-сервиса',
      'Не нужен email-сервер',
      'Гарантируется доставка email',
    ],
    correctIndex: 1,
    explanation:
      'При асинхронной отправке через очередь: 1) Пользователь получает ответ сразу, не дожидаясь отправки email. 2) При временной недоступности email-сервиса сообщения буферизуются и отправляются позже. 3) Можно контролировать rate (не перегружать email-провайдер). 4) Retry при ошибках без влияния на основной flow. Это типичный паттерн использования очередей.',
  },
  {
    id: 'sd-mq-024',
    block: 'sd',
    topic: 'message-queues',
    topicLabel: 'Очереди сообщений',
    difficulty: 'junior',
    type: 'open',
    question: 'Объясните разницу между синхронной и асинхронной коммуникацией между сервисами. Когда использовать каждый подход?',
    sampleAnswer:
      'Синхронная коммуникация (HTTP/gRPC): вызывающий сервис ждёт ответа. Преимущества: простота, немедленный результат, easier debugging. Недостатки: зависимость от доступности получателя, cascading failures. Использовать: когда нужен немедленный ответ (проверка баланса, авторизация), для query-операций. Асинхронная коммуникация (Message Queues): отправитель не ждёт обработки. Преимущества: decoupling, отказоустойчивость, масштабируемость, сглаживание пиков. Недостатки: сложнее отладка, eventual consistency, дополнительная инфраструктура. Использовать: для command-операций (создать заказ), когда результат не нужен сразу, для интеграции между доменами, для event-driven architecture.',
    explanation:
      'Большинство систем комбинируют оба подхода. Типичный паттерн: API Gateway синхронно обрабатывает запрос, сохраняет в БД, публикует событие в очередь. Фоновые задачи (уведомления, аналитика) обрабатываются асинхронно.',
  },
  {
    id: 'sd-mq-025',
    block: 'sd',
    topic: 'message-queues',
    topicLabel: 'Очереди сообщений',
    difficulty: 'middle',
    type: 'quiz',
    question: 'Что такое message TTL (Time To Live) в очередях сообщений?',
    options: [
      'Время жизни соединения с брокером',
      'Время, после которого неиспользованное сообщение удаляется или перемещается в DLQ',
      'Максимальное время обработки сообщения',
      'Интервал между отправкой сообщений',
    ],
    correctIndex: 1,
    explanation:
      'Message TTL — максимальное время жизни сообщения в очереди. Если сообщение не обработано за это время, оно удаляется или перемещается в Dead Letter Queue. Зачем: предотвращение накопления устаревших сообщений, очистка очереди от «застрявших» сообщений, бизнес-логика (сообщение актуально только N минут). В RabbitMQ: x-message-ttl. В Kafka: retention.ms на уровне топика.',
  },
  {
    id: 'sd-mq-026',
    block: 'sd',
    topic: 'message-queues',
    topicLabel: 'Очереди сообщений',
    difficulty: 'middle',
    type: 'quiz',
    question: 'Что такое prefetch в RabbitMQ и зачем он нужен?',
    options: [
      'Предварительная загрузка конфигурации очереди',
      'Количество сообщений, которые потребитель может получить без подтверждения',
      'Кэширование сообщений на стороне клиента',
      'Прогнозирование количества сообщений',
    ],
    correctIndex: 1,
    explanation:
      'Prefetch (QoS) — ограничение количества неподтверждённых сообщений, которые брокер отправит потребителю. Зачем: 1) Равномерное распределение нагрузки — без prefetch один быстрый потребитель может захватить все сообщения. 2) Backpressure — медленный потребитель не получит больше сообщений, чем может обработать. Настройка: prefetch=1 — честное распределение, но ниже throughput. prefetch=10-50 — баланс. В RabbitMQ: channel.basicQos(prefetchCount).',
  },
  {
    id: 'sd-mq-027',
    block: 'sd',
    topic: 'message-queues',
    topicLabel: 'Очереди сообщений',
    difficulty: 'middle',
    type: 'open',
    question: 'Что такое stream processing и чем оно отличается от batch processing? Какие инструменты используются?',
    sampleAnswer:
      'Batch processing — обработка данных большими порциями периодически (hourly, daily). Пример: ночной ETL, генерация отчётов. Инструменты: Hadoop MapReduce, Spark (batch mode). Характеристики: высокая throughput, высокая latency (часы). Stream processing — обработка данных в реальном времени по мере поступления. Пример: fraud detection, real-time analytics, alerting. Инструменты: Apache Kafka Streams, Apache Flink, Apache Spark Streaming, AWS Kinesis. Характеристики: низкая latency (миллисекунды-секунды), continuous processing. Отличия: batch — bounded dataset, stream — unbounded. Batch оптимизирует throughput, stream — latency. Современный тренд — unified batch+stream (Lambda/Kappa architecture, Apache Beam).',
    explanation:
      'Stream processing становится стандартом для real-time use cases. Kafka + Kafka Streams (или Flink) — популярный стек. Важно понимать trade-offs: stream processing сложнее (ordering, exactly-once, state management), но даёт real-time insights.',
  },
  {
    id: 'sd-mq-028',
    block: 'sd',
    topic: 'message-queues',
    topicLabel: 'Очереди сообщений',
    difficulty: 'middle',
    type: 'quiz',
    question: 'Что такое retention period в Apache Kafka?',
    options: [
      'Время хранения соединения с брокером',
      'Период, в течение которого сообщения хранятся в топике, после чего удаляются',
      'Время обработки одного сообщения',
      'Период между репликациями данных',
    ],
    correctIndex: 1,
    explanation:
      'Retention period — время хранения сообщений в Kafka-топике. В отличие от традиционных очередей, Kafka не удаляет сообщения после прочтения — они хранятся до истечения retention. Это позволяет: перечитывать сообщения (replay), нескольким consumer groups читать независимо, восстанавливаться после сбоев. Настройки: retention.ms (время), retention.bytes (размер). Также есть log compaction — хранение только последнего значения для каждого ключа.',
  },
  {
    id: 'sd-mq-029',
    block: 'sd',
    topic: 'message-queues',
    topicLabel: 'Очереди сообщений',
    difficulty: 'middle',
    type: 'quiz',
    question: 'Какой паттерн обмена сообщениями позволяет отправителю получить ответ от получателя?',
    options: [
      'Fire-and-forget',
      'Request-Reply (RPC over messaging)',
      'Publish-Subscribe',
      'Fan-out',
    ],
    correctIndex: 1,
    explanation:
      'Request-Reply — паттерн, при котором отправитель ожидает ответ на своё сообщение. Реализация: сообщение содержит reply-to (адрес очереди для ответа) и correlation-id. Получатель обрабатывает запрос и отправляет ответ в указанную очередь с тем же correlation-id. RabbitMQ Direct Reply-to упрощает этот паттерн. Используется для: RPC через очереди, когда нужен ответ, но с преимуществами асинхронности (retry, timeout).',
  },
  {
    id: 'sd-mq-030',
    block: 'sd',
    topic: 'message-queues',
    topicLabel: 'Очереди сообщений',
    difficulty: 'middle',
    type: 'open',
    question: 'Как обеспечить идемпотентность обработки сообщений? Почему это важно при at-least-once delivery?',
    sampleAnswer:
      'Идемпотентность — свойство операции, при котором многократное выполнение даёт тот же результат, что и однократное. При at-least-once delivery сообщение может быть доставлено несколько раз (retry после сбоя), поэтому обработка должна быть идемпотентной. Способы обеспечения: 1) Unique message ID + deduplication table — сохранять ID обработанных сообщений, игнорировать дубликаты. 2) Idempotent operations — использовать UPSERT вместо INSERT, SET balance = 100 вместо balance += 10. 3) Version/timestamp checks — обновлять только если версия новее. 4) Natural idempotency — некоторые операции идемпотентны по природе (DELETE, SET). 5) Database constraints — UNIQUE constraints предотвращают дублирование. Redis с SETNX для deduplication, Kafka producer с enable.idempotence=true.',
    explanation:
      'Идемпотентность — ключевой принцип надёжной обработки сообщений. Без неё at-least-once превращается в at-least-once-effect, что может привести к дублированию заказов, двойным списаниям и т.д. Проектируйте handlers idempotent с самого начала.',
  },
  {
    id: 'sd-mq-031',
    block: 'sd',
    topic: 'message-queues',
    topicLabel: 'Очереди сообщений',
    difficulty: 'senior',
    type: 'quiz',
    question: 'Что такое log compaction в Apache Kafka?',
    options: [
      'Сжатие логов для экономии места',
      'Хранение только последнего сообщения для каждого ключа, удаление предыдущих',
      'Объединение нескольких партиций в одну',
      'Архивирование старых логов',
    ],
    correctIndex: 1,
    explanation:
      'Log compaction — режим retention в Kafka, при котором для каждого ключа хранится только последнее сообщение. Предыдущие значения удаляются при compaction (фоновый процесс). Используется для: changelog топиков (текущее состояние), конфигураций, user profiles — когда важно последнее значение, а не история. В отличие от time-based retention, compacted топик может хранить данные бессрочно. Сообщение с null value (tombstone) означает удаление ключа.',
  },
  {
    id: 'sd-mq-032',
    block: 'sd',
    topic: 'message-queues',
    topicLabel: 'Очереди сообщений',
    difficulty: 'senior',
    type: 'quiz',
    question: 'Какой инструмент позволяет реализовать Change Data Capture из базы данных в Kafka?',
    options: [
      'Kafka Connect',
      'Debezium',
      'Kafka Streams',
      'Schema Registry',
    ],
    correctIndex: 1,
    explanation:
      'Debezium — open-source платформа для CDC (Change Data Capture). Читает изменения из WAL/binlog базы данных и публикует в Kafka. Поддерживает: PostgreSQL, MySQL, MongoDB, SQL Server, Oracle. Преимущества перед polling: low latency, не нагружает БД запросами, точный порядок изменений. Работает как Kafka Connect connector. Используется для: синхронизации данных, event-driven architecture, cache invalidation, микросервисной интеграции.',
  },
  {
    id: 'sd-mq-033',
    block: 'sd',
    topic: 'message-queues',
    topicLabel: 'Очереди сообщений',
    difficulty: 'senior',
    type: 'open',
    question: 'Объясните архитектуру Kafka Connect и когда её использовать вместо custom producers/consumers.',
    sampleAnswer:
      'Kafka Connect — фреймворк для интеграции Kafka с внешними системами. Архитектура: Workers — процессы, выполняющие connectors. Connectors — плагины для конкретных систем (JDBC, S3, Elasticsearch). Tasks — единицы параллелизма внутри connector. Source connectors — читают из внешней системы в Kafka. Sink connectors — пишут из Kafka во внешнюю систему. Преимущества: готовые коннекторы (сотни доступных), автоматический offset management, масштабирование (distributed mode), мониторинг через REST API, schema evolution с Schema Registry. Когда использовать: интеграция с популярными системами (БД, S3, Elasticsearch), ETL/ELT пайплайны, CDC с Debezium. Когда custom producer/consumer: уникальная бизнес-логика, сложная трансформация, нестандартные источники.',
    explanation:
      'Kafka Connect — production-ready решение для типовых интеграций. Писать custom consumer для записи в PostgreSQL — изобретение велосипеда. Connectors протестированы, поддерживают exactly-once (некоторые), обрабатывают edge cases. Confluent Hub — репозиторий коннекторов.',
  },
  {
    id: 'sd-mq-034',
    block: 'sd',
    topic: 'message-queues',
    topicLabel: 'Очереди сообщений',
    difficulty: 'senior',
    type: 'open',
    question: 'Как реализовать exactly-once processing при записи из Kafka в базу данных? Какие паттерны используются?',
    sampleAnswer:
      'Exactly-once при записи в внешнюю систему требует координации commit-ов: 1) Transactional Outbox + CDC — записывать результат и offset в одну БД-транзакцию, CDC публикует результат. Гарантирует exactly-once, но добавляет задержку. 2) Idempotent writes + at-least-once — хранить message_id в БД, при duplicate — skip. Просто, работает для большинства случаев. 3) Two-Phase Commit (2PC) — XA-транзакции между Kafka и БД. Медленно, сложно, редко используется. 4) Kafka Transactions + DB в одной системе — Kafka Connect JDBC Sink с exactly-once.source=true (requires Kafka transactions). 5) State store (Kafka Streams) — хранить состояние в Kafka, не во внешней БД. Kafka Streams обеспечивает exactly-once internally. На практике: idempotent processing — самый простой и надёжный подход. «Exactly-once» при взаимодействии с внешними системами — часто иллюзия.',
    explanation:
      'Exactly-once между Kafka и внешней системой — нерешённая проблема в общем случае (two generals problem). На практике применяют: idempotency (at-least-once + deduplication), transactional outbox, или принимают at-least-once с идемпотентной обработкой.',
  },
  {
    id: 'sd-mq-035',
    block: 'sd',
    topic: 'message-queues',
    topicLabel: 'Очереди сообщений',
    difficulty: 'junior',
    type: 'quiz',
    question: 'Что такое message payload?',
    options: [
      'Адрес получателя сообщения',
      'Полезная нагрузка — данные, передаваемые в сообщении',
      'Заголовки сообщения',
      'Идентификатор сообщения',
    ],
    correctIndex: 1,
    explanation:
      'Message payload (полезная нагрузка) — основные данные, передаваемые в сообщении. Помимо payload, сообщение обычно содержит: headers (метаданные), key (для партиционирования в Kafka), timestamp, message ID. Payload может быть в любом формате: JSON, Avro, Protobuf, plain text. Размер payload влияет на производительность — Kafka эффективен для сообщений до ~1MB.',
  },
  {
    id: 'sd-mq-036',
    block: 'sd',
    topic: 'message-queues',
    topicLabel: 'Очереди сообщений',
    difficulty: 'junior',
    type: 'quiz',
    question: 'Какой сервис AWS предоставляет управляемую очередь сообщений?',
    options: [
      'AWS Lambda',
      'Amazon SQS (Simple Queue Service)',
      'Amazon RDS',
      'AWS CloudWatch',
    ],
    correctIndex: 1,
    explanation:
      'Amazon SQS — полностью управляемый сервис очередей сообщений. Два типа очередей: Standard (at-least-once, best-effort ordering, высокая пропускная способность) и FIFO (exactly-once, строгий порядок, до 300 msg/sec без batching). Преимущества: serverless (нет серверов для управления), автоматическое масштабирование, интеграция с Lambda, SNS. Альтернатива для pub/sub: Amazon SNS.',
  },
  {
    id: 'sd-mq-037',
    block: 'sd',
    topic: 'message-queues',
    topicLabel: 'Очереди сообщений',
    difficulty: 'middle',
    type: 'quiz',
    question: 'Что такое message batching и зачем он используется?',
    options: [
      'Группировка сообщений по получателям',
      'Отправка нескольких сообщений одним запросом для повышения throughput',
      'Резервное копирование сообщений',
      'Фильтрация сообщений по критериям',
    ],
    correctIndex: 1,
    explanation:
      'Message batching — группировка нескольких сообщений в один запрос для снижения overhead сетевых вызовов. В Kafka: producer batch.size и linger.ms контролируют батчинг на стороне продюсера. Consumer может читать batch сообщений (max.poll.records). Преимущества: выше throughput, лучшая компрессия, меньше сетевых round-trip. Trade-off: выше latency (ждём наполнения batch). Batching критичен для high-throughput сценариев.',
  },
  {
    id: 'sd-mq-038',
    block: 'sd',
    topic: 'message-queues',
    topicLabel: 'Очереди сообщений',
    difficulty: 'middle',
    type: 'open',
    question: 'Опишите паттерн Competing Consumers. Как он помогает масштабировать обработку сообщений?',
    sampleAnswer:
      'Competing Consumers — паттерн, при котором несколько потребителей читают из одной очереди, «конкурируя» за сообщения. Каждое сообщение обрабатывается только одним потребителем. Как работает: сообщение выдаётся одному из доступных потребителей, после обработки и ack сообщение удаляется. Масштабирование: добавление потребителей увеличивает throughput линейно (до пределов очереди/партиций). Реализации: RabbitMQ — несколько consumers на одной очереди. Kafka — consumer group, каждая партиция назначается одному consumer. Ограничения: порядок не гарантируется между потребителями (в Kafka — гарантируется в пределах партиции). При сбое потребителя — redelivery (возможны дубликаты). Используется для: обработки задач (task queue), распределения нагрузки.',
    explanation:
      'Competing Consumers — основа масштабируемой обработки сообщений. В Kubernetes типичная реализация: Deployment с N репликами pod, каждая — consumer. HPA может автоматически масштабировать по queue depth или consumer lag.',
  },
  {
    id: 'sd-mq-039',
    block: 'sd',
    topic: 'message-queues',
    topicLabel: 'Очереди сообщений',
    difficulty: 'middle',
    type: 'quiz',
    question: 'Какой механизм Kafka Streams позволяет хранить состояние обработки локально?',
    options: [
      'Kafka Topics',
      'State Stores (backed by RocksDB)',
      'Consumer Groups',
      'Schema Registry',
    ],
    correctIndex: 1,
    explanation:
      'State Stores в Kafka Streams — локальные хранилища состояния для stateful операций (aggregations, joins, windowing). По умолчанию используют RocksDB (embedded key-value store). State автоматически реплицируется в changelog topic Kafka для восстановления при сбое. Преимущества: быстрый доступ (локальный диск), fault tolerance (changelog), exactly-once (с Kafka transactions). Операции: count(), aggregate(), join() используют state stores.',
  },
  {
    id: 'sd-mq-040',
    block: 'sd',
    topic: 'message-queues',
    topicLabel: 'Очереди сообщений',
    difficulty: 'senior',
    type: 'quiz',
    question: 'Что такое consumer lag в Kafka и почему его важно мониторить?',
    options: [
      'Задержка сети между consumer и broker',
      'Разница между последним сообщением в партиции и позицией чтения consumer',
      'Время обработки одного сообщения',
      'Количество ошибок consumer',
    ],
    correctIndex: 1,
    explanation:
      'Consumer lag — количество непрочитанных сообщений: разница между log-end-offset (последнее сообщение) и committed-offset (позиция consumer). Почему важно: растущий lag означает, что consumer не успевает за producer — система деградирует. Причины: медленная обработка, недостаточно потребителей, проблемы с зависимостями. Мониторинг: Kafka JMX metrics, Burrow, Prometheus kafka_consumergroup_lag. Alert на lag выше порога критичен для production.',
  },
  {
    id: 'sd-mq-041',
    block: 'sd',
    topic: 'message-queues',
    topicLabel: 'Очереди сообщений',
    difficulty: 'senior',
    type: 'open',
    question: 'Сравните Apache Kafka и Amazon Kinesis. Когда выбрать каждый?',
    sampleAnswer:
      'Apache Kafka: Self-hosted или Confluent Cloud. Преимущества: полный контроль, богатая экосистема (Kafka Streams, Connect, ksqlDB), неограниченное retention, log compaction, exactly-once semantics, open-source. Недостатки: операционная сложность (ZooKeeper/KRaft), требует DevOps-экспертизы. Amazon Kinesis: Fully managed AWS сервис. Преимущества: serverless, интеграция с AWS (Lambda, Firehose, Analytics), масштабируется по требованию, нет операций. Недостатки: vendor lock-in, retention до 7 дней (365 с extended), дороже на высоких объёмах, меньше features чем Kafka. Выбор: Kinesis — AWS-native приложение, хотите managed, объём умеренный. Kafka — high throughput, нужны advanced features (compaction, exactly-once), multi-cloud, есть экспертиза. Альтернатива: Amazon MSK — managed Kafka в AWS.',
    explanation:
      'Kinesis проще для старта в AWS-экосистеме, Kafka мощнее и гибче. Многие начинают с Kinesis и мигрируют на Kafka (или MSK) при росте требований. MSK — компромисс: Kafka features с managed operations.',
  },
  {
    id: 'sd-mq-042',
    block: 'sd',
    topic: 'message-queues',
    topicLabel: 'Очереди сообщений',
    difficulty: 'senior',
    type: 'quiz',
    question: 'Что такое event replay и почему это важная возможность Kafka?',
    options: [
      'Повторная отправка неудачных сообщений',
      'Возможность перечитать исторические сообщения, сбросив offset consumer',
      'Воспроизведение событий в тестовой среде',
      'Репликация событий между кластерами',
    ],
    correctIndex: 1,
    explanation:
      'Event replay — возможность перечитать сообщения с любой позиции (offset). В Kafka сообщения не удаляются после чтения (в отличие от традиционных очередей), хранятся до истечения retention. Зачем: восстановление после ошибки в consumer (перечитать и обработать заново), построение новых проекций/views из событий, debugging, testing. Как: сбросить offset consumer group на нужную позицию (kafka-consumer-groups --reset-offsets). Event replay — основа Event Sourcing архитектуры.',
  },
  {
    id: 'sd-mq-043',
    block: 'sd',
    topic: 'message-queues',
    topicLabel: 'Очереди сообщений',
    difficulty: 'junior',
    type: 'quiz',
    question: 'Что происходит с сообщением в очереди, если потребитель отправил negative acknowledgement (nack)?',
    options: [
      'Сообщение удаляется из очереди',
      'Сообщение возвращается в очередь для повторной обработки или отправляется в DLQ',
      'Сообщение отправляется обратно продюсеру',
      'Ничего, сообщение остаётся у потребителя',
    ],
    correctIndex: 1,
    explanation:
      'При negative acknowledgement (nack/reject) в RabbitMQ сообщение: возвращается в очередь для повторной доставки (requeue=true) или отбрасывается/перемещается в DLQ (requeue=false с настроенным dead-letter exchange). Это позволяет обработать временные ошибки (retry) и изолировать постоянные (DLQ для анализа). В Kafka нет явного nack — consumer контролирует offset, не коммитит offset проблемного сообщения.',
  },
  {
    id: 'sd-mq-044',
    block: 'sd',
    topic: 'message-queues',
    topicLabel: 'Очереди сообщений',
    difficulty: 'middle',
    type: 'open',
    question: 'Как организовать приоритетные очереди сообщений? Какие подходы существуют?',
    sampleAnswer:
      'Приоритетные очереди — обработка важных сообщений раньше менее важных. Подходы: 1) RabbitMQ Priority Queue — нативная поддержка приоритетов (x-max-priority). Сообщения с высоким приоритетом обрабатываются первыми. Ограничение: дополнительное потребление памяти. 2) Отдельные очереди — high-priority, medium, low. Consumers сначала обрабатывают high, затем medium. Реализация: multiple consumers с разным распределением. 3) Kafka: нет нативных приоритетов. Решение: отдельные топики по приоритету, consumer сначала читает high-priority topic. 4) Weighted consumers — больше consumers для high-priority очереди. 5) Consumer-side prioritization — читать batch, сортировать по приоритету, обрабатывать. Trade-off: приоритеты усложняют систему, возможно starvation низкоприоритетных сообщений.',
    explanation:
      'Приоритетные очереди нужны для: критичных бизнес-операций (платежи важнее аналитики), SLA-based processing (premium users), graceful degradation (при перегрузке обрабатывать только важное). Простейшее решение — отдельные очереди, явно управляемые.',
  },
  {
    id: 'sd-mq-045',
    block: 'sd',
    topic: 'message-queues',
    topicLabel: 'Очереди сообщений',
    difficulty: 'middle',
    type: 'quiz',
    question: 'Что такое Apache Pulsar и чем он отличается от Kafka?',
    options: [
      'Pulsar — это форк Kafka с другим названием',
      'Pulsar — distributed messaging с разделением compute и storage, native multi-tenancy и geo-replication',
      'Pulsar — инструмент мониторинга для Kafka',
      'Pulsar — протокол сериализации сообщений',
    ],
    correctIndex: 1,
    explanation:
      'Apache Pulsar — distributed messaging и streaming платформа (Yahoo, сейчас Apache). Ключевые отличия от Kafka: 1) Separation of compute and storage — брокеры stateless, данные в Apache BookKeeper. Упрощает масштабирование. 2) Native multi-tenancy — изоляция на уровне платформы. 3) Geo-replication — встроенная репликация между дата-центрами. 4) Unified messaging — queuing и streaming в одной системе. 5) Tiered storage — автоматический offload на S3. Trade-off: сложнее операционно (больше компонентов), меньше экосистема чем у Kafka.',
  },
  {
    id: 'sd-mq-046',
    block: 'sd',
    topic: 'message-queues',
    topicLabel: 'Очереди сообщений',
    difficulty: 'senior',
    type: 'open',
    question: 'Как реализовать distributed tracing для сообщений, проходящих через несколько сервисов и очередей?',
    sampleAnswer:
      'Distributed tracing для async messaging: 1) Propagate trace context — добавлять trace-id и span-id в headers сообщения. OpenTelemetry стандартизирует формат (traceparent header). 2) Producer span — создавать span при отправке сообщения, записывать topic, key в attributes. 3) Consumer span — при получении извлекать context из headers, создавать child span. 4) Instrumentation — библиотеки Kafka/RabbitMQ с поддержкой OpenTelemetry (автоматическая propagation). 5) Visualization — Jaeger, Zipkin, Datadog показывают trace через sync и async calls. Особенности: async span может длиться долго (время в очереди), batching усложняет (много messages = много spans), sampling важен для высоких объёмов. Инструменты: OpenTelemetry SDK, Jaeger, Zipkin, коммерческие APM.',
    explanation:
      'Tracing через очереди критичен для понимания end-to-end latency и debugging. Без propagation context теряется связь между producer и consumer. OpenTelemetry — стандарт де-факто, большинство messaging библиотек имеют интеграцию.',
  },
  {
    id: 'sd-mq-047',
    block: 'sd',
    topic: 'message-queues',
    topicLabel: 'Очереди сообщений',
    difficulty: 'senior',
    type: 'quiz',
    question: 'Что такое Kafka KRaft mode и почему он важен?',
    options: [
      'Режим сжатия сообщений в Kafka',
      'Новый режим consensus без ZooKeeper, упрощающий архитектуру Kafka',
      'Протокол шифрования в Kafka',
      'Режим высокой производительности',
    ],
    correctIndex: 1,
    explanation:
      'KRaft (Kafka Raft) — новый режим metadata management в Kafka без ZooKeeper. До KRaft Kafka требовала отдельный ZooKeeper кластер для хранения metadata (топики, партиции, конфигурация). KRaft использует встроенный Raft consensus между контроллерами Kafka. Преимущества: проще операции (нет ZooKeeper), быстрее partition recovery, лучше масштабируется (миллионы партиций). KRaft стал production-ready в Kafka 3.3+, ZooKeeper deprecated.',
  },
  {
    id: 'sd-mq-048',
    block: 'sd',
    topic: 'message-queues',
    topicLabel: 'Очереди сообщений',
    difficulty: 'middle',
    type: 'quiz',
    question: 'Какой паттерн обеспечивает обработку сообщений в рамках временного окна?',
    options: [
      'Partitioning',
      'Windowing (tumbling, sliding, session windows)',
      'Sharding',
      'Batching',
    ],
    correctIndex: 1,
    explanation:
      'Windowing — паттерн stream processing для группировки событий по временным окнам. Типы: Tumbling window — фиксированные непересекающиеся окна (каждые 5 минут). Sliding window — перекрывающиеся окна (5 минут каждую минуту). Session window — окна на основе активности (закрывается после inactivity gap). Hopping window — как sliding, но с фиксированным шагом. Используется для: aggregations (count per minute), joining streams, detecting patterns. Реализации: Kafka Streams, Flink, Spark Streaming.',
  },
  {
    id: 'sd-mq-049',
    block: 'sd',
    topic: 'message-queues',
    topicLabel: 'Очереди сообщений',
    difficulty: 'junior',
    type: 'open',
    question: 'Какие метрики важно мониторить для системы очередей сообщений?',
    sampleAnswer:
      'Ключевые метрики messaging системы: 1) Queue depth / Consumer lag — количество необработанных сообщений. Рост = проблема с потребителями. 2) Throughput — messages/sec для producers и consumers. 3) Latency — время от отправки до обработки (end-to-end), время в очереди. 4) Error rate — failed deliveries, consumer errors, DLQ messages. 5) Consumer group status — количество active consumers, partition assignment. 6) Replication lag (Kafka) — отставание replicas от leader. 7) Disk usage — для persistent queues. 8) Connection count — к брокеру. 9) Message age — возраст старейшего сообщения в очереди. Алерты: lag выше порога, error rate > X%, consumer down, replication lag high. Инструменты: Prometheus + Grafana, встроенные метрики (Kafka JMX, RabbitMQ Management), Datadog, New Relic.',
    explanation:
      'Consumer lag — главная метрика для Kafka. Queue depth — для традиционных очередей. Рост этих метрик — первый признак проблем. Важно настроить алерты до того, как система деградирует критически.',
  },
  {
    id: 'sd-mq-050',
    block: 'sd',
    topic: 'message-queues',
    topicLabel: 'Очереди сообщений',
    difficulty: 'senior',
    type: 'open',
    question: 'Опишите паттерн Saga для распределённых транзакций с использованием очередей сообщений. Как обрабатывать failures?',
    sampleAnswer:
      'Saga — паттерн для распределённых транзакций без 2PC. Бизнес-транзакция разбивается на последовательность локальных транзакций, каждая с компенсирующим действием. Реализация с очередями (Choreography): 1) Каждый сервис, завершив шаг, публикует событие (OrderCreated). 2) Следующий сервис подписан на событие и выполняет свой шаг (ReserveInventory). 3) При ошибке публикуется compensating event (InventoryReservationFailed). 4) Предыдущие сервисы слушают failure events и выполняют rollback (CancelOrder). Orchestration: центральный координатор управляет последовательностью, вызывая сервисы через команды в очередях. Обработка failures: компенсирующие транзакции должны быть idempotent, retry с backoff, timeout для шагов, saga state machine для отслеживания прогресса. Инструменты: Temporal, Camunda, AWS Step Functions, custom implementation с Kafka.',
    explanation:
      'Saga через очереди — надёжнее синхронных вызовов, но сложнее. Choreography проще для небольших saga, orchestration — для сложных с ветвлением. Ключевое: проектировать compensating actions с самого начала, тестировать failure scenarios.',
  },
];
