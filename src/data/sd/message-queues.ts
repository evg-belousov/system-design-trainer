import type { Question } from '../types';

export const messageQueuesQuestions: Question[] = [
  {
    id: 'sd-mq-001',
    block: 'sd',
    topic: 'message-queues',
    topicLabel: 'Очереди сообщений',
    difficulty: 'junior',
    type: 'quiz',
    question: 'Какую основную проблему решают очереди сообщений в распределённых системах?',
    options: [
      'Шифрование данных при передаче между сервисами',
      'Асинхронная коммуникация между сервисами и развязка (decoupling) компонентов',
      'Хранение постоянных данных вместо базы данных',
      'Балансировка нагрузки между серверами',
    ],
    correctIndex: 1,
    explanation:
      'Очереди сообщений (Message Queues) позволяют сервисам обмениваться данными асинхронно: отправитель помещает сообщение в очередь и продолжает работу, не дожидаясь обработки. Это обеспечивает decoupling (развязку) -- сервисы не зависят друг от друга напрямую, что повышает отказоустойчивость и масштабируемость. Также очереди сглаживают пики нагрузки (load leveling): при всплеске запросов сообщения накапливаются в очереди и обрабатываются по мере доступности ресурсов.',
  },
  {
    id: 'sd-mq-002',
    block: 'sd',
    topic: 'message-queues',
    topicLabel: 'Очереди сообщений',
    difficulty: 'middle',
    type: 'quiz',
    question: 'Чем отличается модель «очередь» (Point-to-Point) от модели «публикация-подписка» (Pub/Sub)?',
    options: [
      'В очереди сообщение обрабатывается одним потребителем, в Pub/Sub -- доставляется всем подписчикам',
      'Очередь работает синхронно, Pub/Sub -- асинхронно',
      'Pub/Sub гарантирует порядок сообщений, а очередь -- нет',
      'В очереди нельзя фильтровать сообщения, а в Pub/Sub -- можно',
    ],
    correctIndex: 0,
    explanation:
      'В модели Point-to-Point (очередь) каждое сообщение обрабатывается ровно одним потребителем (consumer). Это подходит для распределения задач: например, обработка заказов, где каждый заказ должен быть обработан один раз. В модели Pub/Sub (публикация-подписка) сообщение доставляется всем подписчикам (subscribers) топика. Это подходит для рассылки событий: например, событие «заказ создан» может получить сервис уведомлений, сервис аналитики и сервис складского учёта.',
  },
  {
    id: 'sd-mq-003',
    block: 'sd',
    topic: 'message-queues',
    topicLabel: 'Очереди сообщений',
    difficulty: 'middle',
    type: 'open',
    question: 'Сравните Apache Kafka и RabbitMQ. В каких сценариях каждый из них предпочтительнее?',
    sampleAnswer:
      'Apache Kafka -- это распределённая платформа потоковой обработки с лог-архитектурой. Сообщения хранятся на диске в упорядоченных логах, потребители читают по смещению (offset). Kafka оптимальна для: потоковой обработки данных, event sourcing, лог-агрегации, высокой пропускной способности (миллионы сообщений/сек), когда нужно хранить историю сообщений и повторно их читать. RabbitMQ -- классический брокер сообщений с поддержкой протокола AMQP. Он обеспечивает гибкую маршрутизацию через exchange (direct, topic, fanout, headers), подтверждение доставки, TTL и dead-letter очереди. RabbitMQ лучше для: традиционных очередей задач, сложной маршрутизации сообщений, когда нужны приоритеты сообщений, когда объём данных умеренный и каждое сообщение обрабатывается один раз.',
    explanation:
      'Kafka и RabbitMQ решают разные задачи, хотя области применения частично пересекаются. Ключевое архитектурное различие: в Kafka потребители управляют своим смещением (pull-модель), в RabbitMQ брокер отправляет сообщения потребителям (push-модель). Kafka лучше подходит для больших данных и потоковой обработки, RabbitMQ -- для микросервисной коммуникации и task queues.',
  },
  {
    id: 'sd-mq-004',
    block: 'sd',
    topic: 'message-queues',
    topicLabel: 'Очереди сообщений',
    difficulty: 'senior',
    type: 'open',
    question: 'Что такое гарантии доставки сообщений (delivery guarantees)? Объясните разницу между at-most-once, at-least-once и exactly-once. Почему exactly-once так сложно реализовать?',
    sampleAnswer:
      'At-most-once: сообщение доставляется не более одного раза. Отправитель не повторяет отправку при ошибке, возможна потеря сообщений. Самая простая и быстрая реализация. Подходит для не критичных данных (метрики, логи). At-least-once: сообщение доставляется хотя бы один раз. Отправитель повторяет отправку до получения подтверждения, возможны дубликаты. Потребитель должен быть идемпотентным. Наиболее распространённая гарантия. Exactly-once: сообщение доставляется ровно один раз. Сложно реализовать, потому что в распределённой системе невозможно атомарно выполнить «получить сообщение + обработать + подтвердить». Любой шаг может упасть. Реализуется через комбинацию: идемпотентный продюсер (Kafka с идемпотентностью), транзакции (Kafka Transactions), дедупликацию на стороне потребителя (по уникальному ID сообщения). На практике «exactly-once» часто означает «at-least-once delivery + idempotent processing».',
    explanation:
      'Exactly-once semantics -- это «святой Грааль» распределённых систем. Теоретически она невозможна в общем случае (по сути, это задача двух генералов). На практике системы вроде Apache Kafka обеспечивают exactly-once в пределах своей экосистемы (Kafka Streams, Kafka Connect), но при взаимодействии с внешними системами приходится полагаться на идемпотентность операций.',
  },
  {
    id: 'sd-mq-005',
    block: 'sd',
    topic: 'message-queues',
    topicLabel: 'Очереди сообщений',
    difficulty: 'junior',
    type: 'quiz',
    question: 'Что такое Dead Letter Queue (DLQ)?',
    options: [
      'Очередь для хранения зашифрованных сообщений',
      'Специальная очередь для сообщений, которые не удалось обработать после нескольких попыток',
      'Очередь с максимальным приоритетом обработки',
      'Временная очередь, удаляемая после обработки всех сообщений',
    ],
    correctIndex: 1,
    explanation:
      'Dead Letter Queue (DLQ) -- это специальная очередь, куда перенаправляются сообщения, которые не удалось успешно обработать после заданного количества попыток. Причины попадания в DLQ: ошибки десериализации, бизнес-валидации, недоступность зависимых сервисов. DLQ позволяет не потерять проблемные сообщения и проанализировать их позже, не блокируя обработку остальных сообщений в основной очереди.',
  },
  {
    id: 'sd-mq-006',
    block: 'sd',
    topic: 'message-queues',
    topicLabel: 'Очереди сообщений',
    difficulty: 'junior',
    type: 'quiz',
    question: 'Что такое producer (продюсер) и consumer (потребитель) в контексте очередей сообщений?',
    options: [
      'Producer — администратор очереди, consumer — мониторинг очереди',
      'Producer — компонент, отправляющий сообщения в очередь, consumer — компонент, читающий и обрабатывающий сообщения из очереди',
      'Producer — создатель очереди, consumer — удаляющий очередь',
      'Producer — шифрует сообщения, consumer — дешифрует',
    ],
    correctIndex: 1,
    explanation:
      'Producer (продюсер, издатель) — это компонент системы, который создаёт и отправляет сообщения в очередь или топик. Consumer (потребитель, подписчик) — компонент, который читает сообщения из очереди и обрабатывает их. Продюсер и потребитель работают независимо (decoupling): продюсер не знает, кто и когда обработает сообщение. Это позволяет масштабировать продюсеров и потребителей независимо, а также обеспечивает устойчивость к временной недоступности одного из компонентов.',
  },
  {
    id: 'sd-mq-007',
    block: 'sd',
    topic: 'message-queues',
    topicLabel: 'Очереди сообщений',
    difficulty: 'junior',
    type: 'quiz',
    question: 'Какое основное преимущество асинхронной коммуникации через очереди сообщений перед синхронными HTTP-вызовами?',
    options: [
      'Асинхронная коммуникация всегда быстрее синхронной',
      'Очереди обеспечивают развязку сервисов, сглаживание пиков нагрузки и отказоустойчивость',
      'Очереди не требуют сетевого соединения',
      'Асинхронная коммуникация проще в отладке',
    ],
    correctIndex: 1,
    explanation:
      'Основные преимущества очередей: 1) Развязка (decoupling) — отправитель не зависит от доступности получателя. 2) Сглаживание пиков (load leveling) — при всплеске нагрузки сообщения буферизуются в очереди и обрабатываются по мере доступности ресурсов. 3) Отказоустойчивость — если потребитель упал, сообщения сохраняются в очереди. 4) Масштабирование — можно добавлять потребителей для увеличения пропускной способности. Недостатки: сложность отладки, eventual consistency, дополнительная инфраструктура.',
  },
  {
    id: 'sd-mq-008',
    block: 'sd',
    topic: 'message-queues',
    topicLabel: 'Очереди сообщений',
    difficulty: 'junior',
    type: 'quiz',
    question: 'Что означает гарантия доставки «at-least-once»?',
    options: [
      'Сообщение гарантированно доставлено ровно один раз',
      'Сообщение доставлено хотя бы один раз, но возможны дубликаты',
      'Сообщение может быть потеряно, но не дублируется',
      'Сообщение доставлено всем подписчикам одновременно',
    ],
    correctIndex: 1,
    explanation:
      'At-least-once — гарантия, что сообщение будет доставлено потребителю хотя бы один раз. Если подтверждение (ack) от потребителя не получено (из-за сбоя сети или потребителя), брокер повторно отправит сообщение. Это может привести к дубликатам, поэтому потребитель должен быть идемпотентным — обработка одного и того же сообщения несколько раз не должна изменять результат. Способы обеспечения идемпотентности: уникальный ID сообщения + таблица обработанных ID, использование UPSERT вместо INSERT.',
  },
  {
    id: 'sd-mq-009',
    block: 'sd',
    topic: 'message-queues',
    topicLabel: 'Очереди сообщений',
    difficulty: 'middle',
    type: 'quiz',
    question: 'Что такое partition (партиция) в Apache Kafka?',
    options: [
      'Раздел для хранения метаданных кластера',
      'Упорядоченная, неизменяемая последовательность сообщений внутри топика, обеспечивающая параллельную обработку',
      'Механизм изоляции топиков друг от друга',
      'Резервная копия топика на другом брокере',
    ],
    correctIndex: 1,
    explanation:
      'Partition (партиция) — основная единица параллелизма в Kafka. Каждый топик разделён на одну или несколько партиций. Партиция — это упорядоченный, append-only лог сообщений. Сообщения в пределах одной партиции строго упорядочены и имеют уникальный offset. Разные партиции могут обрабатываться разными потребителями параллельно. Ключ сообщения определяет, в какую партицию оно попадёт (hash(key) mod num_partitions), что гарантирует порядок для сообщений с одним ключом.',
  },
  {
    id: 'sd-mq-010',
    block: 'sd',
    topic: 'message-queues',
    topicLabel: 'Очереди сообщений',
    difficulty: 'middle',
    type: 'quiz',
    question: 'Что такое consumer group (группа потребителей) в Apache Kafka?',
    options: [
      'Группа топиков, объединённых по бизнес-логике',
      'Набор потребителей, совместно читающих топик, где каждая партиция обрабатывается только одним потребителем из группы',
      'Группа продюсеров, отправляющих сообщения в один топик',
      'Кластер брокеров, обслуживающих одну группу клиентов',
    ],
    correctIndex: 1,
    explanation:
      'Consumer group — это логическая группа потребителей, которые совместно читают топик. Kafka гарантирует, что каждая партиция назначена ровно одному потребителю в группе. Это обеспечивает: 1) Параллельную обработку — каждый потребитель обрабатывает свои партиции. 2) Масштабирование — добавление потребителей увеличивает пропускную способность (до количества партиций). 3) Отказоустойчивость — при падении потребителя его партиции автоматически перераспределяются (rebalancing). Разные consumer group-ы читают данные независимо — каждая получает все сообщения (паттерн pub/sub).',
  },
  {
    id: 'sd-mq-011',
    block: 'sd',
    topic: 'message-queues',
    topicLabel: 'Очереди сообщений',
    difficulty: 'middle',
    type: 'open',
    question: 'Какие типы exchange существуют в RabbitMQ и чем они отличаются? Приведите практические примеры использования каждого типа.',
    sampleAnswer:
      'Exchange в RabbitMQ — это компонент, который получает сообщения от продюсера и маршрутизирует их в очереди по определённым правилам. Типы exchange: 1) Direct — маршрутизация по точному совпадению routing key. Сообщение с routing key "order.created" попадёт только в очереди, привязанные с тем же ключом. Пример: распределение задач по типу (email-очередь, sms-очередь). 2) Fanout — сообщение копируется во все привязанные очереди, routing key игнорируется. Пример: рассылка уведомлений всем подсистемам (аналитика, логирование, мониторинг). 3) Topic — маршрутизация по шаблону routing key с wildcards (* — одно слово, # — ноль или более слов). Ключ "order.eu.created" совпадёт с "order.*.created" и "order.#". Пример: региональная обработка заказов. 4) Headers — маршрутизация по заголовкам сообщения, а не по routing key. Пример: фильтрация по формату данных (JSON vs XML) или приоритету.',
    explanation:
      'Exchange-модель RabbitMQ обеспечивает гибкую маршрутизацию, которой нет в Kafka (где маршрутизация идёт только по топику и партиции). Это преимущество RabbitMQ для сценариев сложной маршрутизации. На практике чаще всего используются Direct (для point-to-point) и Topic (для pub/sub с фильтрацией) exchange-ы.',
  },
  {
    id: 'sd-mq-012',
    block: 'sd',
    topic: 'message-queues',
    topicLabel: 'Очереди сообщений',
    difficulty: 'middle',
    type: 'quiz',
    question: 'Что такое offset в Apache Kafka?',
    options: [
      'Временная задержка между отправкой и получением сообщения',
      'Уникальный последовательный номер сообщения в партиции, по которому потребитель отслеживает свою позицию чтения',
      'Расстояние между продюсером и потребителем в сети',
      'Количество пропущенных сообщений при ошибке',
    ],
    correctIndex: 1,
    explanation:
      'Offset — это уникальный последовательный номер (0, 1, 2, ...), присваиваемый каждому сообщению в партиции. Потребитель отслеживает свой текущий offset для каждой партиции — это его «закладка» в логе. Kafka не удаляет сообщения после прочтения (в отличие от традиционных очередей) — они хранятся до истечения retention period. Это позволяет: перечитывать сообщения (replay), нескольким consumer group-ам читать независимо, восстанавливаться после сбоев. Offset-ы коммитятся (сохраняются) потребителем в Kafka (__consumer_offsets topic) или во внешнее хранилище.',
  },
  {
    id: 'sd-mq-013',
    block: 'sd',
    topic: 'message-queues',
    topicLabel: 'Очереди сообщений',
    difficulty: 'middle',
    type: 'quiz',
    question: 'Как обеспечить порядок обработки сообщений в распределённой системе с очередью?',
    options: [
      'Порядок гарантируется автоматически в любой конфигурации',
      'Использовать одну партицию/очередь, но это ограничивает пропускную способность',
      'Отправлять сообщения с одинаковым ключом, чтобы они попадали в одну партицию — порядок гарантируется в пределах партиции',
      'Порядок невозможно гарантировать в распределённой системе',
    ],
    correctIndex: 2,
    explanation:
      'В Kafka порядок сообщений гарантируется только в пределах одной партиции. Чтобы обеспечить порядок для связанных сообщений (например, все события одного заказа), нужно отправлять их с одним ключом (order_id) — тогда они попадут в одну партицию. Это позволяет масштабировать обработку (много партиций), сохраняя порядок для логически связанных сообщений. Глобальный порядок всех сообщений требует одной партиции, что ограничивает параллелизм. В RabbitMQ порядок гарантируется в пределах одной очереди при одном потребителе.',
  },
  {
    id: 'sd-mq-014',
    block: 'sd',
    topic: 'message-queues',
    topicLabel: 'Очереди сообщений',
    difficulty: 'senior',
    type: 'open',
    question: 'Что такое backpressure в системах обмена сообщениями и как её реализовать? Какие последствия отсутствия backpressure?',
    sampleAnswer:
      'Backpressure (обратное давление) — механизм, при котором потребитель или брокер сигнализирует продюсеру о необходимости замедлить отправку сообщений, чтобы не перегрузить систему. Без backpressure продюсер может отправлять сообщения быстрее, чем потребитель их обрабатывает, что приводит к: переполнению очереди (OOM), росту задержки обработки, потере сообщений, каскадным отказам. Реализация: 1) Ограничение размера очереди — при заполнении брокер отклоняет новые сообщения (RabbitMQ: x-max-length policy, Kafka: producer получает ошибку при полном буфере). 2) Rate limiting на продюсере — ограничение скорости отправки (Kafka: max.in.flight.requests.per.connection, linger.ms). 3) Credit-based flow control — RabbitMQ использует TCP credit flow для ограничения скорости продюсера. 4) Consumer-side throttling — потребитель контролирует скорость чтения (Kafka pull-модель). 5) Prefetch limit — ограничение количества неподтверждённых сообщений (RabbitMQ: prefetch count). 6) Мониторинг lag — алертинг при росте отставания потребителя (Kafka consumer lag).',
    explanation:
      'Backpressure — критический механизм для production-систем. Без него любая разница в скорости между продюсером и потребителем неизбежно приведёт к проблемам. Kafka по дизайну обеспечивает естественный backpressure через pull-модель: потребитель сам определяет скорость чтения. RabbitMQ использует push-модель, поэтому backpressure реализуется через prefetch и credit flow.',
  },
  {
    id: 'sd-mq-015',
    block: 'sd',
    topic: 'message-queues',
    topicLabel: 'Очереди сообщений',
    difficulty: 'senior',
    type: 'quiz',
    question: 'Какой формат сериализации обеспечивает наилучшую производительность и поддержку эволюции схемы для сообщений в Kafka?',
    options: [
      'JSON — универсальный и читаемый формат',
      'XML — стандарт для enterprise-систем',
      'Apache Avro с Schema Registry — компактный бинарный формат с управлением версиями схемы',
      'Plain Text — простейший формат',
    ],
    correctIndex: 2,
    explanation:
      'Apache Avro в сочетании с Confluent Schema Registry — рекомендуемый подход для Kafka. Avro обеспечивает: компактную бинарную сериализацию (меньше трафика и хранения, чем JSON), эволюцию схемы (backward/forward compatibility — можно добавлять/удалять поля без поломки потребителей), строгую типизацию. Schema Registry хранит и версионирует схемы, проверяя совместимость при регистрации новых версий. Альтернативы: Protocol Buffers (Google, популярен в gRPC), Thrift (Facebook), MessagePack. JSON проще для отладки, но менее эффективен и не поддерживает нативную эволюцию схемы.',
  },
  {
    id: 'sd-mq-016',
    block: 'sd',
    topic: 'message-queues',
    topicLabel: 'Очереди сообщений',
    difficulty: 'senior',
    type: 'open',
    question: 'Как Kafka обеспечивает exactly-once семантику через идемпотентного продюсера и транзакции? Какие ограничения существуют?',
    sampleAnswer:
      'Kafka реализует exactly-once через два механизма: 1) Идемпотентный продюсер (enable.idempotence=true): Kafka присваивает каждому продюсеру Producer ID (PID) и каждому сообщению Sequence Number. Брокер отслеживает последний sequence number для каждого PID и партиции, отклоняя дубликаты при повторной отправке. Это обеспечивает exactly-once для одного продюсера в одну партицию. 2) Транзакции (Kafka Transactions): продюсер может атомарно записать сообщения в несколько партиций/топиков и закоммитить offset потребителя — либо все записи применяются, либо ни одна. Потребитель с isolation.level=read_committed видит только закоммиченные сообщения. Ограничения: exactly-once работает только в рамках экосистемы Kafka (Kafka → Kafka). При взаимодействии с внешними системами (БД, HTTP API) нужна дополнительная идемпотентность. Транзакции увеличивают задержку и снижают пропускную способность. Максимальное количество партиций в одной транзакции ограничено.',
    explanation:
      'Exactly-once в Kafka — это инженерное достижение, но важно понимать его границы. Оно работает для паттерна «read-process-write» внутри Kafka (Kafka Streams). Для внешних систем (запись в PostgreSQL, отправка HTTP) нужен Transactional Outbox Pattern или идемпотентные операции. На практике большинство систем используют at-least-once + idempotency как более простой и надёжный подход.',
  },
  {
    id: 'sd-mq-017',
    block: 'sd',
    topic: 'message-queues',
    topicLabel: 'Очереди сообщений',
    difficulty: 'junior',
    type: 'quiz',
    question: 'Что такое acknowledgement (ack) при обработке сообщений?',
    options: [
      'Шифрование сообщения перед отправкой',
      'Подтверждение от потребителя брокеру, что сообщение успешно обработано',
      'Проверка целостности сообщения при передаче',
      'Запись лога о получении сообщения',
    ],
    correctIndex: 1,
    explanation:
      'Acknowledgement (ack, подтверждение) — это сигнал от потребителя брокеру о том, что сообщение было успешно получено и обработано. После получения ack брокер удаляет сообщение из очереди (в RabbitMQ) или фиксирует offset (в Kafka). Если ack не получен (потребитель упал), брокер считает сообщение необработанным и доставит его повторно (другому потребителю или тому же после восстановления). Важно отправлять ack только после полной обработки, иначе сообщение может быть потеряно. Auto-ack (подтверждение сразу при получении) быстрее, но рискует потерей данных.',
  },
  {
    id: 'sd-mq-018',
    block: 'sd',
    topic: 'message-queues',
    topicLabel: 'Очереди сообщений',
    difficulty: 'middle',
    type: 'open',
    question: 'Что такое паттерн Transactional Outbox и какую проблему он решает при работе с очередями сообщений?',
    sampleAnswer:
      'Transactional Outbox решает проблему атомарности операции «обновить БД + отправить сообщение в очередь». Проблема: при обновлении заказа нужно сохранить изменения в БД и отправить событие в Kafka. Если сохранить в БД и затем отправить в Kafka — при падении между шагами данные обновлены, но событие потеряно. Если сначала отправить в Kafka — событие отправлено, но БД не обновлена. Решение Transactional Outbox: 1) Сервис записывает бизнес-данные И событие в таблицу outbox в одной БД-транзакции. 2) Отдельный процесс (relay/poller) читает новые записи из outbox и отправляет их в Kafka. 3) После успешной отправки помечает запись как обработанную. Альтернатива — Change Data Capture (CDC): инструмент вроде Debezium читает WAL базы данных и публикует изменения в Kafka, включая записи outbox таблицы. CDC надёжнее polling-а и не нагружает БД дополнительными запросами.',
    explanation:
      'Transactional Outbox — один из важнейших паттернов в событийно-ориентированных архитектурах. Без него невозможно гарантировать консистентность между базой данных и очередью сообщений. Debezium + Kafka Connect — популярная реализация CDC-подхода. Паттерн особенно важен при использовании Database per Service, где нельзя использовать распределённые транзакции.',
  },
  {
    id: 'sd-mq-019',
    block: 'sd',
    topic: 'message-queues',
    topicLabel: 'Очереди сообщений',
    difficulty: 'senior',
    type: 'quiz',
    question: 'Как Kafka обеспечивает высокую доступность данных при отказе брокера?',
    options: [
      'Данные хранятся только в памяти и не переживают отказ',
      'Через репликацию партиций — каждая партиция имеет leader и несколько follower-реплик на разных брокерах',
      'Через автоматическое резервное копирование в облачное хранилище',
      'Через зеркалирование всего кластера на резервный дата-центр',
    ],
    correctIndex: 1,
    explanation:
      'Kafka реплицирует данные через механизм In-Sync Replicas (ISR). Каждая партиция имеет одного leader-а (обслуживает чтение и запись) и несколько follower-реплик на других брокерах. Follower-ы синхронно или асинхронно реплицируют данные с leader-а. ISR — множество реплик, которые «догнали» leader-а. При настройке acks=all продюсер получает подтверждение только после записи на все ISR-реплики. При отказе leader-а контроллер кластера автоматически выбирает нового leader-а из ISR. Параметры min.insync.replicas и acks определяют баланс между durability и производительностью.',
  },
  {
    id: 'sd-mq-020',
    block: 'sd',
    topic: 'message-queues',
    topicLabel: 'Очереди сообщений',
    difficulty: 'senior',
    type: 'open',
    question: 'Опишите архитектуру обработки событий с использованием Event Sourcing и Kafka. Какие преимущества и сложности создаёт этот подход?',
    sampleAnswer:
      'Event Sourcing — паттерн, при котором состояние системы определяется последовательностью событий (event log), а не текущим снимком. Kafka идеально подходит как event store благодаря: append-only логу, долгосрочному хранению (retention), replay возможности, упорядоченности в пределах партиции. Архитектура: 1) Команда (Command) валидируется и создаёт событие (Event). 2) Событие записывается в Kafka топик (event store). 3) Проекции (read models) строятся из потока событий для разных представлений: одна проекция в PostgreSQL для запросов, другая в Elasticsearch для поиска, третья в Redis для кэша. 4) При сбое проекция перестраивается из Kafka (replay). Преимущества: полная история изменений (audit log), возможность восстановить любое прошлое состояние, естественная интеграция с CQRS, temporal queries. Сложности: eventual consistency, сложность обработки ошибок (компенсирующие события вместо DELETE/UPDATE), рост объёма данных (compaction помогает частично), сложность миграции схемы событий, крутая кривая обучения.',
    explanation:
      'Event Sourcing + Kafka — мощная комбинация, но подходит не для всех систем. Она оправдана для: финансовых систем (аудит всех транзакций), систем с конкурентными обновлениями (CRDTs, collaborative editing), аналитических платформ. Для простых CRUD-приложений Event Sourcing избыточен. Важно помнить: Kafka не является полноценным event store (нет поддержки optimistic concurrency), для этого существуют специализированные решения вроде EventStoreDB.',
  },
];
