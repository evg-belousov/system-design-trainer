import type { Question } from '../types';

export const scalabilityQuestions: Question[] = [
  {
    id: 'sd-scalability-001',
    block: 'sd',
    topic: 'scalability',
    topicLabel: 'Масштабируемость',
    difficulty: 'junior',
    type: 'quiz',
    question: 'Что такое вертикальное масштабирование (Scale Up)?',
    options: [
      'Добавление новых серверов в кластер для распределения нагрузки',
      'Увеличение ресурсов (CPU, RAM, диск) существующего сервера',
      'Разделение базы данных на несколько шардов',
      'Использование CDN для раздачи статического контента',
    ],
    correctIndex: 1,
    explanation:
      'Вертикальное масштабирование (Scale Up) -- это увеличение мощности одного сервера: добавление процессорных ядер, оперативной памяти, более быстрых дисков. Это самый простой способ масштабирования, но он имеет физический предел -- нельзя бесконечно наращивать ресурсы одной машины. Кроме того, вертикальное масштабирование создаёт единую точку отказа (Single Point of Failure).',
  },
  {
    id: 'sd-scalability-002',
    block: 'sd',
    topic: 'scalability',
    topicLabel: 'Масштабируемость',
    difficulty: 'junior',
    type: 'quiz',
    question: 'Чем горизонтальное масштабирование отличается от вертикального?',
    options: [
      'Горизонтальное масштабирование дешевле вертикального во всех случаях',
      'Горизонтальное масштабирование предполагает добавление новых серверов, а вертикальное -- увеличение ресурсов существующего',
      'Вертикальное масштабирование требует балансировщика нагрузки, а горизонтальное -- нет',
      'Горизонтальное масштабирование применяется только для баз данных',
    ],
    correctIndex: 1,
    explanation:
      'Горизонтальное масштабирование (Scale Out) -- это добавление новых серверов (нод) в систему для распределения нагрузки. В отличие от вертикального масштабирования, оно теоретически не имеет верхнего предела и обеспечивает отказоустойчивость. Однако горизонтальное масштабирование требует более сложной архитектуры: балансировки нагрузки, синхронизации данных, управления состоянием сессий и т.д.',
  },
  {
    id: 'sd-scalability-003',
    block: 'sd',
    topic: 'scalability',
    topicLabel: 'Масштабируемость',
    difficulty: 'middle',
    type: 'open',
    question: 'Объясните, что такое шардирование (sharding) базы данных и какие стратегии выбора ключа шардирования существуют. Какие проблемы может вызвать неправильный выбор ключа?',
    sampleAnswer:
      'Шардирование -- это разделение данных одной базы на несколько независимых частей (шардов), каждая из которых хранится на отдельном сервере. Основные стратегии: 1) На основе диапазона (range-based) -- данные делятся по диапазонам ключей (например, пользователи A-M на шарде 1, N-Z на шарде 2). Просто реализуется, но может приводить к неравномерному распределению. 2) На основе хэша (hash-based) -- хэш-функция от ключа определяет шард. Обеспечивает равномерное распределение, но усложняет range-запросы. 3) На основе директории (directory-based) -- отдельный сервис хранит маппинг ключей на шарды. Гибкий подход, но директория становится узким местом. Неправильный выбор ключа может привести к «горячим шардам» (hotspots), когда один шард получает непропорционально большую нагрузку, сводя на нет преимущества шардирования.',
    explanation:
      'Шардирование -- ключевая техника горизонтального масштабирования баз данных. Правильный выбор ключа шардирования критически важен: он должен обеспечивать равномерное распределение данных и запросов, минимизировать cross-shard запросы и учитывать паттерны доступа к данным. Например, шардирование по user_id хорошо работает для данных, привязанных к пользователю, но плохо для глобальных аналитических запросов.',
  },
  {
    id: 'sd-scalability-004',
    block: 'sd',
    topic: 'scalability',
    topicLabel: 'Масштабируемость',
    difficulty: 'senior',
    type: 'open',
    question: 'Вы проектируете систему, которая должна обрабатывать 1 миллион запросов в секунду. Опишите стратегию масштабирования на уровне приложения, данных и инфраструктуры. Какие компромиссы вам придётся принять?',
    sampleAnswer:
      'Для обработки 1M RPS потребуется комплексный подход: 1) Уровень приложения: stateless-сервисы за L7 балансировщиком, автоскейлинг на основе метрик (CPU, latency), асинхронная обработка через очереди для не-критичных операций. 2) Уровень данных: агрессивное кэширование (Redis/Memcached) для горячих данных, шардирование БД, read-реплики для чтения, CQRS для разделения чтения и записи, денормализация данных для уменьшения JOIN-ов. 3) Инфраструктура: мульти-регионное развёртывание, CDN для статики, DNS-балансировка между регионами, circuit breakers для защиты от каскадных отказов. Компромиссы: eventual consistency вместо strong consistency, увеличение операционной сложности, стоимость инфраструктуры, сложность отладки распределённой системы, необходимость idempotent-операций.',
    explanation:
      'Масштабирование до 1M RPS -- это задача, требующая системного подхода. Нельзя просто добавить серверов: нужно устранить все узкие места на каждом уровне архитектуры. Ключевые принципы: кэшировать как можно больше, делать обработку асинхронной где возможно, избегать shared state, проектировать для отказов (design for failure). На практике большинство систем такого масштаба используют eventual consistency и разделение на горячий/холодный пути обработки данных.',
  },
  {
    id: 'sd-scalability-005',
    block: 'sd',
    topic: 'scalability',
    topicLabel: 'Масштабируемость',
    difficulty: 'middle',
    type: 'quiz',
    question: 'Что означает закон Амдала в контексте масштабируемости системы?',
    options: [
      'Производительность системы линейно растёт с добавлением серверов',
      'Ускорение системы ограничено долей последовательной (не параллелизуемой) части обработки',
      'Удвоение ресурсов всегда приводит к удвоению производительности',
      'Стоимость масштабирования растёт логарифмически',
    ],
    correctIndex: 1,
    explanation:
      'Закон Амдала утверждает, что максимальное ускорение системы при распараллеливании ограничено долей последовательного кода. Если 10% обработки запроса нельзя распараллелить, то максимальное ускорение не превысит 10x, сколько бы серверов вы ни добавили. Это фундаментальный принцип, который объясняет, почему при масштабировании важно выявлять и оптимизировать узкие места (bottlenecks), а не просто добавлять ресурсы.',
  },
  {
    id: 'sd-scalability-006',
    block: 'sd',
    topic: 'scalability',
    topicLabel: 'Масштабируемость',
    difficulty: 'junior',
    type: 'quiz',
    question: 'Что такое stateless-сервис и почему он упрощает горизонтальное масштабирование?',
    options: [
      'Сервис без базы данных — все данные хранятся в памяти',
      'Сервис, не хранящий состояние сессии между запросами, что позволяет направить любой запрос на любой экземпляр',
      'Сервис, работающий только с GET-запросами',
      'Сервис, который не использует внешние зависимости',
    ],
    correctIndex: 1,
    explanation:
      'Stateless-сервис не хранит состояние клиентской сессии между запросами. Каждый запрос содержит всю необходимую информацию для обработки (например, через JWT-токен). Это упрощает горизонтальное масштабирование, потому что любой экземпляр сервиса может обработать любой запрос — не нужно привязывать клиента к конкретному серверу (sticky sessions). Состояние при необходимости выносится в внешние хранилища (Redis, база данных).',
  },
  {
    id: 'sd-scalability-007',
    block: 'sd',
    topic: 'scalability',
    topicLabel: 'Масштабируемость',
    difficulty: 'junior',
    type: 'quiz',
    question: 'Какой из следующих компонентов чаще всего становится узким местом (bottleneck) при масштабировании веб-приложения?',
    options: [
      'DNS-сервер',
      'CDN для статических файлов',
      'Реляционная база данных',
      'Балансировщик нагрузки',
    ],
    correctIndex: 2,
    explanation:
      'Реляционная база данных чаще всего становится узким местом при масштабировании, потому что: 1) горизонтальное масштабирование БД значительно сложнее, чем масштабирование stateless-сервисов; 2) ACID-транзакции и блокировки ограничивают параллелизм; 3) JOIN-операции и сложные запросы потребляют много ресурсов; 4) данные должны быть консистентными, что ограничивает возможности распределения. Поэтому большинство стратегий масштабирования начинается с кэширования, read-реплик и денормализации данных.',
  },
  {
    id: 'sd-scalability-008',
    block: 'sd',
    topic: 'scalability',
    topicLabel: 'Масштабируемость',
    difficulty: 'junior',
    type: 'quiz',
    question: 'Что такое auto-scaling в контексте облачной инфраструктуры?',
    options: [
      'Автоматическое обновление программного обеспечения на серверах',
      'Автоматическое увеличение или уменьшение количества экземпляров сервиса в зависимости от текущей нагрузки',
      'Автоматическое резервное копирование данных',
      'Автоматическая балансировка данных между шардами',
    ],
    correctIndex: 1,
    explanation:
      'Auto-scaling — это механизм облачных платформ (AWS Auto Scaling, Kubernetes HPA), который автоматически изменяет количество экземпляров сервиса на основе метрик: загрузки CPU, количества запросов, длины очереди и т.д. При росте нагрузки добавляются новые экземпляры (scale out), при снижении — лишние удаляются (scale in). Это позволяет оптимизировать стоимость инфраструктуры и обеспечить адекватную производительность.',
  },
  {
    id: 'sd-scalability-009',
    block: 'sd',
    topic: 'scalability',
    topicLabel: 'Масштабируемость',
    difficulty: 'middle',
    type: 'quiz',
    question: 'Какая метрика НЕ является типичным триггером для auto-scaling политик?',
    options: [
      'Средняя загрузка CPU выше 70%',
      'Количество запросов в секунду (RPS)',
      'Размер исходного кода приложения',
      'Средняя задержка ответа (latency) выше порогового значения',
    ],
    correctIndex: 2,
    explanation:
      'Размер исходного кода не имеет отношения к auto-scaling. Типичные метрики для триггеров auto-scaling: загрузка CPU, использование памяти, количество запросов (RPS), задержка ответов (latency), длина очереди сообщений, количество активных соединений. Важно выбирать метрику, которая коррелирует с реальной нагрузкой на сервис, и правильно настраивать пороги и cooldown-период для предотвращения «дребезга» (thrashing) — частого добавления и удаления экземпляров.',
  },
  {
    id: 'sd-scalability-010',
    block: 'sd',
    topic: 'scalability',
    topicLabel: 'Масштабируемость',
    difficulty: 'middle',
    type: 'quiz',
    question: 'Чем отличается масштабируемость (scalability) от эластичности (elasticity)?',
    options: [
      'Это синонимы, разницы нет',
      'Масштабируемость — способность системы справляться с ростом нагрузки, эластичность — способность автоматически адаптировать ресурсы к текущей нагрузке в реальном времени',
      'Эластичность применяется только к базам данных',
      'Масштабируемость работает только вертикально, эластичность — горизонтально',
    ],
    correctIndex: 1,
    explanation:
      'Масштабируемость (scalability) — это способность системы обрабатывать растущую нагрузку за счёт добавления ресурсов. Эластичность (elasticity) — это способность системы автоматически выделять и освобождать ресурсы в соответствии с текущей нагрузкой. Эластичная система не только масштабируется вверх при пиках, но и сжимается при спаде, оптимизируя затраты. Например, интернет-магазин может быть масштабируемым (выдерживает Black Friday), а эластичным он станет, если автоматически добавляет серверы к распродаже и убирает после неё.',
  },
  {
    id: 'sd-scalability-011',
    block: 'sd',
    topic: 'scalability',
    topicLabel: 'Масштабируемость',
    difficulty: 'middle',
    type: 'open',
    question: 'Что такое capacity planning (планирование ёмкости)? Какие шаги необходимо выполнить для оценки ресурсов, необходимых системе?',
    sampleAnswer:
      'Capacity planning — это процесс определения необходимых ресурсов для обеспечения заданного уровня производительности. Основные шаги: 1) Определить ключевые метрики (RPS, пропускная способность, latency SLA). 2) Оценить текущую и прогнозируемую нагрузку (рост пользователей, сезонные пики). 3) Провести нагрузочное тестирование для определения пропускной способности одного экземпляра. 4) Рассчитать количество экземпляров: required_instances = peak_RPS / single_instance_RPS * safety_factor. 5) Учесть запас на отказоустойчивость (N+2 redundancy). 6) Спланировать ресурсы для зависимостей (БД, кэш, очереди). 7) Пересматривать план регулярно на основе реальных данных мониторинга.',
    explanation:
      'Capacity planning предотвращает ситуации, когда система не выдерживает нагрузку (under-provisioning) или когда ресурсы простаивают (over-provisioning). Обычно закладывают safety margin в 30-50% сверх расчётной нагрузки. Важно учитывать не только средние значения, но и пиковые нагрузки (P99). В облачных средах auto-scaling частично решает проблему, но capacity planning всё равно необходим для бюджетирования и определения архитектурных ограничений.',
  },
  {
    id: 'sd-scalability-012',
    block: 'sd',
    topic: 'scalability',
    topicLabel: 'Масштабируемость',
    difficulty: 'middle',
    type: 'quiz',
    question: 'Какое основное преимущество read-реплик базы данных для масштабирования?',
    options: [
      'Увеличение скорости записи данных',
      'Распределение нагрузки чтения между несколькими копиями БД',
      'Автоматическое шардирование данных',
      'Устранение необходимости в кэшировании',
    ],
    correctIndex: 1,
    explanation:
      'Read-реплики — это копии основной базы данных, которые асинхронно получают обновления от master-узла и обслуживают запросы на чтение. Поскольку большинство приложений имеют соотношение чтения к записи 80/20 или выше, read-реплики позволяют значительно увеличить пропускную способность системы. Однако из-за асинхронной репликации данные на репликах могут быть слегка устаревшими (replication lag), что нужно учитывать при проектировании.',
  },
  {
    id: 'sd-scalability-013',
    block: 'sd',
    topic: 'scalability',
    topicLabel: 'Масштабируемость',
    difficulty: 'middle',
    type: 'open',
    question: 'Опишите основные компромиссы (trade-offs) между вертикальным и горизонтальным масштабированием. В каких ситуациях вертикальное масштабирование может быть предпочтительнее?',
    sampleAnswer:
      'Вертикальное масштабирование: преимущества — простота (не нужно менять архитектуру), нет проблем с распределённой координацией, транзакции и консистентность данных работают «из коробки». Недостатки — физический предел ресурсов одной машины, единая точка отказа, стоимость растёт нелинейно (мощный сервер стоит непропорционально дороже). Горизонтальное масштабирование: преимущества — теоретически неограниченный рост, отказоустойчивость, использование commodity-серверов. Недостатки — сложность архитектуры, необходимость stateless-дизайна, проблемы с распределёнными транзакциями и консистентностью. Вертикальное масштабирование предпочтительнее: на ранних стадиях проекта (проще и быстрее), для монолитных приложений с сильными внутренними связями, для баз данных с интенсивной транзакционной нагрузкой, когда текущая машина далека от предела своих ресурсов.',
    explanation:
      'На практике большинство систем начинают с вертикального масштабирования (проще) и переходят к горизонтальному по мере роста. Многие компании успешно работают на вертикальном масштабировании дольше, чем ожидают: Stack Overflow долгое время обслуживал миллионы пользователей с двух серверов. Преждевременная оптимизация под горизонтальное масштабирование может усложнить систему без реальной необходимости.',
  },
  {
    id: 'sd-scalability-014',
    block: 'sd',
    topic: 'scalability',
    topicLabel: 'Масштабируемость',
    difficulty: 'senior',
    type: 'quiz',
    question: 'Что такое consistent hashing и какую проблему он решает при масштабировании распределённых систем?',
    options: [
      'Алгоритм шифрования данных для безопасной передачи между узлами',
      'Способ распределения данных по узлам, минимизирующий перераспределение при добавлении или удалении узлов',
      'Метод проверки целостности данных в распределённом кэше',
      'Протокол достижения консенсуса между узлами кластера',
    ],
    correctIndex: 1,
    explanation:
      'Consistent hashing решает проблему массового перераспределения данных при изменении количества узлов. В обычном хэшировании (key % N) при добавлении или удалении узла почти все ключи перемещаются. В consistent hashing узлы и ключи отображаются на кольцо (hash ring), и при изменении количества узлов перемещается только ~1/N часть ключей. Это критически важно для распределённых кэшей (Memcached), хранилищ (DynamoDB, Cassandra) и систем доставки контента. Виртуальные узлы (vnodes) обеспечивают более равномерное распределение нагрузки.',
  },
  {
    id: 'sd-scalability-015',
    block: 'sd',
    topic: 'scalability',
    topicLabel: 'Масштабируемость',
    difficulty: 'senior',
    type: 'open',
    question: 'Объясните концепцию backpressure в масштабируемых системах. Как она помогает предотвратить каскадные отказы?',
    sampleAnswer:
      'Backpressure — это механизм обратного давления, при котором перегруженный компонент системы сигнализирует вышестоящим компонентам о необходимости снизить скорость отправки данных. Без backpressure быстрый продюсер может перегрузить медленного потребителя, вызвав OOM, рост задержек и каскадные отказы. Способы реализации: 1) Ограничение размера очереди — при заполнении буфера продюсер блокируется или получает ошибку. 2) Rate limiting — ограничение количества запросов в единицу времени. 3) Credit-based flow control — потребитель выдаёт «кредиты» продюсеру, определяя сколько сообщений он может принять. 4) Reactive Streams — стандарт асинхронной потоковой обработки с backpressure (реализации: Project Reactor, RxJava, Akka Streams). 5) Circuit breaker — размыкание «цепи» при обнаружении перегрузки. Backpressure помогает предотвратить каскадные отказы, обеспечивая graceful degradation вместо полного падения.',
    explanation:
      'Backpressure — один из ключевых механизмов устойчивости в распределённых системах. Без него система ведёт себя как цепочка: если одно звено замедляется, запросы копятся, потребление памяти растёт, и система падает целиком. С backpressure система деградирует плавно — сбрасывает лишнюю нагрузку на входе, а не позволяет ей проникать вглубь.',
  },
  {
    id: 'sd-scalability-016',
    block: 'sd',
    topic: 'scalability',
    topicLabel: 'Масштабируемость',
    difficulty: 'senior',
    type: 'quiz',
    question: 'Какой паттерн позволяет разделить модели чтения и записи данных для независимого масштабирования?',
    options: [
      'Saga',
      'CQRS (Command Query Responsibility Segregation)',
      'Circuit Breaker',
      'Service Mesh',
    ],
    correctIndex: 1,
    explanation:
      'CQRS (Command Query Responsibility Segregation) разделяет систему на две части: команды (запись/изменение данных) и запросы (чтение данных). Это позволяет независимо масштабировать чтение и запись, использовать разные модели данных и хранилища для каждой стороны. Например, запись может идти в нормализованную PostgreSQL, а чтение — из денормализованного Elasticsearch. Данные между сторонами синхронизируются через события. CQRS особенно полезен в системах с сильным дисбалансом между чтением и записью.',
  },
  {
    id: 'sd-scalability-017',
    block: 'sd',
    topic: 'scalability',
    topicLabel: 'Масштабируемость',
    difficulty: 'senior',
    type: 'open',
    question: 'Как масштабировать WebSocket-соединения в системе с миллионами одновременных подключений? Какие архитектурные решения необходимы?',
    sampleAnswer:
      'Масштабирование WebSocket-соединений — сложная задача, потому что каждое соединение является stateful (привязано к конкретному серверу). Архитектурные решения: 1) Sticky sessions на балансировщике — направлять клиента на тот же сервер, где установлено его соединение. 2) Pub/Sub для межсерверной коммуникации — если пользователь A подключён к серверу 1, а сообщение пришло на сервер 2, Redis Pub/Sub или Kafka доставят его на нужный сервер. 3) Connection-aware routing — хранить маппинг user → server в Redis для маршрутизации целевых сообщений. 4) Оптимизация ресурсов — использовать epoll/kqueue для обработки множества соединений одним потоком (C10K problem), тюнинг лимитов файловых дескрипторов ОС. 5) Горизонтальное разделение — шардирование пользователей по серверам (например, по chat room или geographic region). 6) Fallback на long polling — для клиентов, не поддерживающих WebSocket.',
    explanation:
      'Системы реального времени вроде Discord (миллионы одновременных пользователей) используют комбинацию этих подходов. Discord, например, разделяет пользователей по гильдиям, каждая гильдия обслуживается определённым сервером. Ключевой принцип — минимизировать cross-server коммуникацию за счёт умного шардирования.',
  },
  {
    id: 'sd-scalability-018',
    block: 'sd',
    topic: 'scalability',
    topicLabel: 'Масштабируемость',
    difficulty: 'junior',
    type: 'quiz',
    question: 'Что такое CDN и как она помогает масштабированию?',
    options: [
      'Централизованная база данных для хранения пользовательских данных',
      'Сеть распределённых серверов, доставляющих контент с ближайшего к пользователю узла',
      'Специальный протокол для шифрования трафика',
      'Инструмент мониторинга производительности серверов',
    ],
    correctIndex: 1,
    explanation:
      'CDN (Content Delivery Network) — это географически распределённая сеть серверов, которая кэширует и отдаёт контент (изображения, JS/CSS, видео) с узла, ближайшего к пользователю. CDN помогает масштабированию, снижая нагрузку на origin-серверы (основные серверы приложения) и уменьшая задержку для конечных пользователей. Популярные CDN: CloudFlare, AWS CloudFront, Akamai. Современные CDN также поддерживают edge computing — выполнение логики на периферийных узлах.',
  },
  {
    id: 'sd-scalability-019',
    block: 'sd',
    topic: 'scalability',
    topicLabel: 'Масштабируемость',
    difficulty: 'middle',
    type: 'quiz',
    question: 'Какой подход к масштабированию базы данных предполагает разделение данных одной таблицы по строкам между несколькими серверами?',
    options: [
      'Вертикальное партиционирование',
      'Горизонтальное партиционирование (шардирование)',
      'Репликация master-slave',
      'Денормализация',
    ],
    correctIndex: 1,
    explanation:
      'Горизонтальное партиционирование (шардирование) разделяет строки одной таблицы между несколькими серверами по ключу шардирования. Например, пользователи с ID 1-1000000 на шарде 1, 1000001-2000000 на шарде 2. Вертикальное партиционирование, напротив, разделяет таблицу по столбцам (разные группы столбцов на разных серверах). Шардирование позволяет масштабировать и чтение, и запись, но усложняет cross-shard запросы и транзакции.',
  },
  {
    id: 'sd-scalability-020',
    block: 'sd',
    topic: 'scalability',
    topicLabel: 'Масштабируемость',
    difficulty: 'senior',
    type: 'open',
    question: 'Объясните, как работает паттерн «Cell-Based Architecture» для масштабирования. Какие преимущества он даёт по сравнению с классическим горизонтальным масштабированием?',
    sampleAnswer:
      'Cell-Based Architecture — паттерн, при котором инфраструктура делится на изолированные ячейки (cells), каждая из которых является полностью автономной копией системы, обслуживающей подмножество пользователей. Каждая ячейка содержит свои серверы приложений, базы данных, кэши и очереди. Маршрутизатор на входе направляет пользователя в его ячейку (обычно по hash от user_id). Преимущества: 1) Изоляция отказов (blast radius) — проблема в одной ячейке не затрагивает другие. 2) Независимое масштабирование — можно добавлять новые ячейки без изменения существующих. 3) Упрощение деплоя — можно обновлять ячейки по одной (canary deployment на уровне ячеек). 4) Предсказуемая производительность — каждая ячейка обслуживает фиксированное количество пользователей. Недостатки: операционная сложность, дублирование инфраструктуры, сложность cross-cell операций. Этот паттерн используется AWS (availability zones), Slack, и другими компаниями, работающими на масштабе.',
    explanation:
      'Cell-Based Architecture — это эволюция горизонтального масштабирования для систем, где blast radius (радиус поражения при сбое) критически важен. Вместо одного большого кластера, который может упасть целиком, система разделена на независимые ячейки. Даже если одна ячейка полностью недоступна, остальные продолжают работать. AWS использует этот принцип в основе своей архитектуры — каждый регион и availability zone спроектирован как изолированная ячейка.',
  },
];
