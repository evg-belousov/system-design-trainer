import type { Question } from '../types';

export const cachingQuestions: Question[] = [
  {
    id: 'sd-caching-001',
    block: 'sd',
    topic: 'caching',
    topicLabel: 'Кэширование',
    difficulty: 'junior',
    type: 'quiz',
    question: 'Какая основная цель использования кэширования в системном дизайне?',
    options: [
      'Уменьшение объёма хранимых данных',
      'Снижение задержки (latency) и нагрузки на основное хранилище за счёт хранения часто запрашиваемых данных в быстрой памяти',
      'Обеспечение консистентности данных между сервисами',
      'Защита данных от несанкционированного доступа',
    ],
    correctIndex: 1,
    explanation:
      'Кэширование -- это хранение копий часто запрашиваемых данных в быстродействующем хранилище (обычно в оперативной памяти). Это позволяет значительно снизить задержку ответов (с миллисекунд обращения к БД до микросекунд обращения к памяти) и уменьшить нагрузку на основное хранилище (базу данных). По принципу Парето, 80% запросов обычно приходится на 20% данных, что делает кэширование очень эффективным.',
  },
  {
    id: 'sd-caching-002',
    block: 'sd',
    topic: 'caching',
    topicLabel: 'Кэширование',
    difficulty: 'middle',
    type: 'quiz',
    question: 'Что такое стратегия Cache-Aside (Lazy Loading)?',
    options: [
      'Данные записываются одновременно в кэш и в базу данных',
      'Приложение сначала проверяет кэш; при промахе загружает данные из БД и помещает в кэш',
      'Кэш автоматически синхронизируется с базой данных через CDC',
      'Данные сначала записываются в кэш, а затем асинхронно сбрасываются в БД',
    ],
    correctIndex: 1,
    explanation:
      'Cache-Aside (Lazy Loading) -- наиболее распространённая стратегия кэширования. Приложение сначала обращается к кэшу. При cache hit данные возвращаются напрямую. При cache miss приложение загружает данные из БД, записывает их в кэш и возвращает клиенту. Преимущества: в кэш попадают только реально запрашиваемые данные, кэш может упасть без потери данных. Недостатки: первый запрос всегда медленный (cold start), возможна рассинхронизация с БД (stale data).',
  },
  {
    id: 'sd-caching-003',
    block: 'sd',
    topic: 'caching',
    topicLabel: 'Кэширование',
    difficulty: 'middle',
    type: 'open',
    question: 'Сравните стратегии Write-Through и Write-Behind (Write-Back) кэширования. Какие у каждой преимущества и недостатки?',
    sampleAnswer:
      'Write-Through: данные записываются одновременно в кэш и в базу данных в рамках одной операции. Преимущества: кэш всегда консистентен с БД, простая модель, нет риска потери данных. Недостатки: более высокая задержка записи (запись в два хранилища), лишние записи в кэш для данных, которые могут не быть прочитаны. Write-Behind (Write-Back): данные записываются только в кэш, а в БД сбрасываются асинхронно (через очередь или по таймеру). Преимущества: очень низкая задержка записи, можно группировать (batch) записи в БД, снижение нагрузки на БД. Недостатки: риск потери данных при падении кэша до сброса в БД, более сложная реализация, eventual consistency.',
    explanation:
      'Выбор стратегии зависит от требований к консистентности и производительности. Write-Through подходит для систем, где консистентность критична (финансовые данные, инвентаризация). Write-Behind -- для систем с высокой нагрузкой на запись, где допустима кратковременная потеря данных (счётчики просмотров, логи активности). На практике часто используется Cache-Aside для чтения в сочетании с write-through для записи.',
  },
  {
    id: 'sd-caching-004',
    block: 'sd',
    topic: 'caching',
    topicLabel: 'Кэширование',
    difficulty: 'senior',
    type: 'open',
    question: 'Что такое проблема «cache stampede» (или «thundering herd»)? Как её предотвратить?',
    sampleAnswer:
      'Cache stampede возникает, когда срок действия популярного ключа в кэше истекает (TTL expiry), и множество параллельных запросов одновременно обнаруживают промах кэша. Все они одновременно обращаются к базе данных за одними и теми же данными, создавая пиковую нагрузку, которая может привести к отказу. Способы предотвращения: 1) Locking (мьютекс): только один запрос идёт в БД, остальные ждут заполнения кэша. 2) Probabilistic early expiration: каждый запрос с небольшой вероятностью обновляет кэш до истечения TTL, распределяя обновления во времени. 3) Background refresh: фоновый процесс обновляет кэш до истечения TTL. 4) Stale-while-revalidate: возвращать устаревшие данные, пока один запрос обновляет кэш. 5) «Вечный» TTL с явной инвалидацией.',
    explanation:
      'Cache stampede -- классическая проблема высоконагруженных систем. В 2010 году Facebook описал, как один просроченный ключ в Memcached мог вызвать сотни тысяч запросов к БД. Их решение -- lease-based подход: Memcached выдаёт «аренду» первому запросу, остальные получают сигнал подождать. Это паттерн, который необходимо учитывать при проектировании любой системы с кэшированием на масштабе.',
  },
  {
    id: 'sd-caching-005',
    block: 'sd',
    topic: 'caching',
    topicLabel: 'Кэширование',
    difficulty: 'junior',
    type: 'quiz',
    question: 'Какая политика вытеснения (eviction policy) удаляет из кэша элемент, который дольше всего не использовался?',
    options: [
      'FIFO (First In, First Out)',
      'LFU (Least Frequently Used)',
      'LRU (Least Recently Used)',
      'Random Replacement',
    ],
    correctIndex: 2,
    explanation:
      'LRU (Least Recently Used) -- политика вытеснения, которая удаляет элемент, к которому дольше всего не обращались. Она основана на предположении, что недавно использованные данные с большей вероятностью будут запрошены снова (принцип временной локальности). LRU -- одна из самых популярных политик вытеснения, используемая в Redis, Memcached и многих других системах кэширования. Реализуется обычно с помощью комбинации хэш-таблицы и двусвязного списка.',
  },
  {
    id: 'sd-caching-006',
    block: 'sd',
    topic: 'caching',
    topicLabel: 'Кэширование',
    difficulty: 'junior',
    type: 'quiz',
    question: 'Что такое TTL (Time To Live) в контексте кэширования?',
    options: [
      'Время, необходимое для записи данных в кэш',
      'Время, через которое запись в кэше автоматически считается устаревшей и удаляется',
      'Максимальное время ответа кэш-сервера',
      'Время синхронизации кэша между несколькими узлами',
    ],
    correctIndex: 1,
    explanation:
      'TTL (Time To Live) — это срок жизни записи в кэше, после истечения которого запись считается устаревшей (expired) и удаляется или обновляется при следующем запросе. TTL помогает решить проблему stale data — устаревших данных в кэше. Выбор TTL — это компромисс: короткий TTL обеспечивает свежесть данных, но увеличивает нагрузку на БД; длинный TTL снижает нагрузку, но повышает риск выдачи устаревших данных. Для разных типов данных TTL может быть разным: справочники — часы, профили пользователей — минуты, биржевые котировки — секунды.',
  },
  {
    id: 'sd-caching-007',
    block: 'sd',
    topic: 'caching',
    topicLabel: 'Кэширование',
    difficulty: 'junior',
    type: 'quiz',
    question: 'Что такое cache hit и cache miss?',
    options: [
      'Cache hit — ошибка кэша, cache miss — успешное обращение',
      'Cache hit — запрашиваемые данные найдены в кэше, cache miss — данных в кэше нет и нужно обратиться к основному хранилищу',
      'Cache hit — добавление данных в кэш, cache miss — удаление данных из кэша',
      'Cache hit — кэш заполнен полностью, cache miss — в кэше есть свободное место',
    ],
    correctIndex: 1,
    explanation:
      'Cache hit (попадание в кэш) — это ситуация, когда запрашиваемые данные находятся в кэше и возвращаются напрямую из него, без обращения к основному хранилищу. Cache miss (промах кэша) — данных в кэше нет, и система обращается к более медленному хранилищу (базе данных). Cache hit ratio (процент попаданий) — ключевая метрика эффективности кэширования. Хороший показатель — 90-99% hit ratio. Низкий hit ratio означает, что кэш неэффективен и, возможно, нужно пересмотреть стратегию кэширования или размер кэша.',
  },
  {
    id: 'sd-caching-008',
    block: 'sd',
    topic: 'caching',
    topicLabel: 'Кэширование',
    difficulty: 'junior',
    type: 'quiz',
    question: 'Какой HTTP-заголовок указывает браузеру, как долго можно использовать кэшированную копию ресурса?',
    options: [
      'Content-Type',
      'Cache-Control',
      'Authorization',
      'X-Forwarded-For',
    ],
    correctIndex: 1,
    explanation:
      'Cache-Control — основной HTTP-заголовок управления кэшированием. Его директивы определяют политику кэширования: max-age=3600 (кэшировать 1 час), no-cache (всегда проверять актуальность на сервере), no-store (не кэшировать вообще), public/private (может ли кэшироваться на промежуточных прокси), immutable (ресурс не изменится). Вместе с ETag и Last-Modified заголовками, Cache-Control обеспечивает эффективное кэширование на стороне браузера и CDN, снижая нагрузку на серверы и ускоряя загрузку для пользователей.',
  },
  {
    id: 'sd-caching-009',
    block: 'sd',
    topic: 'caching',
    topicLabel: 'Кэширование',
    difficulty: 'middle',
    type: 'quiz',
    question: 'Чем отличается стратегия Read-Through от Cache-Aside?',
    options: [
      'В Read-Through кэш сам загружает данные из БД при промахе, в Cache-Aside это делает приложение',
      'Read-Through работает только с записью, Cache-Aside — только с чтением',
      'Read-Through не использует TTL, а Cache-Aside использует',
      'Никакой разницы — это одно и то же',
    ],
    correctIndex: 0,
    explanation:
      'В стратегии Cache-Aside приложение управляет кэшем самостоятельно: проверяет кэш, при промахе загружает данные из БД и записывает в кэш. В Read-Through кэш-провайдер сам отвечает за загрузку данных при промахе — приложение всегда обращается только к кэшу, а кэш сам ходит в БД при необходимости. Read-Through упрощает код приложения и централизует логику загрузки, но требует поддержки со стороны кэш-системы. Примеры кэшей с поддержкой Read-Through: Ehcache, NCache, Oracle Coherence.',
  },
  {
    id: 'sd-caching-010',
    block: 'sd',
    topic: 'caching',
    topicLabel: 'Кэширование',
    difficulty: 'middle',
    type: 'quiz',
    question: 'Что такое cache warming (прогрев кэша)?',
    options: [
      'Увеличение размера кэша в период повышенной нагрузки',
      'Предварительное заполнение кэша данными перед поступлением реальной нагрузки',
      'Мониторинг температуры серверов кэша',
      'Постепенное увеличение TTL кэшированных записей',
    ],
    correctIndex: 1,
    explanation:
      'Cache warming (прогрев кэша) — это предварительное заполнение кэша данными до того, как система начнёт принимать реальные запросы. Это важно при перезапуске кэш-серверов, деплое новой версии или запуске нового дата-центра. Без прогрева все запросы будут cache miss, создавая пиковую нагрузку на БД (cold start problem). Способы прогрева: 1) Скрипт, загружающий часто запрашиваемые данные. 2) Replay-логи предыдущих запросов. 3) Постепенное перенаправление трафика (через балансировщик). 4) Создание snapshot кэша и его восстановление.',
  },
  {
    id: 'sd-caching-011',
    block: 'sd',
    topic: 'caching',
    topicLabel: 'Кэширование',
    difficulty: 'middle',
    type: 'open',
    question: 'Что такое multi-level caching (многоуровневое кэширование)? Приведите пример типичной конфигурации уровней кэширования в веб-приложении.',
    sampleAnswer:
      'Multi-level caching — использование нескольких уровней кэширования, каждый с разными характеристиками по скорости, объёму и расстоянию от клиента. Типичные уровни в веб-приложении (от клиента к серверу): 1) Браузерный кэш (L1) — HTTP-кэш в браузере, управляется заголовками Cache-Control, ETag. Самый быстрый — нет сетевого запроса. 2) CDN (L2) — кэш на edge-серверах CDN, близких к пользователю. Кэширует статику и иногда динамический контент. 3) Reverse proxy / API Gateway (L3) — кэш на уровне Nginx, Varnish. Кэширует ответы API. 4) In-process кэш (L4) — кэш в памяти приложения (Guava Cache, Caffeine). Самый быстрый серверный кэш, но ограничен размером и не разделяется между экземплярами. 5) Distributed cache (L5) — Redis, Memcached. Разделяется между всеми экземплярами, но требует сетевого вызова. 6) Database cache — буферный пул БД (InnoDB Buffer Pool). Каждый уровень обеспечивает разный баланс скорости, объёма и свежести данных.',
    explanation:
      'Multi-level caching позволяет каждому запросу быть обслуженным максимально близко к клиенту. Чем выше уровень (ближе к клиенту), тем быстрее ответ, но тем сложнее инвалидация. Ключевой вызов — обеспечить консистентность между уровнями. На практике используют каскадную инвалидацию: при обновлении данных инвалидируются все уровни от БД до CDN.',
  },
  {
    id: 'sd-caching-012',
    block: 'sd',
    topic: 'caching',
    topicLabel: 'Кэширование',
    difficulty: 'middle',
    type: 'quiz',
    question: 'Какую проблему решает паттерн «cache invalidation» и почему он считается одной из двух сложнейших задач в Computer Science?',
    options: [
      'Определение размера кэша для оптимальной производительности',
      'Выбор оптимального алгоритма сжатия кэшированных данных',
      'Обеспечение своевременного удаления или обновления устаревших данных в кэше при изменении источника',
      'Распределение кэша между несколькими серверами',
    ],
    correctIndex: 2,
    explanation:
      'Cache invalidation — это процесс удаления или обновления записей в кэше, когда соответствующие данные в основном хранилище изменились. Это сложно, потому что: 1) Нужно отследить все места, где данные кэшированы (включая CDN, браузеры, in-process кэши). 2) Между обновлением БД и инвалидацией кэша есть временное окно, когда данные рассогласованы. 3) В распределённой системе инвалидация должна дойти до всех узлов. 4) Race conditions: параллельные чтение и запись могут привести к кэшированию устаревших данных. Фил Карлтон из Netscape сказал: «В Computer Science есть только две сложные вещи: инвалидация кэша и именование».',
  },
  {
    id: 'sd-caching-013',
    block: 'sd',
    topic: 'caching',
    topicLabel: 'Кэширование',
    difficulty: 'senior',
    type: 'quiz',
    question: 'Как Redis Cluster обеспечивает горизонтальное масштабирование распределённого кэша?',
    options: [
      'Каждый узел хранит полную копию всех данных',
      'Данные автоматически распределяются по 16384 хэш-слотам между узлами кластера',
      'Клиент самостоятельно определяет, на какой узел отправить запрос, без участия кластера',
      'Redis Cluster не поддерживает горизонтальное масштабирование',
    ],
    correctIndex: 1,
    explanation:
      'Redis Cluster использует 16384 хэш-слота для распределения ключей между узлами. Каждый узел отвечает за подмножество слотов. Ключ хэшируется (CRC16(key) mod 16384) для определения слота. При добавлении нового узла часть слотов мигрирует на него (resharding) без остановки кластера. Каждый узел знает маппинг слотов на узлы и может перенаправить клиента (MOVED redirect) на правильный узел. Для отказоустойчивости каждый master-узел имеет replica, которая автоматически промотируется при отказе master-а.',
  },
  {
    id: 'sd-caching-014',
    block: 'sd',
    topic: 'caching',
    topicLabel: 'Кэширование',
    difficulty: 'senior',
    type: 'open',
    question: 'Что такое cache coherence (когерентность кэша) в распределённых системах? Какие стратегии обеспечения когерентности существуют?',
    sampleAnswer:
      'Cache coherence — это обеспечение согласованности данных между несколькими кэшами, когда данные могут быть изменены. В распределённой системе с несколькими экземплярами приложения каждый может иметь свой in-process кэш, и изменение данных одним экземпляром должно быть отражено в кэшах остальных. Стратегии: 1) Централизованный кэш (Redis/Memcached) — все экземпляры используют один распределённый кэш, проблема когерентности решается на уровне хранилища. 2) Invalidation-based — при изменении данных отправляется сообщение (через Redis Pub/Sub, Kafka) всем экземплярам с командой удалить запись из локального кэша. 3) Update-based — вместо инвалидации рассылается новое значение для обновления кэша. 4) TTL-based — каждый кэш самостоятельно обновляет данные по истечении TTL, допуская кратковременную рассогласованность. 5) Versioning — при каждом изменении увеличивается версия, кэшированная запись проверяется по версии. На практике комбинируют подходы: централизованный Redis для горячих данных + инвалидация через Pub/Sub для in-process кэшей.',
    explanation:
      'Cache coherence в распределённых системах аналогична проблеме когерентности кэшей в многопроцессорных системах, но на другом масштабе. В CPU используются протоколы MESI/MOESI, в распределённых системах — message-passing. Ключевой компромисс: чем строже когерентность, тем выше задержка и сложность. Для большинства веб-приложений eventual consistency через TTL + event-based invalidation является оптимальным решением.',
  },
  {
    id: 'sd-caching-015',
    block: 'sd',
    topic: 'caching',
    topicLabel: 'Кэширование',
    difficulty: 'junior',
    type: 'quiz',
    question: 'Какой из перечисленных инструментов является распределённым кэшем?',
    options: [
      'PostgreSQL',
      'Redis',
      'Nginx',
      'Prometheus',
    ],
    correctIndex: 1,
    explanation:
      'Redis — это высокопроизводительное in-memory хранилище данных, широко используемое как распределённый кэш. Redis хранит данные в оперативной памяти, обеспечивая задержку порядка микросекунд. Поддерживает различные структуры данных (строки, хэши, списки, множества, sorted sets), TTL для записей, persistence (RDB, AOF) и кластеризацию (Redis Cluster) для горизонтального масштабирования. Memcached — другой популярный распределённый кэш, более простой и специализированный.',
  },
  {
    id: 'sd-caching-016',
    block: 'sd',
    topic: 'caching',
    topicLabel: 'Кэширование',
    difficulty: 'middle',
    type: 'open',
    question: 'Объясните HTTP-механизм условных запросов (conditional requests) с использованием ETag и If-None-Match. Как это помогает кэшированию?',
    sampleAnswer:
      'ETag (Entity Tag) — это идентификатор версии ресурса, генерируемый сервером (обычно хэш содержимого или номер версии). Механизм работает так: 1) Клиент запрашивает ресурс. Сервер отвечает с заголовком ETag: "abc123". 2) Клиент кэширует ресурс и ETag. 3) При следующем запросе клиент отправляет заголовок If-None-Match: "abc123". 4) Сервер сравнивает ETag: если ресурс не изменился, возвращает 304 Not Modified без тела ответа (экономя трафик). Если изменился — возвращает 200 OK с новым ресурсом и новым ETag. Аналогично работает пара Last-Modified / If-Modified-Since, но по дате модификации. Условные запросы экономят трафик и снижают нагрузку на сервер, но не устраняют сам запрос (в отличие от Cache-Control: max-age). Оптимальный подход — комбинировать: Cache-Control для статических ресурсов (JS, CSS с хэшем в имени файла) и ETag для динамических ресурсов.',
    explanation:
      'Условные запросы — важная часть HTTP-кэширования, особенно для ресурсов, которые нельзя кэшировать надолго (Cache-Control: no-cache). Они позволяют серверу быстро подтвердить актуальность кэшированной версии без передачи полного содержимого. Это особенно эффективно для больших ресурсов (изображения, документы).',
  },
  {
    id: 'sd-caching-017',
    block: 'sd',
    topic: 'caching',
    topicLabel: 'Кэширование',
    difficulty: 'senior',
    type: 'quiz',
    question: 'Какой подход к инвалидации кэша минимизирует нагрузку на БД при одновременном истечении TTL популярного ключа?',
    options: [
      'Установить одинаковый TTL для всех ключей',
      'Использовать мьютекс (lock) — только один запрос обновляет кэш, остальные ждут',
      'Удалять все ключи кэша при каждом обновлении БД',
      'Не использовать TTL вообще',
    ],
    correctIndex: 1,
    explanation:
      'Подход с мьютексом (lock) — один из основных способов предотвращения cache stampede. Когда несколько запросов обнаруживают cache miss для одного ключа, только первый захватывает блокировку (например, через Redis SETNX) и загружает данные из БД. Остальные запросы ждут (с коротким sleep и retry) или получают слегка устаревшие данные (stale-while-revalidate). Другие подходы: probabilistic early expiration (каждый запрос с небольшой вероятностью обновляет кэш до истечения TTL) и background refresh (фоновый процесс обновляет кэш до истечения TTL).',
  },
  {
    id: 'sd-caching-018',
    block: 'sd',
    topic: 'caching',
    topicLabel: 'Кэширование',
    difficulty: 'senior',
    type: 'open',
    question: 'Сравните Redis и Memcached как решения для распределённого кэширования. В каких сценариях каждый из них предпочтительнее?',
    sampleAnswer:
      'Redis: поддерживает разнообразные структуры данных (строки, хэши, списки, множества, sorted sets, HyperLogLog, streams), persistence (RDB-снимки, AOF-лог), репликацию, кластеризацию (Redis Cluster), Lua-скриптинг, pub/sub, транзакции. Предпочтителен, когда: нужны сложные структуры данных, нужна persistence, нужен pub/sub, требуется кластеризация с автоматическим failover. Memcached: простой key-value кэш, многопоточная архитектура (лучше утилизирует многоядерные CPU), простой протокол, автоматическое slab-управление памятью. Предпочтителен, когда: нужен максимально простой кэш, данные — только строки/сериализованные объекты, нужна максимальная производительность на многоядерном сервере, не нужна persistence. На практике Redis доминирует благодаря своей универсальности, но Memcached остаётся актуальным для сценариев чистого кэширования с максимальной производительностью (используется в Facebook/Meta).',
    explanation:
      'Оба инструмента обеспечивают задержку порядка микросекунд и широко используются в production. Redis, начиная с версии 6, поддерживает многопоточный I/O, сокращая разрыв в производительности с Memcached. Выбор часто зависит от экосистемы и опыта команды. В облачных средах доступны управляемые сервисы: AWS ElastiCache поддерживает оба.',
  },
  {
    id: 'sd-caching-019',
    block: 'sd',
    topic: 'caching',
    topicLabel: 'Кэширование',
    difficulty: 'middle',
    type: 'quiz',
    question: 'Что такое «cache penetration» и как от него защититься?',
    options: [
      'Атака, при которой злоумышленник получает доступ к данным через кэш',
      'Ситуация, когда запросы к несуществующим ключам всегда проходят в БД, минуя кэш',
      'Переполнение памяти кэш-сервера',
      'Утечка данных из кэша при его перезапуске',
    ],
    correctIndex: 1,
    explanation:
      'Cache penetration — проблема, когда частые запросы к несуществующим данным каждый раз проходят в базу данных, минуя кэш (потому что нечего кэшировать). Это может быть как легитимным сценарием, так и атакой. Способы защиты: 1) Кэширование null-значений — записывать в кэш «пустой» результат с коротким TTL. 2) Bloom Filter — вероятностная структура данных, проверяющая существование ключа без обращения к БД. 3) Валидация входных данных — фильтровать заведомо невалидные запросы до кэша.',
  },
  {
    id: 'sd-caching-020',
    block: 'sd',
    topic: 'caching',
    topicLabel: 'Кэширование',
    difficulty: 'senior',
    type: 'open',
    question: 'Опишите стратегию кэширования для системы с высокой нагрузкой на запись (write-heavy workload). Какие паттерны и компромиссы необходимо учитывать?',
    sampleAnswer:
      'Для write-heavy систем стандартные стратегии кэширования (Cache-Aside, Read-Through) менее эффективны, потому что данные часто инвалидируются. Подходы: 1) Write-Behind (Write-Back) — записи буферизуются в кэше и асинхронно сбрасываются в БД пакетами (batching). Снижает нагрузку на БД, но риск потери при отказе кэша. 2) CQRS — разделение моделей чтения и записи, кэш обслуживает только чтение из отдельной read-модели. 3) Event-driven invalidation — при записи отправляется событие через Kafka/Redis Pub/Sub для инвалидации кэшей всех экземпляров. 4) Write-Around — запись идёт только в БД, минуя кэш. Кэш обновляется при чтении (Cache-Aside). Подходит, когда записанные данные редко читаются сразу. 5) Агрегирование записей — вместо записи каждого инкремента (счётчик просмотров), агрегировать в Redis (INCR) и периодически сбрасывать в БД. Компромиссы: durability vs performance, consistency vs latency, complexity vs reliability.',
    explanation:
      'Write-heavy системы (метрики, логи, IoT-данные, social media feeds) требуют принципиально другого подхода к кэшированию, чем read-heavy. Ключевой принцип — минимизировать синхронные записи в БД через буферизацию и агрегирование. Системы вроде Twitter используют fan-out-on-write (запись в кэш таймлайна каждого фолловера при публикации твита), а не fan-out-on-read.',
  },
  {
    id: 'sd-caching-021',
    block: 'sd',
    topic: 'caching',
    topicLabel: 'Кэширование',
    difficulty: 'junior',
    type: 'quiz',
    question: 'Что такое in-memory cache и какое его главное преимущество?',
    options: [
      'Кэш, хранящийся на SSD-диске',
      'Кэш в оперативной памяти, обеспечивающий доступ за микросекунды',
      'Кэш в облачном хранилище',
      'Кэш, распределённый между процессорами',
    ],
    correctIndex: 1,
    explanation:
      'In-memory cache хранит данные в оперативной памяти (RAM), что обеспечивает время доступа порядка микросекунд (в сравнении с миллисекундами для диска или сети). Примеры: Redis, Memcached для распределённого кэша; Guava Cache, Caffeine для локального кэша в приложении. Ограничение — объём памяти, поэтому важны политики вытеснения (LRU, LFU).',
  },
  {
    id: 'sd-caching-022',
    block: 'sd',
    topic: 'caching',
    topicLabel: 'Кэширование',
    difficulty: 'junior',
    type: 'quiz',
    question: 'Что такое локальный (local) кэш и чем он отличается от распределённого?',
    options: [
      'Локальный кэш находится в географически ближайшем дата-центре',
      'Локальный кэш хранится в памяти одного процесса/сервера и не доступен другим инстансам',
      'Локальный кэш использует локальную базу данных',
      'Локальный кэш работает только для локальных пользователей',
    ],
    correctIndex: 1,
    explanation:
      'Локальный (in-process) кэш хранится в памяти одного процесса приложения. Преимущества: нет сетевых вызовов (быстрее), простота. Недостатки: не разделяется между инстансами (дублирование данных), ограничен памятью процесса, инвалидация сложнее. Распределённый кэш (Redis) доступен всем инстансам, но требует сетевого вызова. Часто комбинируют: локальный L1 + распределённый L2.',
  },
  {
    id: 'sd-caching-023',
    block: 'sd',
    topic: 'caching',
    topicLabel: 'Кэширование',
    difficulty: 'junior',
    type: 'quiz',
    question: 'Какая политика вытеснения удаляет из кэша элемент, который использовался реже всего?',
    options: [
      'LRU (Least Recently Used)',
      'LFU (Least Frequently Used)',
      'FIFO (First In First Out)',
      'Random',
    ],
    correctIndex: 1,
    explanation:
      'LFU (Least Frequently Used) удаляет элемент с наименьшим количеством обращений. В отличие от LRU (удаляет давно не использованный), LFU учитывает частоту использования за всё время. LFU лучше подходит, когда частота обращений важнее давности. Недостаток: новые элементы могут быть вытеснены сразу, так как у них низкий счётчик. Существует TinyLFU — оптимизированный вариант.',
  },
  {
    id: 'sd-caching-024',
    block: 'sd',
    topic: 'caching',
    topicLabel: 'Кэширование',
    difficulty: 'junior',
    type: 'open',
    question: 'Объясните, что такое cache key и какие факторы нужно учитывать при его проектировании.',
    sampleAnswer:
      'Cache key — уникальный идентификатор записи в кэше. При проектировании нужно учитывать: 1) Уникальность — ключ должен однозначно идентифицировать данные. Для API: метод + URL + параметры + версия. 2) Иерархия — включать контекст: user:123:profile vs global:config. 3) Длина — слишком длинные ключи потребляют память и замедляют lookup. 4) Читаемость — для отладки ключ должен быть понятным. 5) Инвалидация — структура должна позволять инвалидировать группы (user:123:* — все данные пользователя). 6) Hash collision — для сложных ключей использовать хэш, но помнить о коллизиях. Пример: product:category:electronics:page:1:sort:price.',
    explanation:
      'Хорошо спроектированный cache key — основа эффективного кэширования. Плохие ключи приводят к: cache pollution (ненужные данные), cache miss (слишком специфичные ключи), сложности инвалидации. Рекомендуется использовать namespace:entity:id:attribute pattern.',
  },
  {
    id: 'sd-caching-025',
    block: 'sd',
    topic: 'caching',
    topicLabel: 'Кэширование',
    difficulty: 'middle',
    type: 'quiz',
    question: 'Что такое write-around caching strategy?',
    options: [
      'Данные записываются только в кэш, минуя БД',
      'Данные записываются напрямую в БД, минуя кэш; кэш обновляется при чтении',
      'Данные записываются в кэш и БД одновременно',
      'Кэш периодически синхронизируется с БД',
    ],
    correctIndex: 1,
    explanation:
      'Write-around — стратегия, при которой запись идёт напрямую в БД, минуя кэш. Кэш заполняется только при чтении (как в Cache-Aside). Преимущества: не загрязняет кэш данными, которые могут не быть прочитаны сразу после записи. Недостатки: первое чтение после записи — cache miss. Подходит, когда записанные данные редко читаются сразу (логи, исторические записи).',
  },
  {
    id: 'sd-caching-026',
    block: 'sd',
    topic: 'caching',
    topicLabel: 'Кэширование',
    difficulty: 'middle',
    type: 'quiz',
    question: 'Какой HTTP-заголовок позволяет указать, что ресурс может кэшироваться только в приватном кэше браузера, но не на промежуточных прокси?',
    options: [
      'Cache-Control: no-store',
      'Cache-Control: private',
      'Cache-Control: public',
      'Cache-Control: no-cache',
    ],
    correctIndex: 1,
    explanation:
      'Cache-Control: private указывает, что ответ предназначен только для одного пользователя и может кэшироваться только в приватном кэше браузера, но не на CDN или промежуточных прокси. Используется для персонализированного контента (личный кабинет, корзина). public — разрешает кэширование везде. no-cache — требует ревалидации. no-store — полностью запрещает кэширование.',
  },
  {
    id: 'sd-caching-027',
    block: 'sd',
    topic: 'caching',
    topicLabel: 'Кэширование',
    difficulty: 'middle',
    type: 'open',
    question: 'Как реализовать кэширование в микросервисной архитектуре? Какие уровни кэширования следует использовать?',
    sampleAnswer:
      'Кэширование в микросервисах — многоуровневое: 1) API Gateway кэш — кэширование ответов на уровне входа; подходит для публичных, редко меняющихся данных. 2) Service-level кэш — каждый сервис имеет свой кэш (Redis) для часто запрашиваемых данных своего домена. Не делить кэш между сервисами — нарушает bounded context. 3) In-process кэш — Caffeine/Guava в каждом инстансе для горячих данных с коротким TTL. 4) Database query cache — кэширование результатов частых запросов. 5) Sidecar cache — в service mesh кэш может быть в sidecar-прокси. Инвалидация: event-driven через Kafka/Redis Pub/Sub — при изменении данных сервис публикует событие, другие сервисы инвалидируют свои кэши. Важно: не кэшировать данные, которыми «владеет» другой сервис — запрашивать через API.',
    explanation:
      'Кэширование в микросервисах сложнее, чем в монолите, из-за распределённости и независимости сервисов. Ключевой принцип — каждый сервис отвечает за кэширование своих данных. Cross-service кэширование создаёт связанность и проблемы с консистентностью.',
  },
  {
    id: 'sd-caching-028',
    block: 'sd',
    topic: 'caching',
    topicLabel: 'Кэширование',
    difficulty: 'middle',
    type: 'quiz',
    question: 'Что такое cache-aside pattern с lazy loading и когда он НЕ подходит?',
    options: [
      'Всегда подходит для любых сценариев',
      'Не подходит, когда критична консистентность и нужны актуальные данные после записи',
      'Не подходит для read-heavy систем',
      'Не подходит при использовании Redis',
    ],
    correctIndex: 1,
    explanation:
      'Cache-Aside с lazy loading: при чтении проверяется кэш, при miss — загрузка из БД и запись в кэш. Не подходит, когда: 1) После записи данные сразу читаются — будет cache miss. 2) Критична строгая консистентность — между обновлением БД и инвалидацией кэша есть окно рассогласованности. 3) Первый запрос важен — cold start проблема. Альтернативы: Write-Through для консистентности, Cache Warming для холодного старта.',
  },
  {
    id: 'sd-caching-029',
    block: 'sd',
    topic: 'caching',
    topicLabel: 'Кэширование',
    difficulty: 'middle',
    type: 'quiz',
    question: 'Какой тип данных Redis лучше всего подходит для кэширования отсортированных списков с возможностью выборки по диапазону?',
    options: [
      'String',
      'Hash',
      'Sorted Set (ZSET)',
      'List',
    ],
    correctIndex: 2,
    explanation:
      'Redis Sorted Set (ZSET) хранит уникальные элементы с числовым score и поддерживает эффективные операции: ZRANGE/ZREVRANGE (выборка по диапазону индексов), ZRANGEBYSCORE (выборка по диапазону score), ZRANK (позиция элемента). Идеален для: лидербордов (score = очки), временных лент (score = timestamp), пагинации отсортированных данных. Сложность операций: O(log N) для добавления, O(log N + M) для выборки диапазона.',
  },
  {
    id: 'sd-caching-030',
    block: 'sd',
    topic: 'caching',
    topicLabel: 'Кэширование',
    difficulty: 'middle',
    type: 'open',
    question: 'Объясните паттерн Refresh-Ahead (proactive cache refresh). Когда он предпочтительнее стандартного TTL-based подхода?',
    sampleAnswer:
      'Refresh-Ahead — проактивное обновление кэша до истечения TTL. Когда запрос приходит к записи, у которой осталось менее X% времени жизни, асинхронно запускается обновление из БД, а текущий запрос получает существующие данные. Преимущества: 1) Нет cache miss при истечении TTL — данные всегда свежие. 2) Нет cache stampede — обновление асинхронное, один поток. 3) Стабильная latency — нет внезапных обращений к БД. Когда использовать: для популярных данных с предсказуемым паттерном доступа; когда latency критична и cache miss недопустим; для данных, обновляемых внешним источником (курсы валют, погода). Реализация: фоновый процесс или trigger при чтении с проверкой remaining TTL.',
    explanation:
      'Refresh-Ahead — продвинутый паттерн для high-traffic систем. Netflix использует его для кэширования метаданных фильмов — данные всегда актуальны, latency стабильна. Требует дополнительной инфраструктуры (фоновые задачи), но окупается для критичных hot data.',
  },
  {
    id: 'sd-caching-031',
    block: 'sd',
    topic: 'caching',
    topicLabel: 'Кэширование',
    difficulty: 'senior',
    type: 'quiz',
    question: 'Что такое cache sharding и какую проблему он решает?',
    options: [
      'Разделение кэша по типам данных',
      'Распределение данных кэша между несколькими узлами для горизонтального масштабирования',
      'Шифрование данных в кэше',
      'Резервное копирование кэша',
    ],
    correctIndex: 1,
    explanation:
      'Cache sharding — распределение данных между несколькими узлами кэша по ключу (consistent hashing). Решает проблему ограниченной памяти одного узла и пропускной способности. Каждый ключ хэшируется для определения целевого узла. Redis Cluster использует 16384 hash slots. Преимущества: горизонтальное масштабирование, распределение нагрузки. Сложности: cross-shard операции (MGET по ключам на разных шардах), re-sharding при добавлении узлов.',
  },
  {
    id: 'sd-caching-032',
    block: 'sd',
    topic: 'caching',
    topicLabel: 'Кэширование',
    difficulty: 'senior',
    type: 'quiz',
    question: 'Какой механизм Redis обеспечивает атомарное выполнение нескольких команд?',
    options: [
      'Pipelining',
      'Pub/Sub',
      'Transactions (MULTI/EXEC) или Lua scripts',
      'Replication',
    ],
    correctIndex: 2,
    explanation:
      'Redis Transactions (MULTI/EXEC) группируют команды для атомарного выполнения — никакие другие команды не выполняются между ними. Lua scripts выполняются атомарно на сервере — предпочтительный способ для сложной логики. Pipelining — отправка нескольких команд без ожидания ответа — не атомарен, просто оптимизация latency. Важно: Redis transactions не поддерживают rollback — все команды выполнятся даже при ошибке в одной.',
  },
  {
    id: 'sd-caching-033',
    block: 'sd',
    topic: 'caching',
    topicLabel: 'Кэширование',
    difficulty: 'senior',
    type: 'open',
    question: 'Как реализовать распределённый rate limiter с использованием Redis? Какие алгоритмы rate limiting существуют?',
    sampleAnswer:
      'Rate limiting ограничивает количество запросов за период. Алгоритмы: 1) Fixed Window — счётчик запросов в фиксированном окне (минута). Redis: INCR key, EXPIRE. Проблема: всплеск на границе окон (100 в конце минуты + 100 в начале следующей = 200 за 2 секунды). 2) Sliding Window Log — хранить timestamp каждого запроса, считать за скользящее окно. Redis: ZADD + ZRANGEBYSCORE. Точный, но потребляет память. 3) Sliding Window Counter — комбинация: weighted average предыдущего и текущего окна. Компромисс точности и памяти. 4) Token Bucket — токены накапливаются с постоянной скоростью, запрос потребляет токен. Redis Lua script для атомарности. Позволяет burst. 5) Leaky Bucket — запросы в очередь, обработка с постоянной скоростью. Реализация в Redis: Lua script для атомарного check-and-update, SET с NX/EX для distributed lock.',
    explanation:
      'Distributed rate limiting — классическая задача для Redis. Token Bucket — наиболее гибкий алгоритм (позволяет burst). Для API обычно используют sliding window или token bucket. Важно: rate limiter сам может стать bottleneck — нужна репликация Redis.',
  },
  {
    id: 'sd-caching-034',
    block: 'sd',
    topic: 'caching',
    topicLabel: 'Кэширование',
    difficulty: 'senior',
    type: 'open',
    question: 'Объясните стратегию кэширования для персонализированного контента (рекомендации, ленты пользователей). Какие особенности нужно учитывать?',
    sampleAnswer:
      'Персонализированный контент сложен для кэширования, так как уникален для каждого пользователя. Стратегии: 1) Per-user cache key — кэшировать по user:123:feed. Работает для активных пользователей, но cache hit rate низкий для long-tail пользователей. 2) Materialized feeds — предвычислять и хранить ленту каждого пользователя (fan-out-on-write). Twitter использует для активных пользователей. Дорого по памяти. 3) Compute on read с кэшированием компонентов — не кэшировать ленту целиком, но кэшировать: пользователей (user:123:profile), посты (post:456), рекомендательные векторы. 4) Edge caching с ESI (Edge Side Includes) — CDN собирает страницу из кэшируемых и персональных блоков. 5) Segment-based caching — группировать пользователей по сегментам (интересы, регион), кэшировать для сегмента. 6) Hybrid — materialized для top users, compute для остальных.',
    explanation:
      'Персонализация — один из главных вызовов для кэширования. Netflix и Spotify используют multi-level подход: кэшируют модели и векторы, вычисляют рекомендации near-realtime. Важно найти баланс между персонализацией и cache efficiency.',
  },
  {
    id: 'sd-caching-035',
    block: 'sd',
    topic: 'caching',
    topicLabel: 'Кэширование',
    difficulty: 'junior',
    type: 'quiz',
    question: 'Что такое stale data в контексте кэширования?',
    options: [
      'Зашифрованные данные в кэше',
      'Устаревшие данные в кэше, которые уже не соответствуют источнику',
      'Данные, сжатые для экономии места',
      'Данные, помеченные для удаления',
    ],
    correctIndex: 1,
    explanation:
      'Stale data — устаревшие данные в кэше, не соответствующие текущему состоянию в основном хранилище. Возникает из-за: долгого TTL, задержки инвалидации, race conditions при обновлении. Последствия: пользователь видит неактуальную информацию. Решения: короткий TTL, event-driven инвалидация, версионирование. Иногда stale data допустимы (stale-while-revalidate) для улучшения производительности.',
  },
  {
    id: 'sd-caching-036',
    block: 'sd',
    topic: 'caching',
    topicLabel: 'Кэширование',
    difficulty: 'junior',
    type: 'quiz',
    question: 'Какой тип кэширования используется в браузере для хранения ресурсов веб-страницы?',
    options: [
      'Server-side cache',
      'Distributed cache',
      'Browser HTTP cache',
      'Database cache',
    ],
    correctIndex: 2,
    explanation:
      'Browser HTTP cache хранит ресурсы (HTML, CSS, JS, изображения) локально в браузере на основе HTTP-заголовков (Cache-Control, ETag, Last-Modified). При повторном запросе браузер либо использует кэшированную копию (при валидном max-age), либо делает conditional request (If-None-Match) для проверки актуальности. Это самый быстрый кэш — нет сетевого запроса вообще.',
  },
  {
    id: 'sd-caching-037',
    block: 'sd',
    topic: 'caching',
    topicLabel: 'Кэширование',
    difficulty: 'middle',
    type: 'quiz',
    question: 'Что такое cache eviction и когда оно происходит?',
    options: [
      'Добавление данных в кэш',
      'Удаление данных из кэша для освобождения места или по истечении TTL',
      'Обновление данных в кэше',
      'Репликация кэша между серверами',
    ],
    correctIndex: 1,
    explanation:
      'Cache eviction — удаление записей из кэша. Происходит: 1) По истечении TTL (time-based eviction). 2) При нехватке памяти (space-based eviction) — применяется политика LRU, LFU, FIFO. 3) При явной инвалидации (explicit eviction) — DELETE по ключу. Redis использует: volatile-lru (LRU среди ключей с TTL), allkeys-lru (LRU по всем ключам), noeviction (ошибка при нехватке памяти) и другие политики.',
  },
  {
    id: 'sd-caching-038',
    block: 'sd',
    topic: 'caching',
    topicLabel: 'Кэширование',
    difficulty: 'middle',
    type: 'open',
    question: 'Как кэшировать результаты API-запросов, которые зависят от множества параметров? Как управлять cache key explosion?',
    sampleAnswer:
      'При множестве параметров количество уникальных ключей может взрываться (cache key explosion), снижая hit rate. Стратегии: 1) Нормализация параметров — сортировать параметры, приводить к lowercase, убирать дефолтные значения. GET /users?sort=name&page=1 = GET /users?page=1&sort=name. 2) Selective caching — кэшировать только популярные комбинации параметров. Отслеживать hit rate по паттернам ключей. 3) Parameter bucketing — округлять числовые параметры (price: 99 → 100), ограничивать возможные значения. 4) Layered caching — кэшировать базовый результат без фильтров, применять фильтры на application level. 5) Computed cache keys — хэшировать параметры для фиксированной длины ключа. 6) TTL tiering — популярные комбинации с долгим TTL, редкие — с коротким или без кэширования.',
    explanation:
      'Cache key explosion — реальная проблема для API с гибкими параметрами. Решение зависит от паттернов использования. Анализ логов показывает, какие комбинации реально используются — часто 90% запросов приходится на 10% комбинаций.',
  },
  {
    id: 'sd-caching-039',
    block: 'sd',
    topic: 'caching',
    topicLabel: 'Кэширование',
    difficulty: 'middle',
    type: 'quiz',
    question: 'Что такое CDN edge cache и какой контент обычно в нём кэшируется?',
    options: [
      'Кэш базы данных на периферийных серверах',
      'Кэш статического и динамического контента на серверах CDN, географически близких к пользователям',
      'Кэш исходного кода приложения',
      'Кэш конфигурации серверов',
    ],
    correctIndex: 1,
    explanation:
      'CDN edge cache — кэш на периферийных серверах CDN (Points of Presence), расположенных ближе к конечным пользователям. Кэшируется: статика (изображения, CSS, JS, видео), API-ответы с соответствующими заголовками, рендеренный HTML. Управляется через Cache-Control заголовки и CDN-правила. Edge cache радикально снижает latency (десятки vs сотни миллисекунд) и разгружает origin-серверы.',
  },
  {
    id: 'sd-caching-040',
    block: 'sd',
    topic: 'caching',
    topicLabel: 'Кэширование',
    difficulty: 'senior',
    type: 'quiz',
    question: 'Какой паттерн позволяет вернуть устаревшие данные из кэша, пока в фоне загружаются свежие?',
    options: [
      'Write-Through',
      'Stale-While-Revalidate',
      'Cache-Aside',
      'Read-Through',
    ],
    correctIndex: 1,
    explanation:
      'Stale-While-Revalidate — паттерн, при котором кэш возвращает устаревшие данные немедленно, одновременно запуская фоновое обновление. Клиент получает быстрый ответ (пусть и stale), следующий запрос получит свежие данные. Используется в HTTP (Cache-Control: stale-while-revalidate=60), SWR-библиотеках (React), CDN. Идеален, когда скорость важнее абсолютной свежести (новостные ленты, каталоги).',
  },
  {
    id: 'sd-caching-041',
    block: 'sd',
    topic: 'caching',
    topicLabel: 'Кэширование',
    difficulty: 'senior',
    type: 'open',
    question: 'Как реализовать кэширование для GraphQL API? Какие особенности GraphQL усложняют кэширование?',
    sampleAnswer:
      'GraphQL усложняет кэширование: 1) POST-запросы — браузер и CDN не кэшируют POST по умолчанию. 2) Динамические query — каждый клиент может запросить разные поля, создавая уникальные запросы. 3) Вложенность — один запрос может затрагивать множество сущностей. Стратегии: 1) Persisted Queries — заменить query хэшем, превратить в GET-запрос, кэшировать на CDN. 2) Response caching — кэшировать полный ответ по хэшу query + variables. 3) Normalized cache (Apollo Client) — клиентский кэш нормализует данные по id, переиспользует между запросами. 4) Field-level caching — кэшировать resolvers отдельных полей (@cacheControl directive). 5) DataLoader — батчинг и кэширование на уровне запроса для предотвращения N+1. 6) HTTP caching hints — возвращать Cache-Control на основе минимального TTL полей в ответе.',
    explanation:
      'GraphQL кэширование — активная область развития. Apollo Server поддерживает cache control directives, Stellate (бывший GraphCDN) — специализированный CDN для GraphQL. Ключевой принцип — кэшировать на максимально низком уровне (field/entity) для лучшего reuse.',
  },
  {
    id: 'sd-caching-042',
    block: 'sd',
    topic: 'caching',
    topicLabel: 'Кэширование',
    difficulty: 'senior',
    type: 'quiz',
    question: 'Что такое cache warming через traffic replay?',
    options: [
      'Копирование кэша с production на staging',
      'Воспроизведение реальных запросов из логов для наполнения кэша перед запуском',
      'Постепенное увеличение TTL записей',
      'Синхронизация кэша между дата-центрами',
    ],
    correctIndex: 1,
    explanation:
      'Traffic replay — метод cache warming, при котором реальные запросы из логов воспроизводятся против нового инстанса для наполнения кэша. Инструменты: GoReplay, tcpreplay. Преимущества: кэш наполняется реальными данными в реальных пропорциях. Используется при: запуске нового кэш-кластера, миграции между версиями, disaster recovery. Важно: replay в off-peak или с ограничением rate, чтобы не перегрузить БД.',
  },
  {
    id: 'sd-caching-043',
    block: 'sd',
    topic: 'caching',
    topicLabel: 'Кэширование',
    difficulty: 'junior',
    type: 'open',
    question: 'Что такое Memcached и чем он отличается от Redis?',
    sampleAnswer:
      'Memcached — высокопроизводительный distributed cache, хранящий пары ключ-значение в памяти. Ключевые отличия от Redis: 1) Структуры данных: Memcached — только строки; Redis — строки, хэши, списки, множества, sorted sets, streams и др. 2) Persistence: Memcached — только in-memory; Redis — поддерживает RDB/AOF persistence. 3) Репликация: Memcached — нет встроенной; Redis — master-replica репликация. 4) Многопоточность: Memcached — многопоточный; Redis — single-threaded (multi-threaded I/O с v6). 5) Протокол: Memcached — простой текстовый/бинарный; Redis — более богатый RESP. Когда Memcached: простой key-value кэш, максимальная производительность, уже используется в инфраструктуре. Когда Redis: нужны структуры данных, persistence, pub/sub, или универсальное решение.',
    explanation:
      'Memcached остаётся актуальным для pure caching сценариев благодаря простоте и производительности. Facebook (Meta) — крупнейший пользователь Memcached в мире. Redis доминирует благодаря универсальности — это не только кэш, но и структура данных, очередь, pub/sub.',
  },
  {
    id: 'sd-caching-044',
    block: 'sd',
    topic: 'caching',
    topicLabel: 'Кэширование',
    difficulty: 'middle',
    type: 'quiz',
    question: 'Какой Redis-команда позволяет установить значение только если ключ не существует (атомарно)?',
    options: [
      'SET key value',
      'SETNX key value или SET key value NX',
      'GET key',
      'APPEND key value',
    ],
    correctIndex: 1,
    explanation:
      'SETNX (SET if Not eXists) или SET key value NX устанавливает значение только если ключ не существует. Возвращает 1 (успех) или 0 (ключ уже есть). Используется для: distributed locks (SET lock_key value NX EX 10), предотвращения перезаписи, cache stampede prevention (только один запрос идёт в БД). SET с опциями NX (not exists) и XX (only if exists) — более современный способ.',
  },
  {
    id: 'sd-caching-045',
    block: 'sd',
    topic: 'caching',
    topicLabel: 'Кэширование',
    difficulty: 'middle',
    type: 'open',
    question: 'Как реализовать инвалидацию кэша при обновлении связанных данных (каскадная инвалидация)?',
    sampleAnswer:
      'Каскадная инвалидация — инвалидация зависимых ключей при изменении исходных данных. Подходы: 1) Tag-based invalidation — каждый ключ ассоциируется с тегами (user:123, product:456). При изменении user:123 инвалидируются все ключи с этим тегом. Реализация: Redis SET для хранения связей tag → keys. 2) Dependency graph — явный граф зависимостей: profile зависит от user и settings. При изменении — обход графа. 3) Event-driven — при обновлении публиковать событие, подписчики знают, какие ключи инвалидировать. 4) Pattern-based — использовать wildcards: SCAN MATCH user:123:* и удалить все. Медленно, но просто. 5) Versioning — вместо инвалидации менять версию в ключе: user:123:v2:profile. Старые версии expire естественно. Важно: инвалидация должна быть атомарной или идемпотентной.',
    explanation:
      'Каскадная инвалидация — одна из сложнейших проблем кэширования. На практике часто используют conservative подход: инвалидировать больше, чем нужно, чтобы гарантировать консистентность. Tag-based invalidation реализована в некоторых кэш-библиотеках (Symfony Cache).',
  },
  {
    id: 'sd-caching-046',
    block: 'sd',
    topic: 'caching',
    topicLabel: 'Кэширование',
    difficulty: 'senior',
    type: 'quiz',
    question: 'Что такое cache coalescing (или request coalescing)?',
    options: [
      'Объединение нескольких кэш-серверов в один',
      'Объединение одинаковых параллельных запросов в один для предотвращения duplicate loads',
      'Сжатие данных в кэше',
      'Слияние нескольких кэш-ключей',
    ],
    correctIndex: 1,
    explanation:
      'Request coalescing — объединение нескольких одновременных запросов к одному ключу в один запрос к источнику. Когда 100 запросов одновременно обнаруживают cache miss, только один идёт в БД, остальные ждут результата. Предотвращает cache stampede. Реализации: singleflight (Go), async memoization, Nginx proxy_cache_lock. Важно настроить timeout ожидания, чтобы не блокировать слишком долго.',
  },
  {
    id: 'sd-caching-047',
    block: 'sd',
    topic: 'caching',
    topicLabel: 'Кэширование',
    difficulty: 'senior',
    type: 'open',
    question: 'Как проектировать кэширование для системы с требованием high availability? Какие паттерны отказоустойчивости применяются?',
    sampleAnswer:
      'High availability кэширование: 1) Redis Sentinel — мониторинг master-replica, автоматический failover. Sentinel-процессы отслеживают master, при отказе промотируют replica. 2) Redis Cluster — шардирование + репликация, автоматический failover на уровне слотов. 3) Multi-tier caching — L1 in-process + L2 distributed. При отказе L2 система деградирует, но работает. 4) Circuit breaker — при недоступности кэша временно идти напрямую в БД, не перегружая cache retries. 5) Fallback to stale — при ошибке кэша возвращать stale данные (если хранятся локально). 6) Write-through с async — при отказе кэша продолжать записи в БД, восстанавливать кэш позже. 7) Geographic replication — Redis Enterprise Active-Active для multi-DC. 8) Cache-aside graceful degradation — система работает при полном отказе кэша (медленнее, но работает).',
    explanation:
      'Кэш не должен быть single point of failure. Правило: система должна работать (пусть медленнее) при полном отказе кэша. Netflix использует fallback patterns повсеместно — при проблемах с кэшем возвращают generic рекомендации вместо персонализированных.',
  },
  {
    id: 'sd-caching-048',
    block: 'sd',
    topic: 'caching',
    topicLabel: 'Кэширование',
    difficulty: 'junior',
    type: 'quiz',
    question: 'Какая проблема возникает при использовании локального кэша в нескольких инстансах приложения?',
    options: [
      'Локальный кэш работает медленнее распределённого',
      'Данные в разных инстансах могут отличаться (inconsistency)',
      'Локальный кэш требует больше памяти',
      'Локальный кэш не поддерживает TTL',
    ],
    correctIndex: 1,
    explanation:
      'При использовании локального кэша в нескольких инстансах данные рассогласовываются: инстанс A обновил данные и свой кэш, но инстанс B всё ещё отдаёт старые данные из своего локального кэша. Решения: 1) Event-driven invalidation — при обновлении рассылать событие всем инстансам (Redis Pub/Sub). 2) Короткий TTL — уменьшить окно рассогласованности. 3) Использовать distributed cache вместо локального. 4) Комбинация: локальный кэш с очень коротким TTL + distributed cache.',
  },
  {
    id: 'sd-caching-049',
    block: 'sd',
    topic: 'caching',
    topicLabel: 'Кэширование',
    difficulty: 'middle',
    type: 'quiz',
    question: 'Что такое cache miss penalty и как его минимизировать?',
    options: [
      'Штраф за использование слишком большого кэша',
      'Время и ресурсы, затраченные на загрузку данных при промахе кэша',
      'Стоимость операций записи в кэш',
      'Overhead на поддержание консистентности кэша',
    ],
    correctIndex: 1,
    explanation:
      'Cache miss penalty — время и ресурсы, затраченные на получение данных из источника при cache miss. Включает: сетевой latency до БД, время выполнения запроса, сериализацию, запись в кэш. Минимизация: 1) Cache warming — предзаполнение кэша. 2) Read-ahead — загрузка связанных данных превентивно. 3) Оптимизация запросов к БД — индексы, денормализация. 4) Multi-tier caching — L1 miss → L2 hit быстрее, чем L1 miss → DB. 5) Background refresh — обновление до истечения TTL.',
  },
  {
    id: 'sd-caching-050',
    block: 'sd',
    topic: 'caching',
    topicLabel: 'Кэширование',
    difficulty: 'senior',
    type: 'open',
    question: 'Опишите архитектуру кэширования для e-commerce платформы с миллионами товаров и высокими требованиями к актуальности цен и наличия.',
    sampleAnswer:
      'Архитектура кэширования e-commerce: 1) Catalog (товары) — длинный TTL (часы), инвалидация по событию от PIM. Elasticsearch + Redis для поиска и карточек. 2) Prices — короткий TTL (минуты) или event-driven update. Критичны для бизнеса, staleness недопустим. Отдельный price service с hot cache. 3) Inventory (наличие) — real-time или near-real-time. Write-through в Redis при изменении. Для отображения — eventual consistency OK, для оформления заказа — strict check. 4) User cart — Redis с persistence, per-user ключи. 5) Search results — кэшировать популярные запросы, invalidate при изменении цен в результатах (tag-based). 6) Category pages — ESI/fragment caching, product cards cached отдельно. 7) Recommendations — precomputed и кэшированы, обновление batch. 8) CDN layer — статика товаров, HTML для SEO. Multi-tier: Browser → CDN → Nginx → Application (L1) → Redis (L2) → Database.',
    explanation:
      'E-commerce кэширование — баланс между производительностью и актуальностью. Цены и наличие критичны — показать неверную цену = юридическая и репутационная проблема. Amazon использует отдельные системы для «browse» (eventual consistency OK) и «buy» (strict consistency).',
  },
];
