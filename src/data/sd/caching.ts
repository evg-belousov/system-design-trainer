import type { Question } from '../types';

export const cachingQuestions: Question[] = [
  {
    id: 'sd-caching-001',
    block: 'sd',
    topic: 'caching',
    topicLabel: 'Кэширование',
    difficulty: 'junior',
    type: 'quiz',
    question: 'Какая основная цель использования кэширования в системном дизайне?',
    options: [
      'Уменьшение объёма хранимых данных',
      'Снижение задержки (latency) и нагрузки на основное хранилище за счёт хранения часто запрашиваемых данных в быстрой памяти',
      'Обеспечение консистентности данных между сервисами',
      'Защита данных от несанкционированного доступа',
    ],
    correctIndex: 1,
    explanation:
      'Кэширование -- это хранение копий часто запрашиваемых данных в быстродействующем хранилище (обычно в оперативной памяти). Это позволяет значительно снизить задержку ответов (с миллисекунд обращения к БД до микросекунд обращения к памяти) и уменьшить нагрузку на основное хранилище (базу данных). По принципу Парето, 80% запросов обычно приходится на 20% данных, что делает кэширование очень эффективным.',
  },
  {
    id: 'sd-caching-002',
    block: 'sd',
    topic: 'caching',
    topicLabel: 'Кэширование',
    difficulty: 'middle',
    type: 'quiz',
    question: 'Что такое стратегия Cache-Aside (Lazy Loading)?',
    options: [
      'Данные записываются одновременно в кэш и в базу данных',
      'Приложение сначала проверяет кэш; при промахе загружает данные из БД и помещает в кэш',
      'Кэш автоматически синхронизируется с базой данных через CDC',
      'Данные сначала записываются в кэш, а затем асинхронно сбрасываются в БД',
    ],
    correctIndex: 1,
    explanation:
      'Cache-Aside (Lazy Loading) -- наиболее распространённая стратегия кэширования. Приложение сначала обращается к кэшу. При cache hit данные возвращаются напрямую. При cache miss приложение загружает данные из БД, записывает их в кэш и возвращает клиенту. Преимущества: в кэш попадают только реально запрашиваемые данные, кэш может упасть без потери данных. Недостатки: первый запрос всегда медленный (cold start), возможна рассинхронизация с БД (stale data).',
  },
  {
    id: 'sd-caching-003',
    block: 'sd',
    topic: 'caching',
    topicLabel: 'Кэширование',
    difficulty: 'middle',
    type: 'open',
    question: 'Сравните стратегии Write-Through и Write-Behind (Write-Back) кэширования. Какие у каждой преимущества и недостатки?',
    sampleAnswer:
      'Write-Through: данные записываются одновременно в кэш и в базу данных в рамках одной операции. Преимущества: кэш всегда консистентен с БД, простая модель, нет риска потери данных. Недостатки: более высокая задержка записи (запись в два хранилища), лишние записи в кэш для данных, которые могут не быть прочитаны. Write-Behind (Write-Back): данные записываются только в кэш, а в БД сбрасываются асинхронно (через очередь или по таймеру). Преимущества: очень низкая задержка записи, можно группировать (batch) записи в БД, снижение нагрузки на БД. Недостатки: риск потери данных при падении кэша до сброса в БД, более сложная реализация, eventual consistency.',
    explanation:
      'Выбор стратегии зависит от требований к консистентности и производительности. Write-Through подходит для систем, где консистентность критична (финансовые данные, инвентаризация). Write-Behind -- для систем с высокой нагрузкой на запись, где допустима кратковременная потеря данных (счётчики просмотров, логи активности). На практике часто используется Cache-Aside для чтения в сочетании с write-through для записи.',
  },
  {
    id: 'sd-caching-004',
    block: 'sd',
    topic: 'caching',
    topicLabel: 'Кэширование',
    difficulty: 'senior',
    type: 'open',
    question: 'Что такое проблема «cache stampede» (или «thundering herd»)? Как её предотвратить?',
    sampleAnswer:
      'Cache stampede возникает, когда срок действия популярного ключа в кэше истекает (TTL expiry), и множество параллельных запросов одновременно обнаруживают промах кэша. Все они одновременно обращаются к базе данных за одними и теми же данными, создавая пиковую нагрузку, которая может привести к отказу. Способы предотвращения: 1) Locking (мьютекс): только один запрос идёт в БД, остальные ждут заполнения кэша. 2) Probabilistic early expiration: каждый запрос с небольшой вероятностью обновляет кэш до истечения TTL, распределяя обновления во времени. 3) Background refresh: фоновый процесс обновляет кэш до истечения TTL. 4) Stale-while-revalidate: возвращать устаревшие данные, пока один запрос обновляет кэш. 5) «Вечный» TTL с явной инвалидацией.',
    explanation:
      'Cache stampede -- классическая проблема высоконагруженных систем. В 2010 году Facebook описал, как один просроченный ключ в Memcached мог вызвать сотни тысяч запросов к БД. Их решение -- lease-based подход: Memcached выдаёт «аренду» первому запросу, остальные получают сигнал подождать. Это паттерн, который необходимо учитывать при проектировании любой системы с кэшированием на масштабе.',
  },
  {
    id: 'sd-caching-005',
    block: 'sd',
    topic: 'caching',
    topicLabel: 'Кэширование',
    difficulty: 'junior',
    type: 'quiz',
    question: 'Какая политика вытеснения (eviction policy) удаляет из кэша элемент, который дольше всего не использовался?',
    options: [
      'FIFO (First In, First Out)',
      'LFU (Least Frequently Used)',
      'LRU (Least Recently Used)',
      'Random Replacement',
    ],
    correctIndex: 2,
    explanation:
      'LRU (Least Recently Used) -- политика вытеснения, которая удаляет элемент, к которому дольше всего не обращались. Она основана на предположении, что недавно использованные данные с большей вероятностью будут запрошены снова (принцип временной локальности). LRU -- одна из самых популярных политик вытеснения, используемая в Redis, Memcached и многих других системах кэширования. Реализуется обычно с помощью комбинации хэш-таблицы и двусвязного списка.',
  },
  {
    id: 'sd-caching-006',
    block: 'sd',
    topic: 'caching',
    topicLabel: 'Кэширование',
    difficulty: 'junior',
    type: 'quiz',
    question: 'Что такое TTL (Time To Live) в контексте кэширования?',
    options: [
      'Время, необходимое для записи данных в кэш',
      'Время, через которое запись в кэше автоматически считается устаревшей и удаляется',
      'Максимальное время ответа кэш-сервера',
      'Время синхронизации кэша между несколькими узлами',
    ],
    correctIndex: 1,
    explanation:
      'TTL (Time To Live) — это срок жизни записи в кэше, после истечения которого запись считается устаревшей (expired) и удаляется или обновляется при следующем запросе. TTL помогает решить проблему stale data — устаревших данных в кэше. Выбор TTL — это компромисс: короткий TTL обеспечивает свежесть данных, но увеличивает нагрузку на БД; длинный TTL снижает нагрузку, но повышает риск выдачи устаревших данных. Для разных типов данных TTL может быть разным: справочники — часы, профили пользователей — минуты, биржевые котировки — секунды.',
  },
  {
    id: 'sd-caching-007',
    block: 'sd',
    topic: 'caching',
    topicLabel: 'Кэширование',
    difficulty: 'junior',
    type: 'quiz',
    question: 'Что такое cache hit и cache miss?',
    options: [
      'Cache hit — ошибка кэша, cache miss — успешное обращение',
      'Cache hit — запрашиваемые данные найдены в кэше, cache miss — данных в кэше нет и нужно обратиться к основному хранилищу',
      'Cache hit — добавление данных в кэш, cache miss — удаление данных из кэша',
      'Cache hit — кэш заполнен полностью, cache miss — в кэше есть свободное место',
    ],
    correctIndex: 1,
    explanation:
      'Cache hit (попадание в кэш) — это ситуация, когда запрашиваемые данные находятся в кэше и возвращаются напрямую из него, без обращения к основному хранилищу. Cache miss (промах кэша) — данных в кэше нет, и система обращается к более медленному хранилищу (базе данных). Cache hit ratio (процент попаданий) — ключевая метрика эффективности кэширования. Хороший показатель — 90-99% hit ratio. Низкий hit ratio означает, что кэш неэффективен и, возможно, нужно пересмотреть стратегию кэширования или размер кэша.',
  },
  {
    id: 'sd-caching-008',
    block: 'sd',
    topic: 'caching',
    topicLabel: 'Кэширование',
    difficulty: 'junior',
    type: 'quiz',
    question: 'Какой HTTP-заголовок указывает браузеру, как долго можно использовать кэшированную копию ресурса?',
    options: [
      'Content-Type',
      'Cache-Control',
      'Authorization',
      'X-Forwarded-For',
    ],
    correctIndex: 1,
    explanation:
      'Cache-Control — основной HTTP-заголовок управления кэшированием. Его директивы определяют политику кэширования: max-age=3600 (кэшировать 1 час), no-cache (всегда проверять актуальность на сервере), no-store (не кэшировать вообще), public/private (может ли кэшироваться на промежуточных прокси), immutable (ресурс не изменится). Вместе с ETag и Last-Modified заголовками, Cache-Control обеспечивает эффективное кэширование на стороне браузера и CDN, снижая нагрузку на серверы и ускоряя загрузку для пользователей.',
  },
  {
    id: 'sd-caching-009',
    block: 'sd',
    topic: 'caching',
    topicLabel: 'Кэширование',
    difficulty: 'middle',
    type: 'quiz',
    question: 'Чем отличается стратегия Read-Through от Cache-Aside?',
    options: [
      'В Read-Through кэш сам загружает данные из БД при промахе, в Cache-Aside это делает приложение',
      'Read-Through работает только с записью, Cache-Aside — только с чтением',
      'Read-Through не использует TTL, а Cache-Aside использует',
      'Никакой разницы — это одно и то же',
    ],
    correctIndex: 0,
    explanation:
      'В стратегии Cache-Aside приложение управляет кэшем самостоятельно: проверяет кэш, при промахе загружает данные из БД и записывает в кэш. В Read-Through кэш-провайдер сам отвечает за загрузку данных при промахе — приложение всегда обращается только к кэшу, а кэш сам ходит в БД при необходимости. Read-Through упрощает код приложения и централизует логику загрузки, но требует поддержки со стороны кэш-системы. Примеры кэшей с поддержкой Read-Through: Ehcache, NCache, Oracle Coherence.',
  },
  {
    id: 'sd-caching-010',
    block: 'sd',
    topic: 'caching',
    topicLabel: 'Кэширование',
    difficulty: 'middle',
    type: 'quiz',
    question: 'Что такое cache warming (прогрев кэша)?',
    options: [
      'Увеличение размера кэша в период повышенной нагрузки',
      'Предварительное заполнение кэша данными перед поступлением реальной нагрузки',
      'Мониторинг температуры серверов кэша',
      'Постепенное увеличение TTL кэшированных записей',
    ],
    correctIndex: 1,
    explanation:
      'Cache warming (прогрев кэша) — это предварительное заполнение кэша данными до того, как система начнёт принимать реальные запросы. Это важно при перезапуске кэш-серверов, деплое новой версии или запуске нового дата-центра. Без прогрева все запросы будут cache miss, создавая пиковую нагрузку на БД (cold start problem). Способы прогрева: 1) Скрипт, загружающий часто запрашиваемые данные. 2) Replay-логи предыдущих запросов. 3) Постепенное перенаправление трафика (через балансировщик). 4) Создание snapshot кэша и его восстановление.',
  },
  {
    id: 'sd-caching-011',
    block: 'sd',
    topic: 'caching',
    topicLabel: 'Кэширование',
    difficulty: 'middle',
    type: 'open',
    question: 'Что такое multi-level caching (многоуровневое кэширование)? Приведите пример типичной конфигурации уровней кэширования в веб-приложении.',
    sampleAnswer:
      'Multi-level caching — использование нескольких уровней кэширования, каждый с разными характеристиками по скорости, объёму и расстоянию от клиента. Типичные уровни в веб-приложении (от клиента к серверу): 1) Браузерный кэш (L1) — HTTP-кэш в браузере, управляется заголовками Cache-Control, ETag. Самый быстрый — нет сетевого запроса. 2) CDN (L2) — кэш на edge-серверах CDN, близких к пользователю. Кэширует статику и иногда динамический контент. 3) Reverse proxy / API Gateway (L3) — кэш на уровне Nginx, Varnish. Кэширует ответы API. 4) In-process кэш (L4) — кэш в памяти приложения (Guava Cache, Caffeine). Самый быстрый серверный кэш, но ограничен размером и не разделяется между экземплярами. 5) Distributed cache (L5) — Redis, Memcached. Разделяется между всеми экземплярами, но требует сетевого вызова. 6) Database cache — буферный пул БД (InnoDB Buffer Pool). Каждый уровень обеспечивает разный баланс скорости, объёма и свежести данных.',
    explanation:
      'Multi-level caching позволяет каждому запросу быть обслуженным максимально близко к клиенту. Чем выше уровень (ближе к клиенту), тем быстрее ответ, но тем сложнее инвалидация. Ключевой вызов — обеспечить консистентность между уровнями. На практике используют каскадную инвалидацию: при обновлении данных инвалидируются все уровни от БД до CDN.',
  },
  {
    id: 'sd-caching-012',
    block: 'sd',
    topic: 'caching',
    topicLabel: 'Кэширование',
    difficulty: 'middle',
    type: 'quiz',
    question: 'Какую проблему решает паттерн «cache invalidation» и почему он считается одной из двух сложнейших задач в Computer Science?',
    options: [
      'Определение размера кэша для оптимальной производительности',
      'Выбор оптимального алгоритма сжатия кэшированных данных',
      'Обеспечение своевременного удаления или обновления устаревших данных в кэше при изменении источника',
      'Распределение кэша между несколькими серверами',
    ],
    correctIndex: 2,
    explanation:
      'Cache invalidation — это процесс удаления или обновления записей в кэше, когда соответствующие данные в основном хранилище изменились. Это сложно, потому что: 1) Нужно отследить все места, где данные кэшированы (включая CDN, браузеры, in-process кэши). 2) Между обновлением БД и инвалидацией кэша есть временное окно, когда данные рассогласованы. 3) В распределённой системе инвалидация должна дойти до всех узлов. 4) Race conditions: параллельные чтение и запись могут привести к кэшированию устаревших данных. Фил Карлтон из Netscape сказал: «В Computer Science есть только две сложные вещи: инвалидация кэша и именование».',
  },
  {
    id: 'sd-caching-013',
    block: 'sd',
    topic: 'caching',
    topicLabel: 'Кэширование',
    difficulty: 'senior',
    type: 'quiz',
    question: 'Как Redis Cluster обеспечивает горизонтальное масштабирование распределённого кэша?',
    options: [
      'Каждый узел хранит полную копию всех данных',
      'Данные автоматически распределяются по 16384 хэш-слотам между узлами кластера',
      'Клиент самостоятельно определяет, на какой узел отправить запрос, без участия кластера',
      'Redis Cluster не поддерживает горизонтальное масштабирование',
    ],
    correctIndex: 1,
    explanation:
      'Redis Cluster использует 16384 хэш-слота для распределения ключей между узлами. Каждый узел отвечает за подмножество слотов. Ключ хэшируется (CRC16(key) mod 16384) для определения слота. При добавлении нового узла часть слотов мигрирует на него (resharding) без остановки кластера. Каждый узел знает маппинг слотов на узлы и может перенаправить клиента (MOVED redirect) на правильный узел. Для отказоустойчивости каждый master-узел имеет replica, которая автоматически промотируется при отказе master-а.',
  },
  {
    id: 'sd-caching-014',
    block: 'sd',
    topic: 'caching',
    topicLabel: 'Кэширование',
    difficulty: 'senior',
    type: 'open',
    question: 'Что такое cache coherence (когерентность кэша) в распределённых системах? Какие стратегии обеспечения когерентности существуют?',
    sampleAnswer:
      'Cache coherence — это обеспечение согласованности данных между несколькими кэшами, когда данные могут быть изменены. В распределённой системе с несколькими экземплярами приложения каждый может иметь свой in-process кэш, и изменение данных одним экземпляром должно быть отражено в кэшах остальных. Стратегии: 1) Централизованный кэш (Redis/Memcached) — все экземпляры используют один распределённый кэш, проблема когерентности решается на уровне хранилища. 2) Invalidation-based — при изменении данных отправляется сообщение (через Redis Pub/Sub, Kafka) всем экземплярам с командой удалить запись из локального кэша. 3) Update-based — вместо инвалидации рассылается новое значение для обновления кэша. 4) TTL-based — каждый кэш самостоятельно обновляет данные по истечении TTL, допуская кратковременную рассогласованность. 5) Versioning — при каждом изменении увеличивается версия, кэшированная запись проверяется по версии. На практике комбинируют подходы: централизованный Redis для горячих данных + инвалидация через Pub/Sub для in-process кэшей.',
    explanation:
      'Cache coherence в распределённых системах аналогична проблеме когерентности кэшей в многопроцессорных системах, но на другом масштабе. В CPU используются протоколы MESI/MOESI, в распределённых системах — message-passing. Ключевой компромисс: чем строже когерентность, тем выше задержка и сложность. Для большинства веб-приложений eventual consistency через TTL + event-based invalidation является оптимальным решением.',
  },
  {
    id: 'sd-caching-015',
    block: 'sd',
    topic: 'caching',
    topicLabel: 'Кэширование',
    difficulty: 'junior',
    type: 'quiz',
    question: 'Какой из перечисленных инструментов является распределённым кэшем?',
    options: [
      'PostgreSQL',
      'Redis',
      'Nginx',
      'Prometheus',
    ],
    correctIndex: 1,
    explanation:
      'Redis — это высокопроизводительное in-memory хранилище данных, широко используемое как распределённый кэш. Redis хранит данные в оперативной памяти, обеспечивая задержку порядка микросекунд. Поддерживает различные структуры данных (строки, хэши, списки, множества, sorted sets), TTL для записей, persistence (RDB, AOF) и кластеризацию (Redis Cluster) для горизонтального масштабирования. Memcached — другой популярный распределённый кэш, более простой и специализированный.',
  },
  {
    id: 'sd-caching-016',
    block: 'sd',
    topic: 'caching',
    topicLabel: 'Кэширование',
    difficulty: 'middle',
    type: 'open',
    question: 'Объясните HTTP-механизм условных запросов (conditional requests) с использованием ETag и If-None-Match. Как это помогает кэшированию?',
    sampleAnswer:
      'ETag (Entity Tag) — это идентификатор версии ресурса, генерируемый сервером (обычно хэш содержимого или номер версии). Механизм работает так: 1) Клиент запрашивает ресурс. Сервер отвечает с заголовком ETag: "abc123". 2) Клиент кэширует ресурс и ETag. 3) При следующем запросе клиент отправляет заголовок If-None-Match: "abc123". 4) Сервер сравнивает ETag: если ресурс не изменился, возвращает 304 Not Modified без тела ответа (экономя трафик). Если изменился — возвращает 200 OK с новым ресурсом и новым ETag. Аналогично работает пара Last-Modified / If-Modified-Since, но по дате модификации. Условные запросы экономят трафик и снижают нагрузку на сервер, но не устраняют сам запрос (в отличие от Cache-Control: max-age). Оптимальный подход — комбинировать: Cache-Control для статических ресурсов (JS, CSS с хэшем в имени файла) и ETag для динамических ресурсов.',
    explanation:
      'Условные запросы — важная часть HTTP-кэширования, особенно для ресурсов, которые нельзя кэшировать надолго (Cache-Control: no-cache). Они позволяют серверу быстро подтвердить актуальность кэшированной версии без передачи полного содержимого. Это особенно эффективно для больших ресурсов (изображения, документы).',
  },
  {
    id: 'sd-caching-017',
    block: 'sd',
    topic: 'caching',
    topicLabel: 'Кэширование',
    difficulty: 'senior',
    type: 'quiz',
    question: 'Какой подход к инвалидации кэша минимизирует нагрузку на БД при одновременном истечении TTL популярного ключа?',
    options: [
      'Установить одинаковый TTL для всех ключей',
      'Использовать мьютекс (lock) — только один запрос обновляет кэш, остальные ждут',
      'Удалять все ключи кэша при каждом обновлении БД',
      'Не использовать TTL вообще',
    ],
    correctIndex: 1,
    explanation:
      'Подход с мьютексом (lock) — один из основных способов предотвращения cache stampede. Когда несколько запросов обнаруживают cache miss для одного ключа, только первый захватывает блокировку (например, через Redis SETNX) и загружает данные из БД. Остальные запросы ждут (с коротким sleep и retry) или получают слегка устаревшие данные (stale-while-revalidate). Другие подходы: probabilistic early expiration (каждый запрос с небольшой вероятностью обновляет кэш до истечения TTL) и background refresh (фоновый процесс обновляет кэш до истечения TTL).',
  },
  {
    id: 'sd-caching-018',
    block: 'sd',
    topic: 'caching',
    topicLabel: 'Кэширование',
    difficulty: 'senior',
    type: 'open',
    question: 'Сравните Redis и Memcached как решения для распределённого кэширования. В каких сценариях каждый из них предпочтительнее?',
    sampleAnswer:
      'Redis: поддерживает разнообразные структуры данных (строки, хэши, списки, множества, sorted sets, HyperLogLog, streams), persistence (RDB-снимки, AOF-лог), репликацию, кластеризацию (Redis Cluster), Lua-скриптинг, pub/sub, транзакции. Предпочтителен, когда: нужны сложные структуры данных, нужна persistence, нужен pub/sub, требуется кластеризация с автоматическим failover. Memcached: простой key-value кэш, многопоточная архитектура (лучше утилизирует многоядерные CPU), простой протокол, автоматическое slab-управление памятью. Предпочтителен, когда: нужен максимально простой кэш, данные — только строки/сериализованные объекты, нужна максимальная производительность на многоядерном сервере, не нужна persistence. На практике Redis доминирует благодаря своей универсальности, но Memcached остаётся актуальным для сценариев чистого кэширования с максимальной производительностью (используется в Facebook/Meta).',
    explanation:
      'Оба инструмента обеспечивают задержку порядка микросекунд и широко используются в production. Redis, начиная с версии 6, поддерживает многопоточный I/O, сокращая разрыв в производительности с Memcached. Выбор часто зависит от экосистемы и опыта команды. В облачных средах доступны управляемые сервисы: AWS ElastiCache поддерживает оба.',
  },
  {
    id: 'sd-caching-019',
    block: 'sd',
    topic: 'caching',
    topicLabel: 'Кэширование',
    difficulty: 'middle',
    type: 'quiz',
    question: 'Что такое «cache penetration» и как от него защититься?',
    options: [
      'Атака, при которой злоумышленник получает доступ к данным через кэш',
      'Ситуация, когда запросы к несуществующим ключам всегда проходят в БД, минуя кэш',
      'Переполнение памяти кэш-сервера',
      'Утечка данных из кэша при его перезапуске',
    ],
    correctIndex: 1,
    explanation:
      'Cache penetration — проблема, когда частые запросы к несуществующим данным каждый раз проходят в базу данных, минуя кэш (потому что нечего кэшировать). Это может быть как легитимным сценарием, так и атакой. Способы защиты: 1) Кэширование null-значений — записывать в кэш «пустой» результат с коротким TTL. 2) Bloom Filter — вероятностная структура данных, проверяющая существование ключа без обращения к БД. 3) Валидация входных данных — фильтровать заведомо невалидные запросы до кэша.',
  },
  {
    id: 'sd-caching-020',
    block: 'sd',
    topic: 'caching',
    topicLabel: 'Кэширование',
    difficulty: 'senior',
    type: 'open',
    question: 'Опишите стратегию кэширования для системы с высокой нагрузкой на запись (write-heavy workload). Какие паттерны и компромиссы необходимо учитывать?',
    sampleAnswer:
      'Для write-heavy систем стандартные стратегии кэширования (Cache-Aside, Read-Through) менее эффективны, потому что данные часто инвалидируются. Подходы: 1) Write-Behind (Write-Back) — записи буферизуются в кэше и асинхронно сбрасываются в БД пакетами (batching). Снижает нагрузку на БД, но риск потери при отказе кэша. 2) CQRS — разделение моделей чтения и записи, кэш обслуживает только чтение из отдельной read-модели. 3) Event-driven invalidation — при записи отправляется событие через Kafka/Redis Pub/Sub для инвалидации кэшей всех экземпляров. 4) Write-Around — запись идёт только в БД, минуя кэш. Кэш обновляется при чтении (Cache-Aside). Подходит, когда записанные данные редко читаются сразу. 5) Агрегирование записей — вместо записи каждого инкремента (счётчик просмотров), агрегировать в Redis (INCR) и периодически сбрасывать в БД. Компромиссы: durability vs performance, consistency vs latency, complexity vs reliability.',
    explanation:
      'Write-heavy системы (метрики, логи, IoT-данные, social media feeds) требуют принципиально другого подхода к кэшированию, чем read-heavy. Ключевой принцип — минимизировать синхронные записи в БД через буферизацию и агрегирование. Системы вроде Twitter используют fan-out-on-write (запись в кэш таймлайна каждого фолловера при публикации твита), а не fan-out-on-read.',
  },
];
