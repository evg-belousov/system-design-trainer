import type { Question } from '../types';

export const resilienceQuestions: Question[] = [
  {
    id: 'sd-resilience-001',
    block: 'sd',
    topic: 'resilience',
    topicLabel: 'Отказоустойчивость',
    difficulty: 'junior',
    type: 'quiz',
    question: 'Что такое отказоустойчивость (fault tolerance) в контексте распределённых систем?',
    options: [
      'Способность системы работать без каких-либо сбоев',
      'Способность системы продолжать корректную работу при отказе одного или нескольких компонентов',
      'Автоматическое масштабирование системы при увеличении нагрузки',
      'Шифрование данных для защиты от внешних угроз',
    ],
    correctIndex: 1,
    explanation:
      'Отказоустойчивость -- это свойство системы продолжать корректно функционировать даже при выходе из строя части её компонентов. Это достигается за счёт избыточности, репликации, автоматического переключения на резервные узлы и других механизмов. В распределённых системах отказы неизбежны (сеть, диски, процессы), поэтому проектирование с учётом отказоустойчивости -- фундаментальное требование.',
  },
  {
    id: 'sd-resilience-002',
    block: 'sd',
    topic: 'resilience',
    topicLabel: 'Отказоустойчивость',
    difficulty: 'junior',
    type: 'quiz',
    question: 'Какой паттерн предотвращает каскадные отказы, прекращая вызовы к неработающему сервису после определённого порога ошибок?',
    options: [
      'Retry Pattern',
      'Bulkhead Pattern',
      'Circuit Breaker Pattern',
      'Saga Pattern',
    ],
    correctIndex: 2,
    explanation:
      'Circuit Breaker (предохранитель) -- паттерн, который отслеживает количество ошибок при вызове внешнего сервиса. При превышении порога ошибок он «размыкается» и немедленно возвращает ошибку без попытки вызова, давая отказавшему сервису время на восстановление. Через определённый интервал переходит в состояние half-open и пропускает пробный запрос. Если он успешен -- замыкается обратно. Это предотвращает каскадные отказы и экономит ресурсы.',
  },
  {
    id: 'sd-resilience-003',
    block: 'sd',
    topic: 'resilience',
    topicLabel: 'Отказоустойчивость',
    difficulty: 'junior',
    type: 'quiz',
    question: 'Какие три состояния имеет паттерн Circuit Breaker?',
    options: [
      'Open, Closed, Locked',
      'Closed, Open, Half-Open',
      'Active, Passive, Standby',
      'Ready, Blocked, Recovery',
    ],
    correctIndex: 1,
    explanation:
      'Circuit Breaker имеет три состояния: Closed (замкнут) -- запросы проходят нормально, ошибки считаются; Open (разомкнут) -- все запросы немедленно отклоняются без вызова зависимого сервиса; Half-Open (полуоткрыт) -- пропускается ограниченное количество пробных запросов, чтобы проверить, восстановился ли сервис. Если пробные запросы успешны, Circuit Breaker переходит в Closed; если нет -- обратно в Open.',
  },
  {
    id: 'sd-resilience-004',
    block: 'sd',
    topic: 'resilience',
    topicLabel: 'Отказоустойчивость',
    difficulty: 'junior',
    type: 'quiz',
    question: 'Что такое Health Check в микросервисной архитектуре?',
    options: [
      'Проверка наличия обновлений для зависимостей сервиса',
      'Периодический эндпоинт, позволяющий определить, работоспособен ли сервис и готов ли он принимать трафик',
      'Аудит безопасности сервиса перед деплоем',
      'Нагрузочный тест для проверки производительности сервиса',
    ],
    correctIndex: 1,
    explanation:
      'Health Check -- это специальный эндпоинт (обычно /health или /healthz), который возвращает статус работоспособности сервиса. Различают liveness probe (сервис жив и не завис) и readiness probe (сервис готов принимать трафик). Балансировщики нагрузки и оркестраторы (Kubernetes) используют health checks для маршрутизации трафика только на здоровые инстансы и автоматического перезапуска зависших.',
  },
  {
    id: 'sd-resilience-005',
    block: 'sd',
    topic: 'resilience',
    topicLabel: 'Отказоустойчивость',
    difficulty: 'junior',
    type: 'quiz',
    question: 'Что такое стратегия retry с экспоненциальным backoff?',
    options: [
      'Повтор запроса с постоянным интервалом между попытками',
      'Повтор запроса с экспоненциально увеличивающимся интервалом ожидания между попытками',
      'Повтор запроса к другому инстансу того же сервиса',
      'Однократный повтор запроса после длительной паузы',
    ],
    correctIndex: 1,
    explanation:
      'Exponential backoff -- стратегия повторных попыток, при которой интервал между ретраями увеличивается экспоненциально (например, 1с, 2с, 4с, 8с). Это предотвращает перегрузку уже нагруженного сервиса лавиной повторных запросов. Часто добавляют jitter (случайное отклонение), чтобы избежать синхронизации ретраев от множества клиентов. Формула: delay = min(base * 2^attempt + random_jitter, max_delay).',
  },
  {
    id: 'sd-resilience-006',
    block: 'sd',
    topic: 'resilience',
    topicLabel: 'Отказоустойчивость',
    difficulty: 'junior',
    type: 'quiz',
    question: 'Какая модель избыточности подразумевает, что обе реплики одновременно обрабатывают трафик?',
    options: [
      'Active-Passive',
      'Active-Active',
      'Master-Slave',
      'Cold Standby',
    ],
    correctIndex: 1,
    explanation:
      'В модели Active-Active все реплики одновременно обрабатывают запросы, распределяя нагрузку между собой. При отказе одной реплики остальные продолжают работать, и трафик перераспределяется автоматически. Преимущества: более эффективное использование ресурсов, минимальное время переключения (near-zero downtime). Недостатки: сложность синхронизации данных между репликами, потенциальные конфликты при одновременной записи.',
  },
  {
    id: 'sd-resilience-007',
    block: 'sd',
    topic: 'resilience',
    topicLabel: 'Отказоустойчивость',
    difficulty: 'middle',
    type: 'quiz',
    question: 'Что такое паттерн Bulkhead и какую проблему он решает?',
    options: [
      'Разделение системы на изолированные отсеки, чтобы отказ одного компонента не исчерпал ресурсы всей системы',
      'Кэширование ответов для снижения нагрузки на downstream-сервисы',
      'Шифрование данных между микросервисами для обеспечения безопасности',
      'Автоматическое масштабирование подов в Kubernetes при увеличении нагрузки',
    ],
    correctIndex: 0,
    explanation:
      'Bulkhead (переборка) -- паттерн, заимствованный из кораблестроения: корпус корабля разделён на отсеки, и затопление одного не приводит к потоплению всего судна. В ПО это реализуется через выделение отдельных пулов потоков, connection pools или отдельных инстансов для разных зависимостей. Если один downstream-сервис тормозит, он исчерпает только свой пул ресурсов, не затрагивая остальные вызовы.',
  },
  {
    id: 'sd-resilience-008',
    block: 'sd',
    topic: 'resilience',
    topicLabel: 'Отказоустойчивость',
    difficulty: 'middle',
    type: 'quiz',
    question: 'Чем отличаются RPO (Recovery Point Objective) и RTO (Recovery Time Objective)?',
    options: [
      'RPO -- максимально допустимое время простоя, RTO -- максимальный объём потерянных данных',
      'RPO -- максимально допустимый объём потерянных данных (за какой период), RTO -- максимально допустимое время восстановления после отказа',
      'RPO -- количество реплик данных, RTO -- количество попыток восстановления',
      'RPO и RTO -- это одно и то же, просто разные термины для времени восстановления',
    ],
    correctIndex: 1,
    explanation:
      'RPO (Recovery Point Objective) определяет максимально допустимый период потери данных: если RPO = 1 час, значит при аварии допустима потеря данных за последний час. Это влияет на частоту бэкапов и репликации. RTO (Recovery Time Objective) определяет максимально допустимое время восстановления работы системы после аварии. RPO=0 требует синхронной репликации, RTO=0 требует active-active конфигурации. Оба показателя напрямую влияют на стоимость инфраструктуры.',
  },
  {
    id: 'sd-resilience-009',
    block: 'sd',
    topic: 'resilience',
    topicLabel: 'Отказоустойчивость',
    difficulty: 'middle',
    type: 'quiz',
    question: 'Что такое Graceful Degradation?',
    options: [
      'Полная остановка сервиса при возникновении любой ошибки',
      'Постепенное снижение функциональности системы при отказе компонентов, сохраняя работоспособность ключевых функций',
      'Автоматическое удаление устаревших данных из базы данных',
      'Снижение версии приложения при обнаружении критической уязвимости',
    ],
    correctIndex: 1,
    explanation:
      'Graceful Degradation (грациозная деградация) -- подход, при котором система продолжает предоставлять основную функциональность даже при отказе некритических компонентов. Например, интернет-магазин может отключить рекомендации и отзывы при сбое соответствующих сервисов, но продолжать работу каталога и оформления заказов. Это требует чёткого определения приоритетов функций и реализации fallback-механизмов.',
  },
  {
    id: 'sd-resilience-010',
    block: 'sd',
    topic: 'resilience',
    topicLabel: 'Отказоустойчивость',
    difficulty: 'middle',
    type: 'quiz',
    question: 'Зачем при retry-стратегии добавляют jitter (случайное отклонение) к интервалу ожидания?',
    options: [
      'Чтобы ускорить обработку запросов за счёт параллельных ретраев',
      'Чтобы избежать ситуации, когда множество клиентов одновременно повторяют запросы и создают всплеск нагрузки (thundering herd)',
      'Чтобы обеспечить криптографическую стойкость повторных запросов',
      'Чтобы пропустить заведомо неуспешные попытки и сэкономить ресурсы',
    ],
    correctIndex: 1,
    explanation:
      'Без jitter множество клиентов, начавших ретраи одновременно (например, после общего сбоя), будут повторять запросы синхронно: через 1с, через 2с, через 4с -- создавая периодические всплески нагрузки. Jitter добавляет случайное отклонение к интервалу, распределяя ретраи во времени. AWS рекомендует «full jitter»: delay = random(0, base * 2^attempt), что эмпирически показывает наилучшие результаты при минимизации общего времени восстановления.',
  },
  {
    id: 'sd-resilience-011',
    block: 'sd',
    topic: 'resilience',
    topicLabel: 'Отказоустойчивость',
    difficulty: 'middle',
    type: 'open',
    question: 'Опишите разницу между failover-стратегиями Active-Active и Active-Passive. Когда какую лучше использовать?',
    sampleAnswer:
      'Active-Active: все узлы одновременно обрабатывают трафик. Плюсы: эффективное использование ресурсов, минимальное время переключения, естественная балансировка нагрузки. Минусы: сложность синхронизации данных, потенциальные конфликты записи, более высокая стоимость обеспечения консистентности. Active-Passive: основной узел обрабатывает трафик, резервный находится в режиме ожидания. Плюсы: простота, нет конфликтов данных, гарантия консистентности. Минусы: резервный узел простаивает, время переключения (failover time) может составлять секунды-минуты. Active-Active подходит для систем с высокими требованиями к доступности (99.99%+) и масштабируемости. Active-Passive -- для систем, где критична строгая консистентность данных и допустим кратковременный простой.',
    explanation:
      'Выбор стратегии зависит от бизнес-требований. Для глобальных систем (CDN, DNS) active-active необходим. Для баз данных с финансовыми транзакциями часто предпочитают active-passive с синхронной репликацией. Существует также вариант Active-Hot Standby, где пассивный узел постоянно получает реплику и может переключиться быстрее, чем Cold Standby.',
  },
  {
    id: 'sd-resilience-012',
    block: 'sd',
    topic: 'resilience',
    topicLabel: 'Отказоустойчивость',
    difficulty: 'middle',
    type: 'open',
    question: 'Что такое Chaos Engineering? Опишите принципы и приведите примеры инструментов.',
    sampleAnswer:
      'Chaos Engineering -- дисциплина экспериментирования над распределённой системой с целью выявления слабых мест до того, как они приведут к реальным сбоям. Принципы: 1) Определить «стабильное состояние» системы через измеримые метрики. 2) Сформулировать гипотезу: «система продолжит работать при X». 3) Внести реальные сбои: убить контейнер, увеличить latency сети, заполнить диск. 4) Сравнить поведение с гипотезой. 5) Минимизировать «радиус взрыва» эксперимента. Инструменты: Netflix Chaos Monkey (случайное убийство инстансов), Gremlin (платформа для хаос-экспериментов), Litmus (для Kubernetes), AWS Fault Injection Simulator. Chaos Engineering должен проводиться сначала в staging, а затем в production с тщательным контролем.',
    explanation:
      'Netflix популяризировал Chaos Engineering, создав Simian Army -- набор инструментов для внесения различных типов сбоев. Ключевой принцип: если вы не тестируете отказы в контролируемых условиях, вы узнаете о них в самый неподходящий момент. Chaos Engineering -- неотъемлемая часть культуры SRE в крупных технологических компаниях.',
  },
  {
    id: 'sd-resilience-013',
    block: 'sd',
    topic: 'resilience',
    topicLabel: 'Отказоустойчивость',
    difficulty: 'middle',
    type: 'open',
    question: 'Как реализовать health checks в Kubernetes? Чем отличаются liveness, readiness и startup probes?',
    sampleAnswer:
      'Liveness Probe -- проверяет, что контейнер жив и не завис. Если проверка не проходит, Kubernetes перезапускает контейнер. Используется для обнаружения deadlocks и зависших процессов. Readiness Probe -- проверяет, что контейнер готов принимать трафик. Если проверка не проходит, pod удаляется из Service (перестаёт получать трафик), но не перезапускается. Используется при инициализации, прогреве кэша, ожидании зависимостей. Startup Probe -- проверяет, завершилась ли инициализация контейнера. До успешной startup probe liveness и readiness probes не выполняются. Используется для приложений с долгим стартом. Все три поддерживают HTTP GET, TCP Socket и exec-команды. Важно правильно настроить initialDelaySeconds, periodSeconds, failureThreshold.',
    explanation:
      'Типичная ошибка -- использование одинаковых эндпоинтов для liveness и readiness. Liveness должен проверять только базовую работоспособность процесса, а readiness -- готовность обслуживать запросы (подключение к БД, прогрев кэша). Агрессивный liveness probe может привести к cascading restarts под нагрузкой.',
  },
  {
    id: 'sd-resilience-014',
    block: 'sd',
    topic: 'resilience',
    topicLabel: 'Отказоустойчивость',
    difficulty: 'middle',
    type: 'quiz',
    question: 'Какой тип ретраев безопасно применять без риска дублирования побочных эффектов?',
    options: [
      'Ретраи для любых HTTP-методов при получении 500 ошибки',
      'Ретраи только для идемпотентных операций (GET, PUT, DELETE с idempotency key)',
      'Ретраи только для POST-запросов, так как они наиболее критичны',
      'Ретраи с бесконечным количеством попыток до успешного ответа',
    ],
    correctIndex: 1,
    explanation:
      'Безопасно ретраить только идемпотентные операции -- те, повторное выполнение которых даёт тот же результат. GET, PUT, DELETE по определению идемпотентны в REST. Для неидемпотентных операций (POST) необходим idempotency key -- уникальный идентификатор запроса, позволяющий серверу распознать дубликат. Stripe, например, поддерживает заголовок Idempotency-Key для безопасного ретрая платёжных операций.',
  },
  {
    id: 'sd-resilience-015',
    block: 'sd',
    topic: 'resilience',
    topicLabel: 'Отказоустойчивость',
    difficulty: 'senior',
    type: 'quiz',
    question: 'Какой подход к Disaster Recovery обеспечивает наименьшее RTO, но является наиболее дорогостоящим?',
    options: [
      'Backup & Restore (холодное резервирование)',
      'Pilot Light (минимальная инфраструктура в резервном регионе)',
      'Warm Standby (уменьшенная копия продакшена в резервном регионе)',
      'Multi-Site Active-Active (полная копия продакшена в нескольких регионах)',
    ],
    correctIndex: 3,
    explanation:
      'Multi-Site Active-Active обеспечивает near-zero RTO, так как трафик уже распределён между регионами. При отказе одного региона остальные автоматически принимают нагрузку. Это наиболее дорогой подход, требующий полной инфраструктуры в каждом регионе и сложной синхронизации данных. AWS классифицирует DR-стратегии по возрастанию стоимости и убыванию RTO: Backup & Restore (часы) → Pilot Light (десятки минут) → Warm Standby (минуты) → Multi-Site (секунды).',
  },
  {
    id: 'sd-resilience-016',
    block: 'sd',
    topic: 'resilience',
    topicLabel: 'Отказоустойчивость',
    difficulty: 'senior',
    type: 'quiz',
    question: 'Что такое self-healing система и какой ключевой механизм лежит в её основе?',
    options: [
      'Система, которая никогда не ломается благодаря идеальному коду',
      'Система, способная автоматически обнаруживать и устранять сбои через control loops (петли обратной связи)',
      'Система, которая самостоятельно обновляет свои зависимости до последних версий',
      'Система с ручным процессом восстановления, документированным в runbook',
    ],
    correctIndex: 1,
    explanation:
      'Self-healing (самовосстанавливающаяся) система использует control loops -- непрерывные циклы наблюдения за текущим состоянием, сравнения с желаемым и автоматической коррекции. Kubernetes -- яркий пример: контроллеры постоянно сравнивают actual state с desired state и выполняют действия (перезапуск подов, масштабирование, перепланирование). Механизмы: auto-restart, auto-scaling, auto-replacement, automated rollback.',
  },
  {
    id: 'sd-resilience-017',
    block: 'sd',
    topic: 'resilience',
    topicLabel: 'Отказоустойчивость',
    difficulty: 'senior',
    type: 'open',
    question: 'Спроектируйте стратегию отказоустойчивости для платёжного сервиса, обрабатывающего финансовые транзакции. Какие паттерны вы применили бы и почему?',
    sampleAnswer:
      'Для платёжного сервиса критичны как доступность, так и консистентность данных. Стратегия: 1) Circuit Breaker для вызовов к платёжным провайдерам (Stripe, PayPal) с fallback на альтернативного провайдера. 2) Idempotency keys для всех операций -- каждая транзакция имеет уникальный UUID, предотвращающий двойное списание при ретраях. 3) Retry с exponential backoff + jitter для временных сбоев сети. 4) Saga Pattern для распределённых транзакций (резервирование → списание → подтверждение) с компенсирующими транзакциями при ошибке. 5) Active-Passive репликация БД с синхронной репликацией (RPO=0). 6) Write-ahead log для восстановления незавершённых транзакций после сбоя. 7) Outbox Pattern для надёжной отправки событий. 8) Rate limiting и bulkhead для изоляции от перегрузок. 9) Health checks с проверкой подключения к БД и платёжным провайдерам.',
    explanation:
      'Финансовые системы имеют наивысшие требования к надёжности. Ключевой принцип: лучше отклонить транзакцию, чем выполнить её дважды. Idempotency и at-least-once delivery в сочетании с дедупликацией на стороне сервера обеспечивают exactly-once семантику на уровне бизнес-логики.',
  },
  {
    id: 'sd-resilience-018',
    block: 'sd',
    topic: 'resilience',
    topicLabel: 'Отказоустойчивость',
    difficulty: 'senior',
    type: 'open',
    question: 'Объясните, как реализовать Bulkhead Pattern на уровне приложения. Приведите конкретные примеры изоляции ресурсов.',
    sampleAnswer:
      'Bulkhead Pattern на уровне приложения реализуется через изоляцию ресурсов для различных зависимостей: 1) Thread Pool Isolation: отдельные пулы потоков для каждого downstream-сервиса (Hystrix использовал этот подход). Если Service A тормозит, исчерпывается только его пул, остальные сервисы работают нормально. 2) Connection Pool Isolation: отдельные connection pools для разных баз данных или внешних API. 3) Semaphore Isolation: ограничение количества одновременных запросов к каждому сервису через семафоры (легковеснее thread pool). 4) Process Isolation: запуск критичных компонентов в отдельных контейнерах/подах. 5) Rate Limiting per dependency: ограничение RPS к каждому downstream. Пример: в e-commerce checkout зависит от Inventory, Payment и Notification. Каждый получает свой пул из 20 потоков. Если Notification зависнет, checkout продолжит работать через Inventory и Payment.',
    explanation:
      'Resilience4j (Java) и Polly (.NET) предоставляют готовые реализации Bulkhead. В Kubernetes bulkhead реализуется через resource limits и отдельные deployments. Комбинация Bulkhead + Circuit Breaker + Timeout даёт максимальную защиту от каскадных отказов.',
  },
  {
    id: 'sd-resilience-019',
    block: 'sd',
    topic: 'resilience',
    topicLabel: 'Отказоустойчивость',
    difficulty: 'senior',
    type: 'open',
    question: 'Как спроектировать multi-region disaster recovery с RPO < 1 минуты и RTO < 5 минут? Какие компромиссы придётся принять?',
    sampleAnswer:
      'Для RPO < 1 мин и RTO < 5 мин: 1) Данные: асинхронная репликация БД между регионами с lag < 1 мин (например, Aurora Global Database с replication lag ~1с, CockroachDB с multi-region). Синхронная репликация даст RPO=0, но увеличит latency записи. 2) Инфраструктура: Warm Standby -- уменьшенная копия продакшена во втором регионе, с автоскейлингом. 3) DNS failover: Route53 health checks + failover routing policy, TTL = 60с. 4) Stateless сервисы в обоих регионах с общим конфигом. 5) Очереди: SQS/Kafka с cross-region replication. 6) Автоматизация: runbook как код через Lambda/Step Functions для автоматического failover. Компромиссы: повышенная стоимость (~1.5-2x), increased write latency при синхронной репликации, сложность тестирования (нужны регулярные DR-drill), потенциальная потеря данных за последнюю минуту при async-репликации, split-brain при network partition между регионами.',
    explanation:
      'Netflix и Amazon проводят регулярные DR-тренировки (Gameday), переключая трафик между регионами. Ключевое правило: DR-план, который не тестируется регулярно, не работает. Стоимость multi-region DR нужно обосновывать через расчёт потерь от простоя (cost of downtime).',
  },
  {
    id: 'sd-resilience-020',
    block: 'sd',
    topic: 'resilience',
    topicLabel: 'Отказоустойчивость',
    difficulty: 'senior',
    type: 'quiz',
    question: 'Какой паттерн позволяет ограничить время ожидания ответа от зависимого сервиса, предотвращая зависание вызывающего потока?',
    options: [
      'Circuit Breaker с порогом ошибок 50%',
      'Timeout Pattern в сочетании с cancel/deadline propagation',
      'Retry с фиксированным интервалом 30 секунд',
      'Bulkhead с одним потоком на сервис',
    ],
    correctIndex: 1,
    explanation:
      'Timeout Pattern -- базовый, но критически важный паттерн. Каждый вызов к внешнему сервису должен иметь таймаут. Deadline propagation передаёт оставшееся время (deadline) вниз по цепочке вызовов: если клиенту осталось 2 секунды, нет смысла ждать 10 секунд от downstream. gRPC поддерживает deadline propagation нативно. Без таймаутов один медленный сервис может заблокировать все потоки вызывающего сервиса, вызвав каскадный отказ.',
  },
];
